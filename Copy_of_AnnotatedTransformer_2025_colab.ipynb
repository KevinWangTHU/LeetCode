{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinWangTHU/LeetCode/blob/master/Copy_of_AnnotatedTransformer_2025_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e1c2519",
      "metadata": {
        "id": "5e1c2519"
      },
      "source": [
        "<center><h1>The Annotated Transformer (2025)</h1> </center>\n",
        "\n",
        "\n",
        "<center>\n",
        "<p><a href=\"https://arxiv.org/abs/1706.03762\">Attention is All You Need\n",
        "</a></p>\n",
        "</center>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://github.com/yflyzhang/AnnotatedTransformer/blob/main/images/paper.png?raw=true)\n"
      ],
      "metadata": {
        "id": "4_qKKtfZMkok"
      },
      "id": "4_qKKtfZMkok"
    },
    {
      "cell_type": "markdown",
      "id": "e03a4c45",
      "metadata": {
        "id": "e03a4c45"
      },
      "source": [
        "This an updated version of the [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/), extending the original implementation to support English-to-Chinese translation using a custom-trained modern tokenizer (e.g., RoBERTa).  \n",
        "\n",
        "This version also replaces Altair with Plotly for visualization and enhances several components, including data loading, batching and data collation.\n",
        "\n",
        "Additionally, fixes and improvements are applied to the attention visualization.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "References:\n",
        "* *[v2022: Austin Huang, Suraj Subramanian, Jonathan Sum, Khalid Almubarak,\n",
        "   and Stella Biderman]((https://nlp.seas.harvard.edu/annotated-transformer/)).*\n",
        "* *[Original: Sasha Rush](https://nlp.seas.harvard.edu/2018/04/03/attention.html).*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "2oDOpOFBt7jN"
      },
      "id": "2oDOpOFBt7jN"
    },
    {
      "cell_type": "markdown",
      "id": "ff96467d",
      "metadata": {
        "id": "ff96467d",
        "lines_to_next_cell": 2
      },
      "source": [
        "# Table of Contents\n",
        "<ul>\n",
        "\n",
        "<li><a href=\"#prelims\">Preliminaries</a></li>\n",
        "\n",
        "<li><a href=\"#background\">Background</a></li>\n",
        "\n",
        "<li><a href=\"#part-1-model-architecture\">Part 1: Model Architecture</a></li><ul>\n",
        "<li><a href=\"#model-architecture\">Model Architecture</a></li>\n",
        "<li><a href=\"#positional-encoding\">Positional Encoding</a></li>\n",
        "<li><a href=\"#embeddings-and-softmax\">Embeddings</a></li>\n",
        "<li><a href=\"#layernorm\">LayerNorm</a></li>\n",
        "<li><a href=\"#position-wise-feed-forward-networks\">Position-wise Feed-Forward\n",
        "Networks</a></li>\n",
        "<li><a href=\"#attention\">Attention</a></li>\n",
        "<li><a href=\"#encoder-and-decoder-stacks\">Encoder and Decoder Stacks</a></li>\n",
        "<li><a href=\"#transformer\">Transformer Model</a></li>\n",
        "<li><a href=\"#full-model\">Create Full Model</a></li>\n",
        "<li><a href=\"#inference\">Inference Test</a></li>\n",
        "</ul></li>\n",
        "\n",
        "<li><a href=\"#part-2-model-training\">Part 2: Preparation for Training</a></li><ul>\n",
        "<li><a href=\"#batches-and-masking\">Batching and Masking</a></li>\n",
        "<li><a href=\"#optimizer\">Optimizer and Scheduler</a></li>\n",
        "<li><a href=\"#training-loop\">Training Loop</a></li>\n",
        "</ul></li>\n",
        "\n",
        "<li><a href=\"#part-3-toy-example\">Part 3: Toy Training Example</a></li><ul>\n",
        "<li><a href=\"#synthetic-data\">Synthetic Data</a></li>\n",
        "<li><a href=\"#loss-computation\">Loss Computation</a></li>\n",
        "<li><a href=\"#greedy-decoding\">Greedy Decoding</a></li>\n",
        "<li><a href=\"#train-loop\">Training Loop</a></li>\n",
        "<li><a href=\"#train-model\">Train the Simple Model</a></li>\n",
        "</ul></li>\n",
        "\n",
        "<li><a href=\"#part-4-a-real-world-example\">Part 4: A Real World Example</a></li>\n",
        "<ul>\n",
        "<li><a href=\"#data-loading\">Data Loading</a></li>\n",
        "<li><a href=\"#iterators\">Train Tokenizer</a></li>\n",
        "<li><a href=\"#tokenize-data\">Tokenize Data</a></li>\n",
        "<li><a href=\"#pad-sequence\">Pad Sequence Examples</a></li>\n",
        "<li><a href=\"#datacollator\">Data Collator and Dataloader</a></li>\n",
        "<li><a href=\"#training-the-system\">Train the System</a></li>\n",
        "<li><a href=\"#greedy-decoding\">Greedy Decoding and Check Results</a></li>\n",
        "</ul></li>\n",
        "\n",
        "<li><a href=\"#results\">Part 5: Attention Visualization</a></li><ul>\n",
        "<li><a href=\"#one-example\">One example from eval dataset</a></li>\n",
        "<li><a href=\"#encoder-self-attention\">Encoder Visualization: Self Attention</a></li>\n",
        "<li><a href=\"#decoder-self-attention\">Decoder Visualization [greedy decoding]: Self Attention</a></li>\n",
        "<li><a href=\"#decoder-cross-attention\">Decoder Visualization [greedy decoding]: Cross Attention</a></li>\n",
        "<li><a href=\"#decoder-self-attention\">Decoder Visualization [teacher force]: Self Attention</a></li>\n",
        "<li><a href=\"#decoder-cross-attention\">Decoder Visualization [teacher force]: Cross Attention</a></li>\n",
        "</ul></li>\n",
        "<li><a href=\"#conclusion\">Conclusion</a></li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a17307f",
      "metadata": {
        "id": "9a17307f"
      },
      "source": [
        "In this tutorial, I changed the order of the components compared to the previous one. The model architecture comes first, followed by positional encoding, embedding, the feed-forward network, attention, the encoder, and the decoder.\n",
        "\n",
        "Finally, the full model is created, and a toy example and a real world example are given."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "W9YZ4Nejt942"
      },
      "id": "W9YZ4Nejt942"
    },
    {
      "cell_type": "markdown",
      "id": "edd0e680",
      "metadata": {
        "id": "edd0e680"
      },
      "source": [
        "# Preliminaries\n",
        "\n",
        "This tutorial is tested in:\n",
        "* python=3.12.7\n",
        "* CUDA=11.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "493ed0c2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:17.534797Z",
          "iopub.status.busy": "2022-05-02T01:25:17.533699Z",
          "iopub.status.idle": "2022-05-02T01:25:17.538114Z",
          "shell.execute_reply": "2022-05-02T01:25:17.537128Z"
        },
        "id": "493ed0c2"
      },
      "outputs": [],
      "source": [
        "## Core python packages\n",
        "\n",
        "# pandas==2.2.3\n",
        "# datasets==3.0.1\n",
        "# plotly==5.24.1\n",
        "# torch==2.4.1\n",
        "# transformers==4.45.2\n",
        "\n",
        "# GPUtil==1.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GPUtil datasets==3.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmYnmggNdO6s",
        "outputId": "f99751fd-e27f-4c07-a26a-0e3a033daada"
      },
      "id": "cmYnmggNdO6s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets==3.0.1\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (0.70.16)\n",
            "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==3.0.1)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (3.12.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.1) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.1) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.1) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.1) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.22.0->datasets==3.0.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.22.0->datasets==3.0.1) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.0.1) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.0.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.0.1) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.0.1) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.0.1) (1.17.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=09fabffbdd85679dfec376492007e462a928ef0b1a1dc3af45a236ce763e4b43\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a8/b7/d8a067c31a74de9ca252bbe53dea5f896faabd25d55f541037\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil, fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GPUtil-1.4.0 datasets-3.0.1 fsspec-2024.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torch 2.4.1 when necessary\n",
        "# !pip install torch==2.4.1 transformers==4.45.2"
      ],
      "metadata": {
        "id": "mFOCxKWqfboz"
      },
      "id": "mFOCxKWqfboz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf3deb7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:17.560273Z",
          "iopub.status.busy": "2022-05-02T01:25:17.559273Z",
          "iopub.status.idle": "2022-05-02T01:25:18.690005Z",
          "shell.execute_reply": "2022-05-02T01:25:18.690769Z"
        },
        "id": "1bf3deb7",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from dataclasses import dataclass\n",
        "from typing import Union, Optional, List, Dict, Any\n",
        "\n",
        "\n",
        "import GPUtil\n",
        "import plotly\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import datasets\n",
        "from transformers import AutoTokenizer, PreTrainedTokenizerBase\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch 2.5.1 is also ok\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CSDApWwsfQ8K",
        "outputId": "385208c0-a1d8-4bc6-9c34-7df8f80a1ddb"
      },
      "id": "CSDApWwsfQ8K",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0+cu126'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W8br6Nk9jU8P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8br6Nk9jU8P",
        "outputId": "ed3baa9c-17ea-4ff6-a528-6237ada56f61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZLwLHjQGjEMq",
      "metadata": {
        "id": "ZLwLHjQGjEMq"
      },
      "outputs": [],
      "source": [
        "# If cuda is available\n",
        "if torch.cuda.is_available():\n",
        "    GPUtil.showUtilization(all=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# my implementation example\n",
        "\n",
        "## todo list:\n",
        "# understand a bit more about positional encoding\n",
        "# understand layernorm\n",
        "# understand dimension of each tensors\n",
        "\n",
        "# attention module is consists of an encoder and a decoder\n",
        "# the encoder is masked such that the shorter sequences in the batch are masked as empty\n",
        "# for encoder it has N layers and it operates on the input sequence which is positional encoded embeddings\n",
        "# for each layer it has two sublayers, which is warpped by a residual connection and a layer norm after that\n",
        "# first sublayer is MHA, second sublayer is MLP\n",
        "# notice that layernorm can be applied before or after the residual connection\n",
        "\n",
        "#\n",
        "# the output dimension\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IUyUXlNjFG86"
      },
      "id": "IUyUXlNjFG86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "WaF119GXf4zu"
      },
      "id": "WaF119GXf4zu"
    },
    {
      "cell_type": "markdown",
      "id": "b000ba74",
      "metadata": {
        "id": "b000ba74"
      },
      "source": [
        "# Background"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87f067cb",
      "metadata": {
        "id": "87f067cb"
      },
      "source": [
        "The dominant sequence transduction models are based on complex recurrent or\n",
        "convolutional neural networks that include an encoder and a decoder. The best\n",
        "performing models also connect the encoder and decoder through an attention\n",
        "mechanism. We propose a new simple network architecture, the Transformer,\n",
        "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
        "entirely. Experiments on two machine translation tasks show these models to\n",
        "be superior in quality while being more parallelizable and requiring significantly\n",
        "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-\n",
        "German translation task, improving over the existing best results, including\n",
        "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
        "our model establishes a new single-model state-of-the-art BLEU score of 41.0 after\n",
        "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
        "best models from the literature."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98d74a9a",
      "metadata": {
        "id": "98d74a9a"
      },
      "source": [
        "\n",
        "The goal of reducing sequential computation also forms the\n",
        "foundation of the Extended Neural GPU, ByteNet and ConvS2S, all of\n",
        "which use convolutional neural networks as basic building block,\n",
        "computing hidden representations in parallel for all input and\n",
        "output positions. In these models, the number of operations required\n",
        "to relate signals from two arbitrary input or output positions grows\n",
        "in the distance between positions, linearly for ConvS2S and\n",
        "logarithmically for ByteNet. This makes it more difficult to learn\n",
        "dependencies between distant positions. In the Transformer this is\n",
        "reduced to a constant number of operations, albeit at the cost of\n",
        "reduced effective resolution due to averaging attention-weighted\n",
        "positions, an effect we counteract with Multi-Head Attention.\n",
        "\n",
        "Self-attention, sometimes called intra-attention is an attention\n",
        "mechanism relating different positions of a single sequence in order\n",
        "to compute a representation of the sequence. Self-attention has been\n",
        "used successfully in a variety of tasks including reading\n",
        "comprehension, abstractive summarization, textual entailment and\n",
        "learning task-independent sentence representations.\n",
        "\n",
        "End-to-end memory networks are based on a recurrent attention mechanism instead\n",
        "of sequencealigned recurrence and have been shown to perform well on\n",
        "simple-language question answering and language modeling tasks.\n",
        "\n",
        "To the best of our knowledge, however, the Transformer is the first\n",
        "transduction model relying entirely on self-attention to compute\n",
        "representations of its input and output without using sequence\n",
        "aligned RNNs or convolution."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "b7WZLcWvuDV0"
      },
      "id": "b7WZLcWvuDV0"
    },
    {
      "cell_type": "markdown",
      "id": "af8b3f4b",
      "metadata": {
        "id": "af8b3f4b"
      },
      "source": [
        "# Part 1: Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ffe7928",
      "metadata": {
        "id": "4ffe7928"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96103f9",
      "metadata": {
        "id": "c96103f9"
      },
      "source": [
        "\n",
        "Most competitive neural sequence transduction models have an\n",
        "encoder-decoder structure. Here, the encoder maps an\n",
        "input sequence of symbol representations $(x_1, ..., x_n)$ to a\n",
        "sequence of continuous representations $\\mathbf{z} = (z_1, ...,\n",
        "z_n)$. Given $\\mathbf{z}$, the decoder then generates an output\n",
        "sequence $(y_1,...,y_m)$ of symbols one element at a time. At each\n",
        "step the model is auto-regressive, consuming the previously\n",
        "generated symbols as additional input when generating the next."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd5d4af0",
      "metadata": {
        "id": "bd5d4af0"
      },
      "source": [
        "\n",
        "The Transformer follows this overall architecture using stacked\n",
        "self-attention and point-wise, fully connected layers for both the\n",
        "encoder and decoder, shown in the left and right halves of Figure 1,\n",
        "respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://github.com/yflyzhang/AnnotatedTransformer/blob/main/images/transformer.png?raw=true)"
      ],
      "metadata": {
        "id": "xwX88W8eNxPR"
      },
      "id": "xwX88W8eNxPR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "qoXLCE07uU4Y"
      },
      "id": "qoXLCE07uU4Y"
    },
    {
      "cell_type": "markdown",
      "id": "dae75640",
      "metadata": {
        "id": "dae75640"
      },
      "source": [
        "## Positional Encoding\n",
        "\n",
        "Since Transformer contains no recurrence and no convolution, in order\n",
        "for the model to make use of the order of the sequence, we must\n",
        "inject some information about the relative or absolute position of\n",
        "the tokens in the sequence.  To this end, we add \"positional\n",
        "encodings\" to the input embeddings at the bottoms of the encoder and\n",
        "decoder stacks.  The positional encodings have the same dimension\n",
        "$d_{\\text{model}}$ as the embeddings, so that the two can be summed.\n",
        "There are many choices of positional encodings, learned and fixed.\n",
        "\n",
        "In this work, we use sine and cosine functions of different frequencies:\n",
        "\n",
        "$$PE_{(pos,2i)} = \\sin(pos / 10000^{2i/d_{\\text{model}}})$$\n",
        "\n",
        "$$PE_{(pos,2i+1)} = \\cos(pos / 10000^{2i/d_{\\text{model}}})$$\n",
        "\n",
        "where $pos$ is the position and $i$ is the dimension.  That is, each\n",
        "dimension of the positional encoding corresponds to a sinusoid.  The\n",
        "wavelengths form a geometric progression from $2\\pi$ to $10000 \\cdot\n",
        "2\\pi$.  We chose this function because we hypothesized it would\n",
        "allow the model to easily learn to attend by relative positions,\n",
        "since for any fixed offset $k$, $PE_{pos+k}$ can be represented as a\n",
        "linear function of $PE_{pos}$.\n",
        "\n",
        "We also experimented with using learned positional embeddings instead, and found that the two\n",
        "versions produced nearly identical results.\n",
        "We chose the sinusoidal version because it may allow the model to extrapolate\n",
        "to sequence lengths longer than the ones encountered during training.\n",
        "\n",
        "In addition, we apply dropout to the sums of the embeddings and the\n",
        "positional encodings in both the encoder and decoder stacks.  For\n",
        "the base model, we use a rate of $P_{drop}=0.1$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea7fe821",
      "metadata": {
        "id": "ea7fe821"
      },
      "outputs": [],
      "source": [
        "def create_fixed_positional_encoding(dim, max_len=5000):\n",
        "    \"Implement the PE function.\"\n",
        "\n",
        "    # Compute the positional encodings once in log space.\n",
        "    pe = torch.zeros(max_len, dim)                      # empty encodings vectors\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)    # position index\n",
        "\n",
        "    # $10000^{\\frac{2i}{d_{model}}}$\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, dim, 2) * -(math.log(10000.0) / dim)\n",
        "    )\n",
        "\n",
        "    # $PE_{p,2i} = sin\\Bigg(\\frac{p}{10000^{\\frac{2i}{d_{model}}}}\\Bigg)$\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "    # $PE_{p,2i + 1} = cos\\Bigg(\\frac{p}{10000^{\\frac{2i}{d_{model}}}}\\Bigg)$\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "    # add batch dimension\n",
        "    pe = pe.unsqueeze(0).requires_grad_(False)\n",
        "\n",
        "    return pe   # simple PE (without embedding info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1070f995",
      "metadata": {
        "id": "1070f995"
      },
      "source": [
        "\n",
        "> Below is an example of the positional encoding which will add in a\n",
        "> sine/cosine wave based on position.\n",
        "> The frequency and offset of the wave is different for each dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "460e649a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "460e649a",
        "outputId": "86cc50fd-6c02-4f4f-b736-899a1a88b471"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d95c2e9e-04f6-4bc9-a385-fc4cdc405d21\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d95c2e9e-04f6-4bc9-a385-fc4cdc405d21\")) {                    Plotly.newPlot(                        \"d95c2e9e-04f6-4bc9-a385-fc4cdc405d21\",                        [{\"hovertemplate\":\"Dimension=0\\u003cbr\\u003ePosition=%{x}\\u003cbr\\u003eEmbedding=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#1F77B4\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"xaxis\":\"x\",\"y\":[0.0,0.84147096,0.9092974,0.14112,-0.7568025,-0.9589243,-0.2794155,0.6569866,0.98935825,0.4121185,-0.5440211,-0.9999902,-0.53657293,0.42016703,0.9906074,0.65028787,-0.2879033,-0.96139747,-0.75098723,0.1498772,0.9129453,0.8366556,-0.008851309,-0.8462204,-0.9055784,-0.13235176,0.76255846,0.95637596,0.2709058,-0.6636339,-0.9880316,-0.40403765,0.5514267,0.99991184,0.5290827,-0.42818266,-0.99177885,-0.6435381,0.29636857,0.96379536,0.74511313,-0.15862267,-0.91652155,-0.8317747,0.017701926,0.8509035,0.90178835,0.123573124,-0.76825464,-0.95375264,-0.26237485,0.6702292,0.9866276,0.39592516,-0.5587891,-0.99975514,-0.521551,0.43616477,0.99287266,0.636738,-0.3048106,-0.9661178,-0.7391807,0.1673557,0.92002606,0.82682866,-0.026551154,-0.85551995,-0.8979277,-0.114784814,0.7738907,0.95105463,0.25382337,-0.67677194,-0.9851463,-0.38778165,0.56610763,0.9995202,0.5139785,-0.44411266,-0.9938887,-0.629888,0.3132288,0.9683645,0.7331903,-0.17607562,-0.92345846,-0.8218178,0.035398304,0.8600694,0.89399666,0.10598751,-0.7794661,-0.9482821,-0.24525198,0.6832617,0.98358774,0.37960774,-0.5733819,-0.99920684,-0.50636566],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Dimension=1\\u003cbr\\u003ePosition=%{x}\\u003cbr\\u003eEmbedding=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"1\",\"line\":{\"color\":\"#FF7F0E\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"xaxis\":\"x\",\"y\":[1.0,0.54030234,-0.41614684,-0.9899925,-0.6536436,0.2836622,0.96017027,0.75390226,-0.14550003,-0.91113025,-0.8390715,0.004425698,0.84385395,0.9074468,0.13673721,-0.7596879,-0.9576595,-0.27516335,0.6603167,0.9887046,0.40808207,-0.54772925,-0.99996084,-0.53283304,0.42417902,0.99120283,0.6469193,-0.29213881,-0.9626059,-0.74805754,0.15425146,0.91474235,0.83422333,-0.013276747,-0.8485703,-0.9036922,-0.12796369,0.76541406,0.95507365,0.26664293,-0.66693807,-0.98733926,-0.3999853,0.5551133,0.9998433,0.525322,-0.43217796,-0.99233544,-0.64014435,0.30059254,0.96496606,0.7421542,-0.16299078,-0.9182828,-0.8293098,0.022126757,0.8532201,0.8998668,0.119180135,-0.7710802,-0.95241296,-0.25810164,0.67350715,0.9858966,0.39185724,-0.56245387,-0.99964744,-0.5177698,0.44014302,0.9933904,0.6333192,-0.30902272,-0.9672506,-0.7361927,0.17171735,0.92175126,0.82433134,-0.030975033,-0.8578031,-0.89597094,-0.11038724,0.77668595,0.9496777,0.24954012,-0.6800235,-0.98437667,-0.38369843,0.5697503,0.99937326,0.5101771,-0.44807363,-0.9943675,-0.62644446,0.3174287,0.96945935,0.7301735,-0.18043046,-0.92514753,-0.81928825,0.03982088,0.8623189],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Dimension=4\\u003cbr\\u003ePosition=%{x}\\u003cbr\\u003eEmbedding=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"4\",\"line\":{\"color\":\"#2CA02C\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"4\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"xaxis\":\"x\",\"y\":[0.0,0.15782663,0.31169716,0.45775455,0.5923377,0.7120732,0.81395954,0.89544296,0.9544809,0.9895935,0.99990064,0.98514396,0.9456933,0.8825376,0.7972599,0.6919978,0.56938994,0.43250963,0.28478765,0.1299273,-0.028190065,-0.18560058,-0.3383588,-0.4826358,-0.61481464,-0.7315824,-0.83001226,-0.9076366,-0.9625098,-0.9932565,-0.9991059,-0.9799113,-0.936154,-0.8689308,-0.7799267,-0.6713724,-0.5459895,-0.40692076,-0.25765195,-0.1019248,0.056357723,0.2132271,0.36475164,0.50713325,0.63680285,0.75051016,0.8454053,0.9191088,0.96977377,0.99613005,0.99751705,0.97389984,0.92587066,0.8546333,0.76197344,0.6502137,0.5221555,0.3810089,0.23031172,0.07384056,-0.08448058,-0.24068412,-0.3908546,-0.53122777,-0.6582851,-0.76884156,-0.8601261,-0.9298504,-0.9762668,-0.9982118,-0.99513525,-0.96711427,-0.9148513,-0.8396564,-0.74341446,-0.62853783,-0.49790612,-0.35479373,-0.20278797,-0.04569906,0.1125363,0.26794985,0.41664687,0.5549001,0.67924404,0.78656185,0.87416345,0.939853,0.98198396,0.9995002,0.9919627,0.95956,0.90310484,0.8240122,0.7242646,0.6063624,0.47326097,0.32829657,0.17510302,0.017520286,-0.14050162],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Dimension=5\\u003cbr\\u003ePosition=%{x}\\u003cbr\\u003eEmbedding=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"5\",\"line\":{\"color\":\"#D62728\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"5\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"xaxis\":\"x\",\"y\":[1.0,0.9874668,0.9501815,0.8890786,0.80568975,0.7021052,0.5809216,0.4451763,0.29827207,0.14389123,-0.014096433,-0.17173062,-0.32506028,-0.47024187,-0.60363615,-0.7218996,-0.82206756,-0.9016293,-0.9585906,-0.9915235,-0.99960256,-0.98262525,-0.9410172,-0.8758212,-0.7886716,-0.681753,-0.55774516,-0.4197569,-0.27124688,-0.11593769,0.042278096,0.19943365,0.35159016,0.49493358,0.6258708,0.74112016,0.837792,0.9134635,0.9662378,0.9947921,0.99841064,0.9770027,0.93110484,0.86186767,0.7710267,0.66085887,0.5341254,0.39400375,0.24400586,0.08789165,-0.070425674,-0.22697815,-0.37784067,-0.5192321,-0.6476083,-0.7597514,-0.85285026,-0.9245714,-0.97311693,-0.99727005,-0.9964251,-0.9706035,-0.9204524,-0.84722906,-0.75276875,-0.63943934,-0.5100815,-0.36793786,-0.21657136,-0.059776228,0.09851823,0.25434226,0.40379086,0.5431179,0.668831,0.777779,0.86723095,0.9349446,0.97922266,0.99895525,0.99364763,0.96343285,0.9090684,0.831917,0.73391247,0.6175115,0.4856318,0.3415791,0.18896428,0.031612813,-0.12653106,-0.28150418,-0.42942008,-0.566572,-0.6895221,-0.7951884,-0.88092226,-0.9445747,-0.9845501,-0.9998465,-0.9900805],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Dimension=10\\u003cbr\\u003ePosition=%{x}\\u003cbr\\u003eEmbedding=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"10\",\"line\":{\"color\":\"#9467BD\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"10\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"xaxis\":\"x\",\"y\":[0.0,0.009999833,0.019998666,0.0299955,0.039989334,0.049979165,0.059964005,0.06994285,0.07991469,0.089878544,0.099833414,0.1097783,0.119712204,0.12963414,0.13954312,0.14943813,0.15931821,0.16918235,0.17902957,0.1888589,0.19866931,0.2084599,0.21822962,0.22797751,0.23770262,0.24740396,0.25708055,0.2667314,0.27635565,0.2859522,0.2955202,0.30505863,0.31456655,0.324043,0.3334871,0.3428978,0.3522742,0.36161545,0.37092048,0.3801884,0.38941833,0.39860934,0.40776044,0.41687077,0.42593947,0.43496552,0.4439481,0.45288628,0.46177918,0.47062588,0.47942555,0.48817724,0.4968801,0.50553334,0.51413596,0.52268726,0.5311862,0.539632,0.54802394,0.556361,0.5646424,0.57286745,0.58103514,0.58914477,0.59719545,0.6051864,0.6131168,0.6209859,0.628793,0.6365372,0.64421767,0.6518338,0.65938467,0.6668696,0.6742879,0.6816388,0.68892145,0.6961352,0.7032794,0.71035326,0.717356,0.72428715,0.7311458,0.7379314,0.7446431,0.75128037,0.75784254,0.76432896,0.7707389,0.7770717,0.78332686,0.7895037,0.7956016,0.80161995,0.8075581,0.81341547,0.8191916,0.82488567,0.8304973,0.83602595,0.84147096],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Dimension=11\\u003cbr\\u003ePosition=%{x}\\u003cbr\\u003eEmbedding=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"11\",\"line\":{\"color\":\"#8C564B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"11\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"xaxis\":\"x\",\"y\":[1.0,0.99995,0.9998,0.99955004,0.9992001,0.99875027,0.99820054,0.997551,0.9968017,0.9959527,0.9950042,0.9939561,0.99280864,0.9915619,0.990216,0.9887711,0.98722726,0.9855848,0.9838437,0.9820042,0.9800666,0.9780309,0.97589743,0.9736664,0.971338,0.9689124,0.96639,0.9637709,0.96105546,0.9582439,0.9553365,0.95233357,0.94923544,0.94604236,0.9427547,0.9393727,0.9358968,0.93232733,0.9286646,0.92490906,0.921061,0.9171208,0.9130889,0.90896577,0.90475166,0.90044713,0.8960525,0.8915683,0.8869949,0.88233286,0.87758255,0.8727445,0.8678192,0.8628071,0.8577087,0.8525245,0.8472551,0.841901,0.8364627,0.83094066,0.8253356,0.819648,0.8138785,0.8080275,0.8020958,0.7960838,0.7899923,0.7838217,0.7775727,0.771246,0.7648422,0.7583619,0.7518057,0.7451744,0.7384685,0.73168886,0.724836,0.7179107,0.71091354,0.7038453,0.6967067,0.6894984,0.68222123,0.6748758,0.6674628,0.65998316,0.6524375,0.64482653,0.6371511,0.62941206,0.62161,0.61374575,0.6058202,0.597834,0.589788,0.5816831,0.57352,0.5652996,0.5570226,0.5486899,0.54030234],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"scatter\":[{\"type\":\"scatter\"}]}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Position\"},\"tickmode\":\"linear\",\"tick0\":0,\"dtick\":5,\"range\":[0,100]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Embedding\"},\"tickmode\":\"linear\",\"tick0\":0,\"dtick\":0.25},\"legend\":{\"title\":{\"text\":\"Dimension\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Positional Encoding\"},\"width\":800,\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d95c2e9e-04f6-4bc9-a385-fc4cdc405d21');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "pe = create_fixed_positional_encoding(20, 5000)       # pe: [1, max_seq_len, d_model]\n",
        "\n",
        "frames = []\n",
        "for dim in [0, 1, 4, 5, 10, 11]:\n",
        "    d = {\n",
        "        'Position': list(range(101)),\n",
        "        'Embedding': pe[0, :101, dim],\n",
        "        'Dimension': dim,\n",
        "    }\n",
        "    frames.append(pd.DataFrame(d))\n",
        "df = pd.concat(frames)\n",
        "fig = px.line(\n",
        "    df, x=\"Position\", y=\"Embedding\", color=\"Dimension\", title='Positional Encoding', template='none',\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    width=800, height=400,\n",
        "    xaxis=dict(\n",
        "        tickmode='linear',\n",
        "        tick0=0,\n",
        "        dtick=5,\n",
        "        range=[0, 100],\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        tickmode='linear',\n",
        "        tick0=0,\n",
        "        dtick=0.25,\n",
        "        # range=[-1, 1],\n",
        "    ),\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b3e15bb",
      "metadata": {
        "id": "1b3e15bb"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13f68bcc",
      "metadata": {
        "id": "13f68bcc"
      },
      "source": [
        "## Embeddings\n",
        "Similarly to other sequence transduction models, we use learned\n",
        "embeddings to convert the input tokens and output tokens to vectors\n",
        "of dimension $d_{\\text{model}}$.  We also use the usual learned\n",
        "linear transformation and softmax function to convert the decoder\n",
        "output to predicted next-token probabilities.  In our model, we\n",
        "share the same weight matrix between the two embedding layers and\n",
        "the pre-softmax linear transformation, similar to\n",
        "[(cite)](https://arxiv.org/abs/1608.05859). In the embedding layers,\n",
        "we multiply those weights by $\\sqrt{d_{\\text{model}}}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc00e748",
      "metadata": {
        "id": "fc00e748"
      },
      "outputs": [],
      "source": [
        "# version 2022\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super().__init__()\n",
        "        self.lut = nn.Embedding(vocab, d_model)     # lut: lookup table\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lut(x) * math.sqrt(self.d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad519c3",
      "metadata": {
        "id": "bad519c3"
      },
      "source": [
        "> We can combine PositionalEncoding with Token Embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "865cf584",
      "metadata": {
        "id": "865cf584"
      },
      "outputs": [],
      "source": [
        "class EmbeddingsWithPositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, dim, dropout=0.1, pe_type='fixed', max_len=50000):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, dim)\n",
        "        self.dim = dim\n",
        "\n",
        "        if pe_type == 'fixed':      # fixed positional encoding\n",
        "            pe = create_fixed_positional_encoding(dim, max_len)\n",
        "            self.register_buffer('pe', pe)              # requires_grad=False\n",
        "        else:                       # learned positional encoding\n",
        "            self.pe = nn.Parameter(torch.zeros(1, max_len, dim))    # requires_grad=True (defaults to True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape (batch_size, seq_len)\n",
        "        \"\"\"\n",
        "\n",
        "        # word/token embedding\n",
        "        token_embedding = self.embed(x) * math.sqrt(self.dim)     # return shape: (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        # positional encoding\n",
        "        positional_encoding = self.pe[:, :x.size(1)]           # return shape: (1, seq_len, embed_dim)\n",
        "\n",
        "        return self.dropout(token_embedding + positional_encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd571c97",
      "metadata": {
        "id": "dd571c97"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff9fe31a",
      "metadata": {
        "id": "ff9fe31a"
      },
      "source": [
        "## LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1f96c3",
      "metadata": {
        "id": "8f1f96c3"
      },
      "outputs": [],
      "source": [
        "# version 2022\n",
        "class LayerNorm(nn.Module):\n",
        "    \"Construct a layernorm module (See citation for details).\"\n",
        "\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c569e51d",
      "metadata": {
        "id": "c569e51d"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "        self.bias = nn.Parameter(torch.zeros(dim))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.weight * (x - mean) / (std + self.eps) + self.bias\n",
        "\n",
        "\n",
        "# Can be replaced by: `nn.LayerNorm`\n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4c629b8",
      "metadata": {
        "id": "a4c629b8"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49e2ab0b",
      "metadata": {
        "id": "49e2ab0b"
      },
      "source": [
        "## Position-wise Feed-Forward Networks\n",
        "\n",
        "In addition to attention sub-layers, each of the layers in our\n",
        "encoder and decoder contains a fully connected feed-forward network,\n",
        "which is applied to each position separately and identically.  This\n",
        "consists of two linear transformations with a ReLU activation in\n",
        "between.\n",
        "\n",
        "$$\\mathrm{FFN}(x)=\\max(0, xW_1 + b_1) W_2 + b_2$$\n",
        "\n",
        "While the linear transformations are the same across different\n",
        "positions, they use different parameters from layer to\n",
        "layer. Another way of describing this is as two convolutions with\n",
        "kernel size 1.  The dimensionality of input and output is\n",
        "$d_{\\text{model}}=512$, and the inner-layer has dimensionality\n",
        "$d_{ff}=2048$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9609213f",
      "metadata": {
        "id": "9609213f"
      },
      "outputs": [],
      "source": [
        "# version 2022\n",
        "class FeedForward(nn.Module):\n",
        "    \"Implements FFN equation.\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(self.w_1(x).relu()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1578c75",
      "metadata": {
        "id": "f1578c75"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim, dropout=0.0, bias=True):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(embed_dim, 4*embed_dim, bias=bias)     # middle layer size is set as 4*embed_dim\n",
        "        self.linear2 = nn.Linear(4*embed_dim, embed_dim, bias=bias)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "353a14cb",
      "metadata": {
        "id": "353a14cb"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53d2701b",
      "metadata": {
        "id": "53d2701b"
      },
      "source": [
        "## Attention\n",
        "\n",
        "An attention function can be described as mapping a query and a set\n",
        "of key-value pairs to an output, where the query, keys, values, and\n",
        "output are all vectors.  The output is computed as a weighted sum of\n",
        "the values, where the weight assigned to each value is computed by a\n",
        "compatibility function of the query with the corresponding key.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1b0d166",
      "metadata": {
        "id": "e1b0d166"
      },
      "source": [
        "### Scaled Dot-Product Attention\n",
        "\n",
        "We call our particular attention \"Scaled Dot-Product Attention\".\n",
        "The input consists of queries and keys of dimension $d_k$, and\n",
        "values of dimension $d_v$.  We compute the dot products of the query\n",
        "with all keys, divide each by $\\sqrt{d_k}$, and apply a softmax\n",
        "function to obtain the weights on the values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "074dbcd7",
      "metadata": {
        "id": "074dbcd7"
      },
      "source": [
        "\n",
        "In practice, we compute the attention function on a set of queries\n",
        "simultaneously, packed together into a matrix $Q$.  The keys and\n",
        "values are also packed together into matrices $K$ and $V$.  We\n",
        "compute the matrix of outputs as:\n",
        "\n",
        "$$\n",
        "   \\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://github.com/yflyzhang/AnnotatedTransformer/blob/main/images/attention.png?raw=true)"
      ],
      "metadata": {
        "id": "qliLx5F8ON_j"
      },
      "id": "qliLx5F8ON_j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9773859",
      "metadata": {
        "id": "c9773859"
      },
      "outputs": [],
      "source": [
        "# version 2022\n",
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"Compute 'Scaled Dot Product Attention'\"\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    p_attn = scores.softmax(dim=-1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7c7094",
      "metadata": {
        "id": "7a7c7094"
      },
      "source": [
        "\n",
        "The two most commonly used attention functions are additive\n",
        "attention, and dot-product\n",
        "(multiplicative) attention.  Dot-product attention is identical to\n",
        "our algorithm, except for the scaling factor of\n",
        "$\\frac{1}{\\sqrt{d_k}}$. Additive attention computes the\n",
        "compatibility function using a feed-forward network with a single\n",
        "hidden layer.  While the two are similar in theoretical complexity,\n",
        "dot-product attention is much faster and more space-efficient in\n",
        "practice, since it can be implemented using highly optimized matrix\n",
        "multiplication code.\n",
        "\n",
        "\n",
        "While for small values of $d_k$ the two mechanisms perform\n",
        "similarly, additive attention outperforms dot product attention\n",
        "without scaling for larger values of $d_k$. We suspect that for\n",
        "large values of $d_k$, the dot products grow large in magnitude,\n",
        "pushing the softmax function into regions where it has extremely\n",
        "small gradients (To illustrate why the dot products get large,\n",
        "assume that the components of $q$ and $k$ are independent random\n",
        "variables with mean $0$ and variance $1$.  Then their dot product,\n",
        "$q \\cdot k = \\sum_{i=1}^{d_k} q_ik_i$, has mean $0$ and variance\n",
        "$d_k$.). To counteract this effect, we scale the dot products by\n",
        "$\\frac{1}{\\sqrt{d_k}}$.\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "865cecca",
      "metadata": {
        "id": "865cecca"
      },
      "source": [
        "\n",
        "### Multi-Head Attention\n",
        "\n",
        "Multi-head attention allows the model to jointly attend to\n",
        "information from different representation subspaces at different\n",
        "positions. With a single attention head, averaging inhibits this.\n",
        "\n",
        "$$\n",
        "\\mathrm{MultiHead}(Q, K, V) =\n",
        "    \\mathrm{Concat}(\\mathrm{head_1}, ..., \\mathrm{head_h})W^O \\\\\n",
        "    \\text{where}~\\mathrm{head_i} = \\mathrm{Attention}(QW^Q_i, KW^K_i, VW^V_i)\n",
        "$$\n",
        "\n",
        "Where the projections are parameter matrices $W^Q_i \\in\n",
        "\\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^K_i \\in\n",
        "\\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^V_i \\in\n",
        "\\mathbb{R}^{d_{\\text{model}} \\times d_v}$ and $W^O \\in\n",
        "\\mathbb{R}^{hd_v \\times d_{\\text{model}}}$.\n",
        "\n",
        "In this work we employ $h=8$ parallel attention layers, or\n",
        "heads. For each of these we use $d_k=d_v=d_{\\text{model}}/h=64$. Due\n",
        "to the reduced dimension of each head, the total computational cost\n",
        "is similar to that of single-head attention with full\n",
        "dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a977f412",
      "metadata": {
        "id": "a977f412"
      },
      "outputs": [],
      "source": [
        "# version 2022\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        \"Take in model size and number of heads.\"\n",
        "        super().__init__()\n",
        "        assert d_model % h == 0, \"embeding dim (d_model) must be divisible by number of heads (h)\"\n",
        "        # We assume d_v always equals d_k\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.attn = None    # record attention score\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # query, key, value (QKV) projections for all heads\n",
        "        self.q_proj = nn.Linear(d_model, d_model)\n",
        "        self.k_proj = nn.Linear(d_model, d_model)\n",
        "        self.v_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # output projection\n",
        "        self.out_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"Implements Figure 2\"\n",
        "        if mask is not None:\n",
        "            # Same mask applied to all h heads.\n",
        "            mask = mask.unsqueeze(1)\n",
        "        # nbatches, seq_len, d_model = query.size()     # 【query】的维度为：batch size (nbatches)[batch first], sequence length (seq_len), embedding dimension (d_model)\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
        "        query = self.q_proj(query).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) # d_model => h x d_k：实现了 multihead attention（多头注意力机制）\n",
        "        key = self.k_proj(key).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "        value = self.k_proj(value).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # 2) Apply attention on all the projected vectors in batch.\n",
        "        x, self.attn = attention(\n",
        "            query, key, value, mask=mask, dropout=self.dropout\n",
        "        )\n",
        "\n",
        "        # 3) \"Concat\" using a view and apply a final linear.\n",
        "        x = (\n",
        "            x.transpose(1, 2)\n",
        "            .contiguous()\n",
        "            .view(nbatches, -1, self.h * self.d_k)  # 通过view/reshape，巧妙地实现了concat multihead的操作\n",
        "        )\n",
        "        del query\n",
        "        del key\n",
        "        del value\n",
        "\n",
        "        return self.out_proj(x)     # 此时返回的变量其维度为：[nbatches, seq_len, d_model]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "833a297a",
      "metadata": {
        "id": "833a297a"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim,\n",
        "        num_heads,\n",
        "        dropout: float = 0.1,\n",
        "        bias: bool = True,\n",
        "        ):\n",
        "\n",
        "        super().__init__()\n",
        "        assert embed_dim % num_heads == 0, \"embed_dim (d_model) must be divisible by num_heads\"\n",
        "        self.head_dim = embed_dim // num_heads      # d_k\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.attn_score = None    # record attention score\n",
        "\n",
        "        # scaling factor\n",
        "        self.scaling = self.head_dim**-0.5\n",
        "\n",
        "        # query, key, value (QKV) projections for all heads\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "\n",
        "        # output projection\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # parameter initialization can be done later after the full model is created\n",
        "        # self.reset_parameters()\n",
        "\n",
        "    # def reset_parameters(self):\n",
        "    #     nn.init.xavier_normal_(self.q_proj.weight)\n",
        "    #     nn.init.xavier_normal_(self.k_proj.weight)\n",
        "    #     nn.init.xavier_normal_(self.v_proj.weight)\n",
        "    #     nn.init.xavier_uniform_(self.out_proj.weight)\n",
        "    #     if self.out_proj.bias is not None:\n",
        "    #         nn.init.constant_(self.out_proj.bias, 0.0)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        query: torch.Tensor,\n",
        "        key: torch.Tensor,\n",
        "        value: torch.Tensor,\n",
        "        mask=None,\n",
        "        return_weights=False\n",
        "        ):\n",
        "\n",
        "        bsz, seq_len, embed_dim = query.size()      # batch size (bsz)[batch first], sequence length (query), embedding dimensionality (embed_dim)\n",
        "        assert embed_dim == self.embed_dim\n",
        "        assert key.size() == value.size()           # key = value\n",
        "\n",
        "        # 1. Q/K/V projections in batch from d_model => h x d_k\n",
        "        # calculate query, key, value for all heads in batch\n",
        "        # and move head forward to be the batch dim\n",
        "        q = self.q_proj(query).view(bsz, -1, self.num_heads, self.head_dim).transpose(1, 2)     # bsz, num_heads, seq_len, head_dim\n",
        "        k = self.k_proj(key).view(bsz, -1, self.num_heads, self.head_dim).transpose(1, 2)       # bsz, num_heads, seq_len, head_dim\n",
        "        v = self.v_proj(value).view(bsz, -1, self.num_heads, self.head_dim).transpose(1, 2)     # bsz, num_heads, seq_len, head_dim\n",
        "\n",
        "        # implementation of attention\n",
        "        # scores = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        scores = (q @ k.transpose(-2, -1)) * self.scaling     # bsz, num_heads, seq_len (query), seq_len (key)\n",
        "\n",
        "        # masked attention\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)        # broadcast: same mask applied to all (num_heads) attention heads\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))   # elements with 0 are masked\n",
        "\n",
        "        # attention weight/probability\n",
        "        attn = F.softmax(scores, dim=-1)    # dim in key sequence\n",
        "\n",
        "        if self.dropout is not None:\n",
        "            attn = self.dropout(attn)\n",
        "\n",
        "        self.attn_score = attn              # record attention score\n",
        "\n",
        "        # attended/weighted sum\n",
        "        # (bsz, num_heads, seq_len, seq_len) x (bsz, num_heads, seq_len, head_dim) -> (bsz, num_heads, seq_len, head_dim)\n",
        "        values = attn @ v\n",
        "        # values = torch.matmul(attn, v)\n",
        "        # values = torch.bmm(attn, v)\n",
        "\n",
        "        # combine multihead attn (reshape)\n",
        "        # (bsz, num_heads, seq_len, head_dim) -> (bsz, seq_len, num_heads, head_dim) -> (bsz, seq_len, embed_dim)\n",
        "        values = values.transpose(1, 2).reshape(bsz, seq_len, embed_dim)\n",
        "        # values = values.permute(0, 2, 1, 3).contiguous().view(bsz, seq_len, embed_dim)\n",
        "\n",
        "        # output projection\n",
        "        out = self.out_proj(values)        # bsz, seq_len, embed_dim\n",
        "\n",
        "        if return_weights:          # return attention weights\n",
        "            return out, attn\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9430667",
      "metadata": {
        "id": "f9430667"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Applications of Attention in our Model\n",
        "\n",
        "The Transformer uses multi-head attention in three different ways:\n",
        "1) In \"encoder-decoder attention\" layers, the queries come from the\n",
        "previous decoder layer, and the memory keys and values come from the\n",
        "output of the encoder.  This allows every position in the decoder to\n",
        "attend over all positions in the input sequence.  This mimics the\n",
        "typical encoder-decoder attention mechanisms in sequence-to-sequence\n",
        "models.\n",
        "\n",
        "\n",
        "2) The encoder contains self-attention layers.  In a self-attention\n",
        "layer all of the keys, values and queries come from the same place,\n",
        "in this case, the output of the previous layer in the encoder.  Each\n",
        "position in the encoder can attend to all positions in the previous\n",
        "layer of the encoder.\n",
        "\n",
        "\n",
        "3) Similarly, self-attention layers in the decoder allow each\n",
        "position in the decoder to attend to all positions in the decoder up\n",
        "to and including that position.  We need to prevent leftward\n",
        "information flow in the decoder to preserve the auto-regressive\n",
        "property.  We implement this inside of scaled dot-product attention\n",
        "by masking out (setting to $-\\infty$) all values in the input of the\n",
        "softmax which correspond to illegal connections."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab6203d5",
      "metadata": {
        "id": "ab6203d5"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edb1b738",
      "metadata": {
        "id": "edb1b738"
      },
      "source": [
        "## Encoder and Decoder Stacks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a08426e3",
      "metadata": {
        "id": "a08426e3"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The encoder is composed of a stack of $N=6$ identical layers.\n",
        "Each layer has two sub-layers. The first is a multi-head\n",
        "self-attention mechanism, and the second is a simple, position-wise\n",
        "fully connected feed-forward network."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f09ce1",
      "metadata": {
        "id": "69f09ce1"
      },
      "source": [
        "\n",
        "We employ a residual connection around each of the two\n",
        "sub-layers, followed by layer normalization.\n",
        "\n",
        "\n",
        "That is, the output of each sub-layer is $\\mathrm{LayerNorm}(x +\n",
        "\\mathrm{Sublayer}(x))$, where $\\mathrm{Sublayer}(x)$ is the function\n",
        "implemented by the sub-layer itself.  We apply dropout to the\n",
        "output of each sub-layer, before it is added to the sub-layer input\n",
        "and normalized.\n",
        "\n",
        "To facilitate these residual connections, all sub-layers in the\n",
        "model, as well as the embedding layers, produce outputs of dimension\n",
        "$d_{\\text{model}}=512$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c2cbaaf",
      "metadata": {
        "id": "5c2cbaaf"
      },
      "outputs": [],
      "source": [
        "# version 2022\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
        "\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.size = size\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"Follow Figure 1 (left) for connections.\"\n",
        "        # x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        # return self.sublayer[1](x, self.feed_forward)\n",
        "\n",
        "        # 1. self-attention sublayer\n",
        "        norm_x = self.norm(x)       # pre-norm, instead of post-norm【这里和文章不一致，先对输入x进行了norm（也称为pre-norm），而文章中是最后才做了norm（也称为post-norm）】\n",
        "        attn_output = self.self_attn(norm_x, norm_x, norm_x, mask)\n",
        "        x = x + self.dropout(attn_output)\n",
        "\n",
        "        # 2. feedforward sublayer\n",
        "        norm_x = self.norm(x)\n",
        "        ff_output = self.feed_forward(norm_x)\n",
        "        return x + self.dropout(ff_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21f7ba53",
      "metadata": {
        "id": "21f7ba53"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    EncoderLayer consists of self-attention and feed forward layers\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, num_heads, dropout=0.1, pre_norm=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(embed_dim, num_heads, dropout)\n",
        "        self.ff = FeedForward(embed_dim, dropout)\n",
        "\n",
        "        self.norm_self_attn = LayerNorm(embed_dim)\n",
        "        self.norm_ff = LayerNorm(embed_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.pre_norm = pre_norm\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "\n",
        "        if self.pre_norm:       # pre-norm\n",
        "            # 1. self-attention sublayer\n",
        "            norm_x = self.norm_self_attn(x)\n",
        "            x = x + self.dropout(self.self_attn(norm_x, norm_x, norm_x, mask))\n",
        "\n",
        "            # 2. feedforward sublayer\n",
        "            norm_x = self.norm_ff(x)\n",
        "            x = x + self.dropout(self.ff(norm_x))\n",
        "        else:                   # post-norm\n",
        "            # 1. self-attention sublayer\n",
        "            x = x + self.dropout(self.self_attn(x, x, x, mask))\n",
        "            x = self.norm_self_attn(x)\n",
        "\n",
        "            # 2. feedforward sublayer\n",
        "            x = x + self.dropout(self.ff(x))\n",
        "            x = self.norm_ff(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b46476af",
      "metadata": {
        "id": "b46476af"
      },
      "source": [
        "> The encoder is composed of a stack of $N=6$ encoder layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44acc3e9",
      "metadata": {
        "id": "44acc3e9"
      },
      "outputs": [],
      "source": [
        "# version 2022\n",
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"Core encoder is a stack of N layers\"\n",
        "\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"Pass the input (and mask) through each layer in turn.\"\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e12940fa",
      "metadata": {
        "id": "e12940fa"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder consists of multiple EncoderLayer sublayers\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim, num_layers, num_heads, dropout=0.1, pre_norm=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # 先实例化，再deepcopy\n",
        "        # Instantiated once, and deepcopy N times\n",
        "        encoder_layer = EncoderLayer(embed_dim, num_heads, dropout, pre_norm)\n",
        "        self.layers = nn.ModuleList([copy.deepcopy(encoder_layer) for _ in range(num_layers)])  # deepcopy is required\n",
        "\n",
        "        # 或者，直接实例化N次\n",
        "        # or instantiated N times directly\n",
        "        # self.layers = nn.ModuleList([EncoderLayer(embed_dim, num_heads, dropout, pre_norm) for _ in range(num_layers)])  # no need to deepcopy\n",
        "\n",
        "        self.norm = LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4329fa0",
      "metadata": {
        "id": "f4329fa0"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69103a47",
      "metadata": {
        "id": "69103a47"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "The decoder is also composed of a stack of $N=6$ identical layers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b30b2b78",
      "metadata": {
        "id": "b30b2b78"
      },
      "source": [
        "\n",
        "In addition to the two sub-layers in each encoder layer, the decoder\n",
        "inserts a third sub-layer, which performs multi-head attention over\n",
        "the output of the encoder stack.  Similar to the encoder, we employ\n",
        "residual connections around each of the sub-layers, followed by\n",
        "layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67947509",
      "metadata": {
        "id": "67947509"
      },
      "outputs": [],
      "source": [
        "# version 2022\n",
        "class DecoderLayer(nn.Module):\n",
        "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
        "\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        \"Follow Figure 1 (right) for connections.\"\n",
        "\n",
        "        # 1. masked self-attention sublayer【对decoder的input做self-attention (self_attn)】\n",
        "        norm_x = self.norm(x)   # pre-norm, instead of post-norm【这里和文章不一致，先对输入x进行了norm（也称为pre-norm），而文章中是最后才做了norm（也称为post-norm）】\n",
        "        attn_output = self.self_attn(norm_x, norm_x, norm_x, tgt_mask)  # 此处的 mask 为tagt_mask（target mask，即decoder输入端的mask）\n",
        "        x = x + self.dropout(attn_output)\n",
        "\n",
        "        # 2. cross-attention sublayer【decoder的input 与 encoder的输出 做 cross-attention (src_attn)】\n",
        "        # memory 即为 encoder 的输出\n",
        "        norm_x = self.norm(x)               # pre-norm, instead of post-norm\n",
        "        attn_output = self.src_attn(norm_x, memory, memory, src_mask)   # 此处的 mask 为src_mask（source mask，即 mask encoder端的padding）\n",
        "                                            # Q = norm_x, K/V = memory\n",
        "        x = x + self.dropout(attn_output)\n",
        "\n",
        "        # 3. feedforward sublayer\n",
        "        norm_x = self.norm(x)\n",
        "        ff_output = self.feed_forward(norm_x)\n",
        "        return x + self.dropout(ff_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b9b56e",
      "metadata": {
        "id": "11b9b56e"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    DecoderLayer consists of self attention, cross attention, and feed forward\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, num_heads, dropout=0.1, pre_norm=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(embed_dim, num_heads, dropout)\n",
        "        self.cross_attn = MultiHeadAttention(embed_dim, num_heads, dropout)\n",
        "        self.ff = FeedForward(embed_dim, dropout)\n",
        "\n",
        "        self.norm_self_attn = LayerNorm(embed_dim)\n",
        "        self.norm_cross_attn = LayerNorm(embed_dim)\n",
        "        self.norm_ff = LayerNorm(embed_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.pre_norm = pre_norm\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):   # caution: the order of args should be consistent across modules\n",
        "        \"\"\"\n",
        "        x, tgt_mask : decoder input and associated 'causal' mask (auto-regressive)\n",
        "        memory, src_mask : encoder output (serves as K, V in cross attention) and associated mask\n",
        "        \"\"\"\n",
        "\n",
        "        if self.pre_norm:       # pre-norm\n",
        "            # 1. masked self-attention sublayer\n",
        "            norm_x = self.norm_self_attn(x)\n",
        "            x = x + self.dropout(self.self_attn(norm_x, norm_x, norm_x, tgt_mask))\n",
        "\n",
        "            # 2. cross-attention sublayer\n",
        "            norm_x = self.norm_cross_attn(x)\n",
        "            x = x + self.dropout(self.cross_attn(norm_x, memory, memory, src_mask)) # decoder side 'queries' encoder output (memory)\n",
        "\n",
        "            # 3. feedforward sublayer\n",
        "            norm_x = self.norm_ff(x)\n",
        "            x = x + self.dropout(self.ff(norm_x))\n",
        "        else:                   # post-norm\n",
        "            # 1. masked self-attention sublayer\n",
        "            x = x + self.dropout(self.self_attn(x, x, x, tgt_mask))\n",
        "            x = self.norm_self_attn(x)\n",
        "\n",
        "            # 2. cross-attention sublayer\n",
        "            x = x + self.dropout(self.cross_attn(x, memory, memory, src_mask))      # decoder side 'queries' encoder output (memory)\n",
        "            x = self.norm_cross_attn(x)\n",
        "\n",
        "            # 3. feedforward sublayer\n",
        "            x = x + self.dropout(self.ff(x))\n",
        "            x = self.norm_ff(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99c212d",
      "metadata": {
        "id": "e99c212d"
      },
      "source": [
        "> The decoder is also composed of a stack of $N=6$ decoder layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c05f6fe",
      "metadata": {
        "id": "8c05f6fe"
      },
      "outputs": [],
      "source": [
        "# version 2022\n",
        "class Decoder(nn.Module):\n",
        "    \"Generic N layer decoder with masking.\"\n",
        "\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2093973f",
      "metadata": {
        "id": "2093973f"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder consists of multiple DecoderLayer sublayers\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim, num_layers, num_heads, dropout=0.1, pre_norm=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # # 先实例化，再deepcopy N次\n",
        "        # Instantiated once, and deepcopy N times\n",
        "        # decoder_layer = DecoderLayer(embed_dim, num_heads, dropout, pre_norm)\n",
        "        # self.layers = nn.ModuleList([copy.deepcopy(decoder_layer) for _ in range(num_layers)])  # 需要deepcopy，否则会导致 所有层共享同一组参数，无法实现独立训练\n",
        "\n",
        "        # 或者，直接实例化N次\n",
        "        # or instantiated N times directly\n",
        "        self.layers = nn.ModuleList([DecoderLayer(embed_dim, num_heads, dropout, pre_norm) for _ in range(num_layers)])\n",
        "        self.norm = LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a79ae34",
      "metadata": {
        "id": "3a79ae34"
      },
      "source": [
        "\n",
        "We also modify the self-attention sub-layer in the decoder stack to\n",
        "prevent positions from attending to subsequent positions.  This\n",
        "masking, combined with fact that the output embeddings are offset by\n",
        "one position, ensures that the predictions for position $i$ can\n",
        "depend only on the known outputs at positions less than $i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3683e9f",
      "metadata": {
        "id": "b3683e9f"
      },
      "outputs": [],
      "source": [
        "def create_causal_mask(size):\n",
        "    \"Mask out subsequent positions to preserve the auto-regressive property.\"\n",
        "    attn_shape = (1, size, size)\n",
        "    causal_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
        "    return causal_mask == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42236386",
      "metadata": {
        "id": "42236386"
      },
      "source": [
        "\n",
        "> Below the attention mask shows the position each target word (row) is\n",
        "> allowed to look at (column).\n",
        "> To preserve the auto-regressive property, words are blocked for attending to\n",
        "> future words during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d08aea58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "d08aea58",
        "outputId": "242c7c29-04b8-4887-b32c-5b02f8837392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tgt mask shape is (21, 21)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a7a87fb1-4b92-4122-ac27-bdb491415242\" class=\"plotly-graph-div\" style=\"height:400px; width:400px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a7a87fb1-4b92-4122-ac27-bdb491415242\")) {                    Plotly.newPlot(                        \"a7a87fb1-4b92-4122-ac27-bdb491415242\",                        [{\"colorbar\":{\"thickness\":20,\"ticklen\":3},\"colorscale\":[[0.0,\"rgb(255,247,251)\"],[0.125,\"rgb(236,231,242)\"],[0.25,\"rgb(208,209,230)\"],[0.375,\"rgb(166,189,219)\"],[0.5,\"rgb(116,169,207)\"],[0.625,\"rgb(54,144,192)\"],[0.75,\"rgb(5,112,176)\"],[0.875,\"rgb(4,90,141)\"],[1.0,\"rgb(2,56,88)\"]],\"xgap\":1,\"ygap\":1,\"z\":[[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],\"type\":\"heatmap\"}],                        {\"height\":400,\"title\":{\"text\":\"Causal Mask\",\"x\":0.5},\"width\":400,\"xaxis\":{\"ticks\":\"outside\"},\"yaxis\":{\"autorange\":\"reversed\",\"ticks\":\"outside\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a7a87fb1-4b92-4122-ac27-bdb491415242');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "n = 21\n",
        "matrix = create_causal_mask(n).int().numpy()[0]\n",
        "print(\"tgt mask shape is\", matrix.shape)\n",
        "\n",
        "heat = go.Heatmap(\n",
        "        z=matrix,\n",
        "        # x=xlabels,\n",
        "        # y=ylabels,\n",
        "        xgap=1, ygap=1,\n",
        "        colorscale='PuBu',\n",
        "        colorbar_thickness=20,\n",
        "        colorbar_ticklen=3,\n",
        "    )\n",
        "layout = go.Layout(\n",
        "    title_text=\"Causal Mask\",\n",
        "    title_x=0.5,\n",
        "    width=400, height=400,\n",
        "    yaxis_autorange='reversed',\n",
        "    xaxis=dict(\n",
        "        ticks='outside'\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        ticks='outside'\n",
        "    ),\n",
        ")\n",
        "fig=go.Figure(data=[heat], layout=layout)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "846a4de2",
      "metadata": {
        "id": "846a4de2"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74aef3a8",
      "metadata": {
        "id": "74aef3a8"
      },
      "source": [
        "## Transformer Model\n",
        "\n",
        "> Transformer model consists of Encoder, Decoder, and a final projection layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf4d54d7",
      "metadata": {
        "id": "bf4d54d7"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    Define decoder side lanaguge model head (`final_proj`, a linear projection) and softmax for generation.\n",
        "    Note: To tie the weights of final_proj with nn.Embedding, bias term in final_proj is set to be False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim, vocab_size):\n",
        "        super().__init__()\n",
        "        self.final_proj = nn.Linear(embed_dim, vocab_size, bias=False)    # projection to vocab size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.final_proj(x), dim=-1)      # softmax and log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4dae104",
      "metadata": {
        "id": "f4dae104"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer consists of Encoder, Decoder, and a final projection layers\n",
        "    \"\"\"\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, embed_dim, num_layers, num_heads, dropout=0.1, pre_norm=True, pe_type='fixed'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.src_embed = EmbeddingsWithPositionalEncoding(src_vocab_size, embed_dim, dropout, pe_type)\n",
        "        self.tgt_embed = EmbeddingsWithPositionalEncoding(tgt_vocab_size, embed_dim, dropout, pe_type)\n",
        "\n",
        "        self.encoder = Encoder(embed_dim, num_layers, num_heads, dropout, pre_norm)\n",
        "        self.decoder = Decoder(embed_dim, num_layers, num_heads, dropout, pre_norm)\n",
        "\n",
        "        self.generator = Generator(embed_dim, tgt_vocab_size)\n",
        "\n",
        "        # post init\n",
        "        self.post_init()\n",
        "\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        \"\"\"Encoder process\"\"\"\n",
        "        x = self.src_embed(src)                     # embedding of src\n",
        "        enc_out = self.encoder(x, src_mask)         # encoder output\n",
        "        return enc_out\n",
        "\n",
        "    def decode(self, tgt, memory, src_mask, tgt_mask):  # the order of args should be consistent across modules\n",
        "        \"\"\"Decoder process\"\"\"\n",
        "        x = self.tgt_embed(tgt)                     # embedding of tgt\n",
        "        dec_out = self.decoder(x, memory, src_mask, tgt_mask)    # the 'encoder output' serves as K,V in 'decoder cross sttention'\n",
        "        return dec_out\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        memory = self.encode(src, src_mask)                      # encoder output (memory)\n",
        "        dec_out = self.decode(tgt, memory, src_mask, tgt_mask)   # decoder output\n",
        "        return dec_out\n",
        "\n",
        "        # out = self.generator(dec_out)                            # final layer projection\n",
        "\n",
        "\n",
        "    def post_init(self):\n",
        "        \"Tie final_proj weight with target embedding weight (defaults to do so)\"\n",
        "        self.generator.final_proj.weight = self.tgt_embed.embed.weight\n",
        "        print(\"Source (encoder) and target (decoder) embedding weights are not tied by default.\")\n",
        "\n",
        "    def tie_weights(self):\n",
        "        \"\"\"\n",
        "        Tie source and target embedding weights when necessary.\n",
        "        For example, tie weights if source and target embeddings use the same vocabulary.\n",
        "        \"\"\"\n",
        "        self.src_embed.embed.weight = self.tgt_embed.embed.weight\n",
        "        print(\"Source (encoder) and target (decoder) embedding weights are now tied.\")\n",
        "\n",
        "    @property\n",
        "    def device(self) -> torch.device:\n",
        "        \"\"\"\n",
        "        `torch.device`: The device on which the module is.\n",
        "        (assuming that all the module parameters are on the same device)\n",
        "        \"\"\"\n",
        "        return next(self.parameters()).device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccabf4b0",
      "metadata": {
        "id": "ccabf4b0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a5ff9589",
      "metadata": {
        "id": "a5ff9589"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdde12fe",
      "metadata": {
        "id": "cdde12fe"
      },
      "source": [
        "## Create Full Model\n",
        "\n",
        "> Here we define a function from hyperparameters to a full model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3939b43",
      "metadata": {
        "id": "b3939b43"
      },
      "outputs": [],
      "source": [
        "def create_model(\n",
        "    src_vocab_size,\n",
        "    tgt_vocab_size,\n",
        "    embed_dim=512,\n",
        "    num_layers=6,\n",
        "    num_heads=8,\n",
        "    dropout=0.1,\n",
        "    pre_norm=True,\n",
        "    pe_type='fixed',\n",
        "    device=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    config:\n",
        "        configurations to set the model\n",
        "\n",
        "        - src_vocab_size\n",
        "        - tgt_vocab_size\n",
        "\n",
        "        - embed_dim\n",
        "        - num_layers\n",
        "        - num_heads\n",
        "        - dropout\n",
        "        - pre_norm\n",
        "        - pe_type\n",
        "\n",
        "        - device\n",
        "    \"\"\"\n",
        "\n",
        "    model = Transformer(src_vocab_size, tgt_vocab_size, embed_dim, num_layers, num_heads, dropout, pre_norm, pe_type)\n",
        "\n",
        "    # Initialize model weights\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    if device is not None:      # note: `0` indicates `cuda:0`\n",
        "        model = model.to(device)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9af576cf",
      "metadata": {
        "id": "9af576cf"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e5767b6",
      "metadata": {
        "id": "0e5767b6"
      },
      "source": [
        "## Inference Test\n",
        "\n",
        "#### Use simple cases to quickly test if the implemented code is executable\n",
        "\n",
        "> Here we make a forward step to generate a prediction of the\n",
        "model. We try to use our transformer to memorize the input. As you\n",
        "will see the output is randomly generated due to the fact that the\n",
        "model is not trained yet. In the next tutorial we will build the\n",
        "training function and try to train our model to memorize the numbers\n",
        "from 1 to 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316fb1d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:19.641806Z",
          "iopub.status.busy": "2022-05-02T01:25:19.640944Z",
          "iopub.status.idle": "2022-05-02T01:25:20.885368Z",
          "shell.execute_reply": "2022-05-02T01:25:20.885607Z"
        },
        "id": "316fb1d2",
        "outputId": "93cc1440-95bf-46c3-8b3b-e599fb07b9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test number 0\n",
            "Source (encoder) and target (decoder) embedding weights are not tied by default.\n",
            "src_embed.embed.weight torch.Size([11, 512])\n",
            "tgt_embed.embed.weight torch.Size([11, 512])\n",
            "encoder.layers.0.self_attn.q_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.0.self_attn.q_proj.bias torch.Size([512])\n",
            "encoder.layers.0.self_attn.k_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.0.self_attn.k_proj.bias torch.Size([512])\n",
            "encoder.layers.0.self_attn.v_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.0.self_attn.v_proj.bias torch.Size([512])\n",
            "encoder.layers.0.self_attn.out_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.0.self_attn.out_proj.bias torch.Size([512])\n",
            "encoder.layers.0.ff.linear1.weight torch.Size([2048, 512])\n",
            "encoder.layers.0.ff.linear1.bias torch.Size([2048])\n",
            "encoder.layers.0.ff.linear2.weight torch.Size([512, 2048])\n",
            "encoder.layers.0.ff.linear2.bias torch.Size([512])\n",
            "encoder.layers.0.norm_self_attn.weight torch.Size([512])\n",
            "encoder.layers.0.norm_self_attn.bias torch.Size([512])\n",
            "encoder.layers.0.norm_ff.weight torch.Size([512])\n",
            "encoder.layers.0.norm_ff.bias torch.Size([512])\n",
            "encoder.layers.1.self_attn.q_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.1.self_attn.q_proj.bias torch.Size([512])\n",
            "encoder.layers.1.self_attn.k_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.1.self_attn.k_proj.bias torch.Size([512])\n",
            "encoder.layers.1.self_attn.v_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.1.self_attn.v_proj.bias torch.Size([512])\n",
            "encoder.layers.1.self_attn.out_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.1.self_attn.out_proj.bias torch.Size([512])\n",
            "encoder.layers.1.ff.linear1.weight torch.Size([2048, 512])\n",
            "encoder.layers.1.ff.linear1.bias torch.Size([2048])\n",
            "encoder.layers.1.ff.linear2.weight torch.Size([512, 2048])\n",
            "encoder.layers.1.ff.linear2.bias torch.Size([512])\n",
            "encoder.layers.1.norm_self_attn.weight torch.Size([512])\n",
            "encoder.layers.1.norm_self_attn.bias torch.Size([512])\n",
            "encoder.layers.1.norm_ff.weight torch.Size([512])\n",
            "encoder.layers.1.norm_ff.bias torch.Size([512])\n",
            "encoder.layers.2.self_attn.q_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.2.self_attn.q_proj.bias torch.Size([512])\n",
            "encoder.layers.2.self_attn.k_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.2.self_attn.k_proj.bias torch.Size([512])\n",
            "encoder.layers.2.self_attn.v_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.2.self_attn.v_proj.bias torch.Size([512])\n",
            "encoder.layers.2.self_attn.out_proj.weight torch.Size([512, 512])\n",
            "encoder.layers.2.self_attn.out_proj.bias torch.Size([512])\n",
            "encoder.layers.2.ff.linear1.weight torch.Size([2048, 512])\n",
            "encoder.layers.2.ff.linear1.bias torch.Size([2048])\n",
            "encoder.layers.2.ff.linear2.weight torch.Size([512, 2048])\n",
            "encoder.layers.2.ff.linear2.bias torch.Size([512])\n",
            "encoder.layers.2.norm_self_attn.weight torch.Size([512])\n",
            "encoder.layers.2.norm_self_attn.bias torch.Size([512])\n",
            "encoder.layers.2.norm_ff.weight torch.Size([512])\n",
            "encoder.layers.2.norm_ff.bias torch.Size([512])\n",
            "encoder.norm.weight torch.Size([512])\n",
            "encoder.norm.bias torch.Size([512])\n",
            "decoder.layers.0.self_attn.q_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.0.self_attn.q_proj.bias torch.Size([512])\n",
            "decoder.layers.0.self_attn.k_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.0.self_attn.k_proj.bias torch.Size([512])\n",
            "decoder.layers.0.self_attn.v_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.0.self_attn.v_proj.bias torch.Size([512])\n",
            "decoder.layers.0.self_attn.out_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.0.self_attn.out_proj.bias torch.Size([512])\n",
            "decoder.layers.0.cross_attn.q_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.0.cross_attn.q_proj.bias torch.Size([512])\n",
            "decoder.layers.0.cross_attn.k_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.0.cross_attn.k_proj.bias torch.Size([512])\n",
            "decoder.layers.0.cross_attn.v_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.0.cross_attn.v_proj.bias torch.Size([512])\n",
            "decoder.layers.0.cross_attn.out_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.0.cross_attn.out_proj.bias torch.Size([512])\n",
            "decoder.layers.0.ff.linear1.weight torch.Size([2048, 512])\n",
            "decoder.layers.0.ff.linear1.bias torch.Size([2048])\n",
            "decoder.layers.0.ff.linear2.weight torch.Size([512, 2048])\n",
            "decoder.layers.0.ff.linear2.bias torch.Size([512])\n",
            "decoder.layers.0.norm_self_attn.weight torch.Size([512])\n",
            "decoder.layers.0.norm_self_attn.bias torch.Size([512])\n",
            "decoder.layers.0.norm_cross_attn.weight torch.Size([512])\n",
            "decoder.layers.0.norm_cross_attn.bias torch.Size([512])\n",
            "decoder.layers.0.norm_ff.weight torch.Size([512])\n",
            "decoder.layers.0.norm_ff.bias torch.Size([512])\n",
            "decoder.layers.1.self_attn.q_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.1.self_attn.q_proj.bias torch.Size([512])\n",
            "decoder.layers.1.self_attn.k_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.1.self_attn.k_proj.bias torch.Size([512])\n",
            "decoder.layers.1.self_attn.v_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.1.self_attn.v_proj.bias torch.Size([512])\n",
            "decoder.layers.1.self_attn.out_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.1.self_attn.out_proj.bias torch.Size([512])\n",
            "decoder.layers.1.cross_attn.q_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.1.cross_attn.q_proj.bias torch.Size([512])\n",
            "decoder.layers.1.cross_attn.k_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.1.cross_attn.k_proj.bias torch.Size([512])\n",
            "decoder.layers.1.cross_attn.v_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.1.cross_attn.v_proj.bias torch.Size([512])\n",
            "decoder.layers.1.cross_attn.out_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.1.cross_attn.out_proj.bias torch.Size([512])\n",
            "decoder.layers.1.ff.linear1.weight torch.Size([2048, 512])\n",
            "decoder.layers.1.ff.linear1.bias torch.Size([2048])\n",
            "decoder.layers.1.ff.linear2.weight torch.Size([512, 2048])\n",
            "decoder.layers.1.ff.linear2.bias torch.Size([512])\n",
            "decoder.layers.1.norm_self_attn.weight torch.Size([512])\n",
            "decoder.layers.1.norm_self_attn.bias torch.Size([512])\n",
            "decoder.layers.1.norm_cross_attn.weight torch.Size([512])\n",
            "decoder.layers.1.norm_cross_attn.bias torch.Size([512])\n",
            "decoder.layers.1.norm_ff.weight torch.Size([512])\n",
            "decoder.layers.1.norm_ff.bias torch.Size([512])\n",
            "decoder.layers.2.self_attn.q_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.2.self_attn.q_proj.bias torch.Size([512])\n",
            "decoder.layers.2.self_attn.k_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.2.self_attn.k_proj.bias torch.Size([512])\n",
            "decoder.layers.2.self_attn.v_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.2.self_attn.v_proj.bias torch.Size([512])\n",
            "decoder.layers.2.self_attn.out_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.2.self_attn.out_proj.bias torch.Size([512])\n",
            "decoder.layers.2.cross_attn.q_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.2.cross_attn.q_proj.bias torch.Size([512])\n",
            "decoder.layers.2.cross_attn.k_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.2.cross_attn.k_proj.bias torch.Size([512])\n",
            "decoder.layers.2.cross_attn.v_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.2.cross_attn.v_proj.bias torch.Size([512])\n",
            "decoder.layers.2.cross_attn.out_proj.weight torch.Size([512, 512])\n",
            "decoder.layers.2.cross_attn.out_proj.bias torch.Size([512])\n",
            "decoder.layers.2.ff.linear1.weight torch.Size([2048, 512])\n",
            "decoder.layers.2.ff.linear1.bias torch.Size([2048])\n",
            "decoder.layers.2.ff.linear2.weight torch.Size([512, 2048])\n",
            "decoder.layers.2.ff.linear2.bias torch.Size([512])\n",
            "decoder.layers.2.norm_self_attn.weight torch.Size([512])\n",
            "decoder.layers.2.norm_self_attn.bias torch.Size([512])\n",
            "decoder.layers.2.norm_cross_attn.weight torch.Size([512])\n",
            "decoder.layers.2.norm_cross_attn.bias torch.Size([512])\n",
            "decoder.layers.2.norm_ff.weight torch.Size([512])\n",
            "decoder.layers.2.norm_ff.bias torch.Size([512])\n",
            "decoder.norm.weight torch.Size([512])\n",
            "decoder.norm.bias torch.Size([512])\n",
            "generator.final_proj.weight torch.Size([11, 512])\n",
            "cpu\n",
            "Example Untrained Model Prediction: tensor([[0, 9, 9, 9, 9, 9, 9, 9, 9, 9]])\n",
            "=====\n"
          ]
        }
      ],
      "source": [
        "def inference_test():\n",
        "    test_model = create_model(\n",
        "        src_vocab_size=11,\n",
        "        tgt_vocab_size=11,\n",
        "        embed_dim=512,\n",
        "        num_layers=3,\n",
        "        num_heads=8,\n",
        "        dropout=0.1,\n",
        "        pre_norm=True,\n",
        "        pe_type='fixed',\n",
        "        device=None,\n",
        "    )\n",
        "    # do not tie the weight for a random test:\n",
        "    test_model.generator.final_proj.weight = nn.Parameter(torch.randn_like(test_model.generator.final_proj.weight))\n",
        "\n",
        "    test_model.eval()\n",
        "    for name, param in test_model.named_parameters(recurse=True):\n",
        "        print(name, param.shape)\n",
        "    print(test_model.device)\n",
        "    src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
        "    src_mask = torch.ones(1, 1, 10)\n",
        "\n",
        "    memory = test_model.encode(src, src_mask)\n",
        "    ys = torch.zeros(1, 1).type_as(src)     # note: ys[0]=0, i.e., ys starts with 0\n",
        "\n",
        "    # model rollout\n",
        "    for i in range(9):\n",
        "        tgt_mask = create_causal_mask(ys.size(1)).type_as(src.data)\n",
        "        out = test_model.decode(ys, memory, src_mask, tgt_mask)\n",
        "        prob = test_model.generator(out[:, -1])     # last token\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data[0]\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.empty(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
        "        )\n",
        "\n",
        "\n",
        "    print(\"Example Untrained Model Prediction:\", ys)\n",
        "\n",
        "for i in range(1):\n",
        "    print(\"test number {}\".format(i))\n",
        "    inference_test()\n",
        "    print(\"=====\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "7ZDffKpPhI6V"
      },
      "id": "7ZDffKpPhI6V"
    },
    {
      "cell_type": "markdown",
      "id": "859848fd",
      "metadata": {
        "id": "859848fd"
      },
      "source": [
        "# Part 2: Preparation for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16acd58b",
      "metadata": {
        "id": "16acd58b"
      },
      "source": [
        "This section describes the training regime for our models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e4dad0d",
      "metadata": {
        "id": "7e4dad0d"
      },
      "source": [
        "\n",
        "> We stop for a quick interlude to introduce some of the tools\n",
        "> needed to train a standard encoder decoder model. First we define a\n",
        "> batch object that holds the src and target sentences for training,\n",
        "> as well as constructing the masks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "918f5ddd",
      "metadata": {
        "id": "918f5ddd"
      },
      "source": [
        "### Batching and Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "927a4213",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "927a4213",
        "outputId": "2ab9c7e7-3a5e-4a2b-9c29-2bc747d233e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ True, False, False, False],\n",
              "         [ True,  True, False, False],\n",
              "         [ True,  True,  True, False],\n",
              "         [ True,  True,  True,  True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "create_causal_mask(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee20bc4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:20.889839Z",
          "iopub.status.busy": "2022-05-02T01:25:20.889563Z",
          "iopub.status.idle": "2022-05-02T01:25:20.890646Z",
          "shell.execute_reply": "2022-05-02T01:25:20.892925Z"
        },
        "id": "4ee20bc4"
      },
      "outputs": [],
      "source": [
        "# 简单的 batch 格式\n",
        "# simple batching format\n",
        "\n",
        "# version 2022\n",
        "class Batch:\n",
        "    \"\"\"Object for holding a batch of data with mask during training.\"\"\"\n",
        "\n",
        "    def __init__(self, src, tgt=None, pad=2):  # 2 = <blank>\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2)  # padding mask (unsqueeze for broadcasting)\n",
        "        if tgt is not None:\n",
        "            self.tgt = tgt[:, :-1]\n",
        "            self.tgt_y = tgt[:, 1:]     # next token/word prediction\n",
        "            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n",
        "            self.num_tokens = (self.tgt_y != pad).data.sum()\n",
        "\n",
        "    @staticmethod\n",
        "    def make_std_mask(tgt, pad):\n",
        "        \"Create a mask to hide padding and future words.\"\n",
        "        tgt_mask = (tgt != pad).unsqueeze(-2)       # padding mask (unsqueeze for broadcasting)\n",
        "        tgt_mask = tgt_mask & create_causal_mask(tgt.size(-1)).type_as(tgt_mask.data)   # add causal mask\n",
        "        return tgt_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d5693f",
      "metadata": {
        "id": "a4d5693f"
      },
      "outputs": [],
      "source": [
        "# 更强大的 batch 格式控制\n",
        "# more sophisticated batching format\n",
        "# ref: https://github.com/huggingface/transformers/blob/v4.45.2/src/transformers/tokenization_utils_base.py#L192\n",
        "\n",
        "from collections import UserDict\n",
        "class Batch(UserDict):\n",
        "    \"\"\"Object for holding a batch of data with mask during training.\"\"\"\n",
        "\n",
        "    def __init__(self, src, tgt, pad):\n",
        "\n",
        "        self.data = {}      # ultimate dictionary that stores ('src', 'src_mask', etc.).\n",
        "        self.data['src'] = src\n",
        "        self.data['src_mask'] = (src != pad).unsqueeze(-2)\n",
        "        if tgt is not None:\n",
        "            # shifted right for next word/token prediction\n",
        "            self.data['tgt'] = tgt[:, :-1]      # decoder input\n",
        "            self.data['tgt_y'] = tgt[:, 1:]     # decoder target\n",
        "            self.data['tgt_mask'] = self.make_std_mask(self.data['tgt'], pad)\n",
        "            self.data['num_tokens'] = (self.data['tgt_y'] != pad).data.sum()   # num_tokens\n",
        "\n",
        "        super().__init__(self.data)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_std_mask(tgt, pad):\n",
        "        \"Create a mask to hide padding and future words.\"\n",
        "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "        tgt_mask = tgt_mask & create_causal_mask(tgt.size(-1)).type_as(         # add causal mask\n",
        "            tgt_mask.data\n",
        "        )\n",
        "        return tgt_mask\n",
        "\n",
        "    def __getitem__(self, item: str):\n",
        "        \"\"\"\n",
        "        If the key is a string, returns the value of the dict associated to `key`\n",
        "        ('src', 'src_mask', etc.).\n",
        "        \"\"\"\n",
        "        if isinstance(item, str):\n",
        "            return self.data[item]\n",
        "        else:\n",
        "            raise KeyError(\"Invalid key. Only string of key is available\")\n",
        "\n",
        "    def __getattr__(self, item: str):\n",
        "        try:\n",
        "            return self.data[item]\n",
        "        except KeyError:\n",
        "            raise AttributeError\n",
        "\n",
        "    def keys(self):\n",
        "        return self.data.keys()\n",
        "\n",
        "    def values(self):\n",
        "        return self.data.values()\n",
        "\n",
        "    def items(self):\n",
        "        return self.data.items()\n",
        "\n",
        "    def device(self):\n",
        "        return self.data['src'].device\n",
        "\n",
        "    def to(self, device: Union[str, \"torch.device\"]):\n",
        "        \"\"\"\n",
        "        Send all values to device by calling `v.to(device)` (PyTorch only).\n",
        "\n",
        "        Args:\n",
        "            device (`str` or `torch.device`): The device to put the tensors on.\n",
        "        \"\"\"\n",
        "\n",
        "        # This check catches things like APEX blindly calling \"to\" on all inputs to a module\n",
        "        # Otherwise it passes the casts down and casts the LongTensor containing the token idxs\n",
        "        # into a HalfTensor\n",
        "        if isinstance(device, str) or isinstance(device, int) or isinstance(device, torch.device):\n",
        "            self.data = {\n",
        "                k: v.to(device=device) if isinstance(v, torch.Tensor) else v\n",
        "                for k, v in self.data.items()\n",
        "            }\n",
        "        else:\n",
        "            print(f\"warning: Attempting to cast a Batch to type {str(device)}. This is not supported.\")\n",
        "        return self"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7865da91",
      "metadata": {
        "id": "7865da91"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3af07c4b",
      "metadata": {
        "id": "3af07c4b"
      },
      "source": [
        "## Optimizer and Scheduler\n",
        "\n",
        "We used the Adam optimizer\n",
        "with $\\beta_1=0.9$, $\\beta_2=0.98$ and $\\epsilon=10^{-9}$.  We\n",
        "varied the learning rate over the course of training, according to\n",
        "the formula:\n",
        "\n",
        "$$\n",
        "lrate = d_{\\text{model}}^{-0.5} \\cdot\n",
        "  \\min({step\\_num}^{-0.5},\n",
        "    {step\\_num} \\cdot {warmup\\_steps}^{-1.5})\n",
        "$$\n",
        "\n",
        "This corresponds to increasing the learning rate linearly for the\n",
        "first $warmup\\_steps$ training steps, and decreasing it thereafter\n",
        "proportionally to the inverse square root of the step number.  \n",
        "\n",
        "\n",
        "> We can laso use some other optimizers (e.g., `AdamW`) and learning schedulers (e.g., `CosineAnnealingLR`) implemented in PyTorch or other resources.<br>\n",
        "> For further details, see: https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
        ">\n",
        "> Note: `AdamW` is an improved version of `Adam` and is thus more widely used now.\n",
        "> <br>https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html#torch.optim.AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ded57a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:20.906007Z",
          "iopub.status.busy": "2022-05-02T01:25:20.904743Z",
          "iopub.status.idle": "2022-05-02T01:25:20.907701Z",
          "shell.execute_reply": "2022-05-02T01:25:20.907236Z"
        },
        "id": "27ded57a"
      },
      "outputs": [],
      "source": [
        "def rate(step, model_size, factor, warmup):\n",
        "    \"\"\"\n",
        "    we have to default the step to 1 for LambdaLR function\n",
        "    to avoid zero raising to negative power.\n",
        "    \"\"\"\n",
        "    if step == 0:\n",
        "        step = 1\n",
        "    return factor * (\n",
        "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e809dff8",
      "metadata": {
        "id": "e809dff8"
      },
      "source": [
        "\n",
        "> Example of the curves of this model for different model sizes and\n",
        "> for optimization hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7512d7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "b7512d7e",
        "outputId": "a0de2ff5-458d-4925-c2a3-2d646386bf3b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"26099489-8fe5-48c7-8f0a-b6255aa8d61b\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"26099489-8fe5-48c7-8f0a-b6255aa8d61b\")) {                    Plotly.newPlot(                        \"26099489-8fe5-48c7-8f0a-b6255aa8d61b\",                        [{\"hovertemplate\":\"group=256:200\\u003cbr\\u003estep=%{x}\\u003cbr\\u003elr=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"256:200\",\"line\":{\"color\":\"#1F77B4\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"256:200\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000],\"xaxis\":\"x\",\"y\":[0.00002209708691207961,0.00002209708691207961,0.00004419417382415922,0.00006629126073623883,0.00008838834764831844,0.00011048543456039805,0.00013258252147247765,0.00015467960838455727,0.00017677669529663688,0.0001988737822087165,0.0002209708691207961,0.00024306795603287572,0.0002651650429449553,0.00028726212985703494,0.00030935921676911453,0.00033145630368119417,0.00035355339059327376,0.00037565047750535334,0.000397747564417433,0.00041984465132951257,0.0004419417382415922,0.0004640388251536718,0.00048613591206575144,0.0005082329989778311,0.0005303300858899106,0.0005524271728019902,0.0005745242597140699,0.0005966213466261494,0.0006187184335382291,0.0006408155204503087,0.0006629126073623883,0.0006850096942744679,0.0007071067811865475,0.0007292038680986272,0.0007513009550107067,0.0007733980419227863,0.000795495128834866,0.0008175922157469456,0.0008396893026590251,0.0008617863895711048,0.0008838834764831844,0.000905980563395264,0.0009280776503073436,0.0009501747372194232,0.0009722718241315029,0.0009943689110435824,0.0010164659979556622,0.0010385630848677417,0.0010606601717798212,0.001082757258691901,0.0011048543456039805,0.00112695143251606,0.0011490485194281398,0.0011711456063402193,0.0011932426932522988,0.0012153397801643786,0.0012374368670764581,0.0012595339539885377,0.0012816310409006174,0.001303728127812697,0.0013258252147247767,0.0013479223016368562,0.0013700193885489357,0.0013921164754610155,0.001414213562373095,0.0014363106492851746,0.0014584077361972543,0.0014805048231093338,0.0015026019100214134,0.0015246989969334931,0.0015467960838455727,0.0015688931707576524,0.001590990257669732,0.0016130873445818115,0.0016351844314938912,0.0016572815184059707,0.0016793786053180503,0.00170147569223013,0.0017235727791422096,0.001745669866054289,0.0017677669529663688,0.0017898640398784484,0.001811961126790528,0.0018340582137026076,0.0018561553006146872,0.001878252387526767,0.0019003494744388465,0.001922446561350926,0.0019445436482630057,0.0019666407351750853,0.001988737822087165,0.0020108349089992443,0.0020329319959113243,0.002055029082823404,0.0020771261697354834,0.002099223256647563,0.0021213203435596424,0.002143417430471722,0.002165514517383802,0.0021876116042958815,0.002209708691207961,0.0022318057781200405,0.00225390286503212,0.0022759999519442,0.0022980970388562796,0.002320194125768359,0.0023422912126804386,0.002364388299592518,0.0023864853865045977,0.0024085824734166776,0.002430679560328757,0.0024527766472408367,0.0024748737341529162,0.0024969708210649958,0.0025190679079770753,0.0025411649948891553,0.002563262081801235,0.0025853591687133143,0.002607456255625394,0.0026295533425374734,0.0026516504294495534,0.002673747516361633,0.0026958446032737124,0.002717941690185792,0.0027400387770978715,0.002762135864009951,0.002784232950922031,0.0028063300378341105,0.00282842712474619,0.0028505242116582696,0.002872621298570349,0.002894718385482429,0.0029168154723945086,0.002938912559306588,0.0029610096462186677,0.002983106733130747,0.0030052038200428267,0.0030273009069549067,0.0030493979938669862,0.0030714950807790658,0.0030935921676911453,0.003115689254603225,0.003137786341515305,0.0031598834284273843,0.003181980515339464,0.0032040776022515434,0.003226174689163623,0.0032482717760757025,0.0032703688629877824,0.003292465949899862,0.0033145630368119415,0.003336660123724021,0.0033587572106361006,0.00338085429754818,0.00340295138446026,0.0034250484713723396,0.003447145558284419,0.0034692426451964986,0.003491339732108578,0.003513436819020658,0.0035355339059327377,0.003557630992844817,0.0035797280797568967,0.0036018251666689763,0.003623922253581056,0.0036460193404931358,0.0036681164274052153,0.003690213514317295,0.0037123106012293744,0.003734407688141454,0.003756504775053534,0.0037786018619656134,0.003800698948877693,0.0038227960357897725,0.003844893122701852,0.0038669902096139315,0.0038890872965260115,0.003911184383438091,0.0039332814703501705,0.00395537855726225,0.00397747564417433,0.003999572731086409,0.004021669817998489,0.004043766904910568,0.004065863991822649,0.004087961078734728,0.004110058165646808,0.004132155252558887,0.004154252339470967,0.004176349426383046,0.004198446513295126,0.004220543600207205,0.004242640687119285,0.004264737774031364,0.004286834860943444,0.004308931947855524,0.004331029034767604,0.004353126121679683,0.004375223208591763,0.0043973202955038425,0.004419417382415922,0.004408410099116239,0.004397484654564324,0.004386640039647478,0.00437587526258753,0.0043651893485598635,0.0043545813393226105,0.004344050292855724,0.004333595283009603,0.004323215399162967,0.004312909745889714,0.004302677442634464,0.004292517623396532,0.004282429436422073,0.004272412043904146,0.004262464621690459,0.004252586358998573,0.0042427764581383165,0.004233034134241228,0.004223358614996787,0.004213749140395263,0.004204204962476953,0.004194725345087652,0.004185309563640156,0.004175956904881631,0.004166666666666667,0.004157438157735871,0.004148270697499825,0.004139163615828262,0.004130116252844311,0.004121127958723669,0.004112198093498556,0.0041033260268663295,0.004094511138002615,0.004085752815378834,0.004077050456584014,0.0040684034681507455,0.004059811265385193,0.0040512732722010275,0.004042788920957193,0.004034357652299393,0.004025978915005193,0.004017652165832657,0.004009376869372401,0.004001152497902999,0.0039929785312496245,0.003984854456645865,0.003976779768598611,0.003968753968755953,0.003960776565777987,0.003952847075210474,0.0039449650193612695,0.0039371299271794506,0.003929341334137072,0.003921598782113491,0.003913901819282185,0.00390625,0.0038986428846987833,0.0038910800397793147,0.0038835610375075004,0.003876085455912764,0.0038686528786885804,0.003861262895095097,0.0038539150998637963,0.003846609093104148,0.003839344480212195,0.0038321208717810363,0.0038249378835131537,0.0038177951361345382,0.0038106922553105774,0.0038036288715636536,0.003796604620192419,0.0037896191411927026,0.003782672079180015,0.003775763083313606,0.003768891807222045,0.0037620579089302874,0.0037552610507881855,0.0037485008994004197,0.0037417771255578106,0.00373508940416998,0.003728437414199335,0.0037218208385963354,0.003715239364236025,0.003708692681855792,0.003702180485994327,0.003695702474931766,0.0036892583506309704,0.003682847818679935,0.003676470588235294,0.0036701263719668966,0.003663814886003432,0.0036575358498790803,0.0036512889864811623,0.003645074021998777,0.003638890685872387,0.0036327387107443526,0.0036266178324103715,0.0036205277897718266,0.0036144683247890013,0.003608439182435161,0.0036024401106514686,0.003596470860302725,0.003590531185133913,0.0035846208417275277,0.0035787395894616766,0.0035728871904689343,0.003567063409595935,0.003561268014363686,0.0035555007749285892,0.003549761464044155,0.003544049857023392,0.0035383657317018618,0.0035327088684013845,0.003527079049894377,0.0035214760613688193,0.003515899690393825,0.0035103497268858153,0.0035048259630752767,0.003499328193474089,0.0034938562148434213,0.003488409826162172,0.003482988828595955,0.0034775930254666077,0.003472222222222222,0.003466876226407682,0.0034615548476356955,0.003456257897558319,0.0034509851898389546,0.0034457365401248203,0.0034405117660198767,0.0034353106870582046,0.0034301331246778233,0.0034249789021949437,0.0034198478447786426,0.0034147397794259565,0.003409654534937381,0.0034045919418927706,0.0033995518326276324,0.0033945340412098023,0.0033895384034165026,0.0033845647567117645,0.0033796129402242194,0.003374682794725243,0.0033697741626074504,0.0033648868878635345,0.0033600208160654396,0.0033551757943438686,0.003350351671368109,0.0033455482973261826,0.003340765523905305,0.0033360032042726484,0.003331261193056413,0.0033265393463271843,0.0033218375215795866,0.0033171555777142202,0.003312493375019875,0.00330785077515602,0.0033032276411355623,0.003298623837307872,0.0032940392293420617,0.003289473684210526,0.003284927070172729,0.0032803992567592374,0.0032758901147559947,0.0032713995161888355,0.0032669273343082293,0.0032624734435742534,0.0032580377196417933,0.0032536200393459597,0.003249220280687727,0.0032448383228197816,0.003240474046032579,0.0032361273317406108,0.0032317980624688696,0.003227486121839514,0.0032231913945587293,0.0032189137664037797,0.003214653124210248,0.0032104093558594634,0.0032061823502661066,0.0032019719973659998,0.003197778188104068,0.003193600814422475,0.00318943976924893,0.0031852949464851598,0.0031811662409955473,0.0031770535485959304,0.0031729567660425595,0.0031688757910212115,0.0031648105221364583,0.003160760858901085,0.003156726701725659,0.0031527079519082396,0.00314870451162424,0.0031447162839164226,0.003140743172685038,0.0031367850826780974,0.0031328419194817845,0.003128913589510993,0.003125,0.0031211010589932645,0.0031172166753363527,0.0031133467586669868,0.003109491219406216,0.003105649968749708,0.003101822918659157,0.0030980099818538106,0.003094211071802107,0.0030904261027134296,0.0030866549895299674,0.003082897647918688,0.0030791539942634162,0.003075423945657018,0.0030717074198936905,0.0030680043354613497,0.0030643146115341257,0.0030606381679649484,0.0030569749252782404,0.0030533248046626968,0.003049687727964166,0.003046063617678621,0.0030424523969452217,0.00303885398953947,0.0030352683198664504,0.003031695312954162,0.003028134894446933,0.0030245869905989203,0.0030210515282676985,0.0030175284349079224,0.0030140176385650757,0.0030105190678693,0.003007032652029301,0.00300355832082633,0.003000096004608246,0.002996645634283651,0.002993207141316098,0.002989780457718374,0.0029863655160468536,0.0029829622493959228,0.002979570591392476,0.002976190476190476,0.002972821838465588,0.0029694646134098743,0.0029661187367265593,0.0029627841446248577,0.0029594607738148647,0.0029561485615025133,0.002952847445384588,0.0029495573636438045,0.002946278254943948,0.0029430100584250693,0.0029397527136987415,0.0029365061608433722,0.0029332703403995757,0.0029300451933655966,0.0029268306611927937,0.002923626685781175,0.002920433209474986,0.002917250175058354,0.0029140775257509807,0.0029109152052038895,0.0029077631574952216,0.002904621327126082,0.0029014896590164353,0.0028983680985010516,0.0028952565913254965,0.002892155083642172,0.0028890635220064015,0.0028859818533725633,0.002882910025090266,0.0028798479849005713,0.0028767956809322604,0.002873753061698143,0.0028707200760914086,0.002867696673382022,0.0028646828032131604,0.002861678415597688,0.0028586834609146765,0.0028556978899059613,0.00285272165367274,0.0028497547036722077,0.002846796991714231,0.002843848469958063,0.002840909090909091,0.0028379788074156236,0.0028350575726657154,0.0028321453401840236,0.002829242063828704,0.0028263476977883413,0.00282346219657891,0.002820585515040776,0.002817717608335726,0.0028148584319440313,0.0028120079416615474,0.002809166093596842,0.002806332844168358,0.002803508150101604,0.00280069196842638,0.0027978842564740326,0.002795084971874737,0.0027922940725548144,0.0027895115167340737,0.0027867372629231863,0.0027839712699210873,0.002781213496812405,0.002778463902964919,0.002775722448027047,0.0027729890919253554,0.0027702637948621017,0.0027675465173127977,0.002764837220023805,0.0027621358640099515,0.0027594424105521747,0.002756756821195193,0.0027540790577451984,0.0027514090822675745,0.0027487468570846405,0.0027460923447734176,0.0027434455081634195,0.002740806310334466,0.002738174714614522,0.0027355506845775533,0.002732934184041413,0.0027303251770657436,0.002727723627949905,0.0027251295012309207,0.0027225427616814507,0.002719963374307779,0.002717391304347826,0.0027148265172691837,0.002712268978767164,0.002709718654762875,0.0027071755114013124,0.002704639515049472,0.002702110632294481,0.0026995888299417505,0.0026970740750131444,0.0026945663347451676,0.002692065576587175,0.002689571768199595,0.0026870848774521736,0.002684604872422236,0.0026821317213929657,0.0026796653928517007,0.002677205855488246,0.0026747530781932056,0.00267230703005633,0.002669867680364878,0.0026674349986019995,0.0026650089544451305,0.0026625895177644064,0.0026601766586210893,0.0026577703472660144,0.002655370554138046,0.0026529772498625555,0.002650590405249909,0.0026482099912939734,0.0026458359791706352,0.0026434683402363347,0.002641107046026614,0.0026387520682546817,0.0026364033788099863,0.00263406094975681,0.0026317247533328716,0.0026293947619479455,0.002627070948182491,0.0026247532847863,0.0026224417446771534,0.002620136300939491,0.002617836926823097,0.002615543595741795,0.0026132562812721588,0.00261097495715223,0.002608699597280257,0.0026064301757134345,0.0026041666666666665,0.0026019090445113333,0.002599657283774072,0.002597411359135571,0.002595171245429374,0.002592936917640695,0.0025907083509052447,0.0025884855205080695,0.0025862684018824,0.0025840569706085093,0.0025818512024125863,0.0025796510731656125,0.002577456558882258,0.0025752676357197785,0.002573084279976932,0.0025709064680928973,0.0025687341766462077,0.002566567382353693,0.002564406062069432,0.0025622501927837116,0.0025600997516220013,0.0025579547158439313,0.0025558150628422834,0.00255368077014199,0.002551551815399144,0.002549428176400013,0.00254730983106007,0.0025451967574230253,0.002543088933659873,0.002540986338067943,0.002538888949069961,0.0025367967452131217,0.0025347097051681648,0.0025326278077284618,0.0025305510318091124,0.0025284793564460464,0.0025264127607951352,0.0025243512241313105,0.0025222947258476927,0.0025202432454547244,0.0025181967625793134,0.002516155256963983,0.0025141187084660303,0.00251208709705669,0.002510060402820309,0.002508038605953525,0.0025060216867644545,0.002504009625671887,0.0025020024032044864,0.0025,0.0024980023968044734,0.0024960095744714743,0.002494021513961319,0.0024920381963403123,0.0024900596027799867,0.002488085714556353,0.0024861165130491566,0.0024841519797411385,0.002482192096217305,0.002480236844164203,0.0024782862053692005,0.002476340161719773,0.0024743986952027995,0.002472461787903861,0.0024705294220065464,0.0024686015797917636,0.0024666782436370575,0.0024647593960159344,0.0024628450194971894,0.002460935096744243,0.0024590296105144803,0.002457128543658598,0.0024552318791199565,0.0024533395999339364,0.0024514516892273006,0.0024495681302175642,0.002447688906212367,0.002445814000608851,0.002443943396893047,0.002442077078639261,0.00244021502950947,0.00243835723325272,0.0024365036737045327,0.0024346543347863116,0.0024328092005047592,0.0024309682549512935,0.002429131482301474,0.0024272988668144293,0.00242547039283229,0.002423646044779629,0.0024218258071629015,0.0024200096645698947,0.0024181976016691776,0.0024163896032095597,0.0024145856540195494,0.0024127857390068216,0.002410989843157686,0.0024091979515365614,0.002407410049285454,0.0024056261216234406,0.002403846153846154,0.0024020701313252745,0.0024002980395080266,0.002398529863916676,0.002396765590148033,0.0023950052038729606,0.002393248690835886,0.0023914960368543155,0.0023897472278183516,0.002388002249690219,0.002386261088503789,0.0023845237303641116,0.002382790161446948,0.0023810603679983106,0.002379334336334003,0.002377612052839167,0.0023758935039678297,0.0023741786762424572,0.0023724675562535108,0.002370760130659005,0.002369056386184073,0.002367356309620532,0.0023656598878264517,0.0023639671077257305,0.00236227795630767,0.002360592420626556,0.0023589104878012413,0.002357232145014732,0.0023555573795137784,0.002353886178608467,0.002352218529671817,0.00235055442013938,0.00234889383750884,0.002347236769339624,0.0023455832032525047,0.0023439331269292166,0.002342286528112067,0.0023406433946035568,0.0023390037142659993,0.002337367475021143,0.0023357346648497997,0.002334105271791472,0.002332479283943987,0.00233085668946313,0.002329237476562281,0.002327621633512058,0.002326009148639959,0.0023244000103300054,0.002322794207022395,0.0023211917272131484,0.0023195925594537673,0.0023179966923508877,0.002316404114565941,0.0023148148148148147,0.0023132287818675165,0.002311646004547841,0.00231006647173304,0.0023084901723534933,0.002306917095392382,0.0023053472298853674,0.0023037805649202677,0.0023022170896367417,0.0023006567932259696,0.0022990996649303428,0.002297545694043149,0.0022959948699082656,0.002294447181919851,0.0022929026195220407,0.0022913611722086454,0.0022898228295228492,0.002288287581056914,0.0022867554164518822,0.0022852263253972833,0.0022837002976308428,0.002282177322938192,0.0022806573911525836,0.0022791404921546025,0.0022776266158718865,0.002276115752278843,0.0022746078913963718,0.0022731030232915873,0.0022716011380775436,0.0022701022259129624,0.0022686062770019616,0.0022671132815937863,0.002265623229982543,0.0022641361125069325,0.002262651919549989,0.0022611706415388176,0.0022596922689443353,0.002258216792281013,0.0022567442021066216,0.0022552744890219755,0.002253807643670684,0.0022523436567388976,0.0022508825189550617,0.0022494242210896703,0.00224796875395502,0.002246516108404967,0.0022450662753346865,0.002243619245680432,0.0022421750104192977,0.0022407335605689836,0.002239294887187558,0.0022378589813732276,0.0022364258342641038,0.0022349954370379736,0.0022335677809120725,0.002232142857142857,0.0022307206570257804,0.002229301171895068,0.002227884393123497,0.0022264703121221766,0.0022250589203403263,0.0022236502092650625,0.002222244170421181,0.002220840795370942,0.0022194400757138593,0.002218042003086488,0.0022166465691622144,0.00221525376565105,0.0022138635842994204,0.002212476016889965,0.002211091055241328,0.002209708691207961,0.0022083289166799167,0.002206951723582652,0.0022055771038768297,0.0022042050495581196,0.002202835552657004,0.002201468605238584,0.002200104199402384,0.002198742327282162,0.002197382981045719,0.002196026152894708,0.0021946718350644486,0.002193320019823739,0.0021919706994746697,0.0021906238663524425,0.0021892795128251835,0.002187937631293765,0.0021865982141916237,0.00218526125398458,0.002183926743170663,0.0021825946742799317,0.0021812650398743,0.0021799378325473616,0.0021786130449242182,0.0021772906696613053,0.002175970699446223,0.0021746531269975656,0.002173337945064753,0.002172025146427862,0.002170714723897462,0.0021694066703144476,0.0021681009785498757,0.0021667976415048014,0.0021654966521101157,0.0021641980033263865,0.002162901688143696,0.0021616076995814833,0.002160316030688386,0.0021590266745420837,0.0021577396242491416,0.002156454872944857,0.0021551724137931034,0.00215389223998618,0.0021526143447446583,0.002151338721317232,0.002150065362980567,0.002148794263039153,0.0021475254148251547,0.002146258811698266,0.0021449944470455632,0.0021437323142813607,0.0021424724068470655,0.0021412147182110364,0.0021399592418684396,0.002138705971341109,0.0021374549001774044,0.002136206021952073,0.0021349593302661097,0.0021337148187466214,0.002132472481046689,0.0021312323108452296,0.0021299943018468657,0.002128758447781786,0.0021275247424056174,0.0021262931794992865,0.0021250637528688935,0.0021238364563455777,0.002122611283785389,0.0021213882290691583,0.0021201672861023697,0.0021189484488150323,0.0021177317111615536,0.002116517067120614,0.00211530451069504,0.0021140940359116824,0.0021128856368212916,0.0021116793074983935,0.0021104750420411697,0.0021092728345713345,0.002108072679234015,0.0021068745701976316,0.0021056785016537786,0.0021044844678171056,0.0021032924629252017,0.0021021024812384764,0.0021009145170400446,0.002099728564635612,0.0020985446183533585,0.002097362672543826,0.0020961827215798053,0.0020950047598562215,0.0020938287817900253,0.002092654781820078,0.002091482754407046,0.002090312694033285,0.0020891445952027363,0.0020879784524408156,0.002086814260294306,0.0020856520133312496,0.002084491706140844,0.0020833333333333333,0.002082176889539905,0.002081022369412584,0.0020798697676241307,0.0020787190788679353,0.0020775702978579175,0.002076423419328423,0.002075278438034123,0.0020741353487499126,0.002072994146270811,0.0020718548254118623,0.0020707173810080364,0.002069581807914131,0.0020684481010046726,0.0020673162551738205,0.0020661862653352696,0.0020650581264221556,0.0020639318333869577,0.002062807381201405,0.0020616847648563816,0.0020605639793618343,0.0020594450197466774,0.002058327881058701,0.002057212558364479,0.002056099046749278,0.0020549873413169663,0.0020538774371899214,0.002052769329508944,0.0020516630134331647,0.0020505584841399582,0.002049455736824853,0.002048354766701444,0.0020472555690013074,0.00204615813897391,0.002045062471886526,0.0020439685630241518,0.002042876407689417,0.0020417860012025037,0.00204069733890106,0.0020396104161401175,0.002038525228292007,0.0020374417707462763,0.0020363600389096083,0.002035280028205738,0.0020342017340753728,0.0020331251519761107,0.00203205027738236,0.0020309771057852584,0.0020299056326925965,0.002028835853628736,0.002027767764134532,0.0020267013597672547,0.0020256366361005138,0.002024573588724178,0.0020235122132443006,0.0020224525052830425,0.0020213944604785964,0.002020338074485112,0.00201928334297262,0.002018230261626958,0.0020171788261496965,0.0020161290322580645,0.002015080875684878,0.0020140343521784657,0.0020129894575025963,0.0020119461874364077,0.002010904537774334,0.002009864504326036,0.0020088260829163283,0.002007789269385111,0.0020067540595872986,0.00200572044939275,0.0020046884346862004,0.002003658011367192,0.0020026291753500046,0.0020016019225635893,0.0020005762489514996,0.001999552150471825,0.0019985296230971227,0.0019975086628143536,0.0019964892656248122,0.0019954714275440652,0.0019944551446018834,0.0019934404128421775,0.0019924272283229323,0.001991415587116144,0.0019904054853077564,0.0019893969189975946,0.0019883898842993054,0.001987384377340292,0.0019863803942616505,0.001985377931218112,0.0019843769843779766,0.0019833775499230526,0.0019823796240485973,0.0019813832029632545,0.0019803882828889935,0.0019793948600610512,0.00197840293072787,0.0019774124911510396,0.001976423537605237],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"group=512:200\\u003cbr\\u003estep=%{x}\\u003cbr\\u003elr=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"512:200\",\"line\":{\"color\":\"#FF7F0E\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"512:200\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000],\"xaxis\":\"x\",\"y\":[0.000015625,0.000015625,0.00003125,0.000046875,0.0000625,0.000078125,0.00009375,0.000109375,0.000125,0.00014062500000000002,0.00015625,0.00017187500000000002,0.0001875,0.00020312500000000002,0.00021875,0.00023437500000000002,0.00025,0.000265625,0.00028125000000000003,0.000296875,0.0003125,0.000328125,0.00034375000000000003,0.00035937500000000005,0.000375,0.000390625,0.00040625000000000004,0.000421875,0.0004375,0.000453125,0.00046875000000000004,0.000484375,0.0005,0.000515625,0.00053125,0.000546875,0.0005625000000000001,0.0005781250000000001,0.00059375,0.000609375,0.000625,0.000640625,0.00065625,0.0006718750000000001,0.0006875000000000001,0.000703125,0.0007187500000000001,0.000734375,0.00075,0.0007656250000000001,0.00078125,0.000796875,0.0008125000000000001,0.0008281250000000001,0.00084375,0.0008593750000000001,0.000875,0.0008906249999999999,0.00090625,0.0009218750000000001,0.0009375000000000001,0.0009531250000000001,0.00096875,0.000984375,0.001,0.001015625,0.00103125,0.001046875,0.0010625,0.001078125,0.00109375,0.0011093750000000001,0.0011250000000000001,0.001140625,0.0011562500000000002,0.0011718750000000002,0.0011875,0.0012031250000000002,0.00121875,0.001234375,0.00125,0.001265625,0.00128125,0.001296875,0.0013125,0.001328125,0.0013437500000000001,0.0013593750000000001,0.0013750000000000001,0.0013906250000000002,0.00140625,0.001421875,0.0014375000000000002,0.0014531250000000002,0.00146875,0.001484375,0.0015,0.001515625,0.0015312500000000003,0.001546875,0.0015625,0.001578125,0.00159375,0.0016093750000000001,0.0016250000000000001,0.0016406250000000002,0.0016562500000000002,0.001671875,0.0016875,0.0017031250000000002,0.0017187500000000002,0.001734375,0.00175,0.001765625,0.0017812499999999998,0.0017968750000000003,0.0018125,0.001828125,0.0018437500000000001,0.001859375,0.0018750000000000001,0.0018906250000000002,0.0019062500000000002,0.001921875,0.0019375,0.001953125,0.00196875,0.001984375,0.002,0.002015625,0.00203125,0.002046875,0.0020625,0.002078125,0.00209375,0.002109375,0.002125,0.002140625,0.00215625,0.002171875,0.0021875,0.0022031250000000002,0.0022187500000000002,0.0022343750000000002,0.0022500000000000003,0.0022656250000000003,0.00228125,0.002296875,0.0023125000000000003,0.0023281250000000003,0.0023437500000000003,0.002359375,0.002375,0.002390625,0.0024062500000000004,0.002421875,0.0024375,0.002453125,0.00246875,0.0024843750000000005,0.0025,0.002515625,0.00253125,0.002546875,0.0025625,0.002578125,0.00259375,0.002609375,0.002625,0.002640625,0.00265625,0.002671875,0.0026875000000000002,0.0027031250000000002,0.0027187500000000002,0.002734375,0.0027500000000000003,0.0027656250000000003,0.0027812500000000003,0.002796875,0.0028125,0.002828125,0.00284375,0.002859375,0.0028750000000000004,0.0028906250000000004,0.0029062500000000004,0.0029218750000000004,0.0029375,0.002953125,0.00296875,0.002984375,0.003,0.003015625,0.00303125,0.0030468750000000005,0.0030625000000000006,0.003078125,0.00309375,0.003109375,0.003125,0.003117216675336353,0.003109491219406216,0.0031018229186591576,0.003094211071802107,0.0030866549895299674,0.0030791539942634162,0.0030717074198936905,0.0030643146115341257,0.003056974925278241,0.0030496877279641665,0.003042452396945222,0.003035268319866451,0.003028134894446933,0.0030210515282676994,0.0030140176385650757,0.003007032652029301,0.003000096004608246,0.0029932071413160985,0.0029863655160468536,0.002979570591392476,0.0029728218384655882,0.0029661187367265593,0.0029594607738148647,0.002952847445384588,0.002946278254943948,0.002939752713698742,0.002933270340399576,0.002926830661192794,0.002920433209474986,0.0029140775257509807,0.0029077631574952216,0.0029014896590164353,0.002895256591325497,0.0028890635220064015,0.0028829100250902665,0.0028767956809322604,0.0028707200760914086,0.0028646828032131604,0.0028586834609146765,0.002852721653672741,0.002846796991714231,0.0028409090909090914,0.0028350575726657154,0.0028292420638287045,0.0028234621965789104,0.0028177176083357264,0.002812007941661547,0.002806332844168358,0.0028006919684263804,0.002795084971874737,0.0027895115167340737,0.0027839712699210878,0.002778463902964919,0.002772989091925356,0.002767546517312798,0.0027621358640099515,0.0027567568211951934,0.0027514090822675745,0.0027460923447734176,0.0027408063103344666,0.0027355506845775533,0.002730325177065744,0.002725129501230921,0.002719963374307779,0.0027148265172691837,0.0027097186547628753,0.002704639515049472,0.0026995888299417505,0.002694566334745168,0.002689571768199595,0.002684604872422236,0.0026796653928517007,0.0026747530781932056,0.0026698676803648784,0.0026650089544451305,0.0026601766586210893,0.002655370554138046,0.002650590405249909,0.0026458359791706357,0.0026411070460266146,0.0026364033788099863,0.002631724753332872,0.002627070948182491,0.002622441744677154,0.002617836926823097,0.0026132562812721588,0.002608699597280257,0.002604166666666667,0.002599657283774072,0.002595171245429374,0.0025907083509052447,0.0025862684018824003,0.0025818512024125863,0.002577456558882258,0.002573084279976932,0.0025687341766462077,0.002564406062069432,0.0025600997516220018,0.0025558150628422834,0.002551551815399144,0.0025473098310600704,0.0025430889336598736,0.002538888949069961,0.0025347097051681648,0.002530551031809113,0.0025264127607951352,0.002522294725847693,0.0025181967625793134,0.0025141187084660303,0.002510060402820309,0.002506021686764455,0.002502002403204487,0.002498002396804474,0.0024940215139613196,0.002490059602779987,0.0024861165130491566,0.002482192096217305,0.0024782862053692005,0.0024743986952027995,0.0024705294220065464,0.0024666782436370575,0.00246284501949719,0.0024590296105144807,0.0024552318791199565,0.0024514516892273006,0.002447688906212367,0.002443943396893047,0.00244021502950947,0.0024365036737045327,0.0024328092005047592,0.002429131482301474,0.0024254703928322905,0.002421825807162902,0.002418197601669178,0.0024145856540195494,0.0024109898431576866,0.002407410049285454,0.002403846153846154,0.0024002980395080266,0.002396765590148033,0.0023932486908358865,0.0023897472278183516,0.002386261088503789,0.002382790161446948,0.0023793343363340035,0.0023758935039678297,0.0023724675562535108,0.002369056386184073,0.0023656598878264517,0.0023622779563076705,0.0023589104878012413,0.0023555573795137784,0.0023522185296718174,0.0023488938375088404,0.0023455832032525047,0.0023422865281120674,0.0023390037142659993,0.0023357346648497997,0.0023324792839439874,0.002329237476562281,0.002326009148639959,0.002322794207022395,0.0023195925594537673,0.002316404114565941,0.0023132287818675165,0.00231006647173304,0.002306917095392382,0.0023037805649202677,0.00230065679322597,0.002297545694043149,0.0022944471819198514,0.0022913611722086454,0.002288287581056914,0.0022852263253972833,0.0022821773229381925,0.0022791404921546025,0.0022761157522788434,0.0022731030232915873,0.002270102225912963,0.0022671132815937868,0.0022641361125069325,0.0022611706415388176,0.0022582167922810133,0.002255274489021976,0.0022523436567388976,0.0022494242210896707,0.002246516108404967,0.002243619245680432,0.0022407335605689836,0.002237858981373228,0.0022349954370379736,0.0022321428571428575,0.002229301171895068,0.0022264703121221766,0.002223650209265063,0.0022208407953709423,0.002218042003086488,0.00221525376565105,0.002212476016889965,0.0022097086912079614,0.002206951723582652,0.0022042050495581196,0.0022014686052385843,0.0021987423272821624,0.002196026152894708,0.002193320019823739,0.0021906238663524425,0.0021879376312937656,0.00218526125398458,0.0021825946742799317,0.002179937832547362,0.0021772906696613053,0.0021746531269975656,0.002172025146427862,0.002169406670314448,0.0021667976415048014,0.0021641980033263865,0.0021616076995814833,0.0021590266745420837,0.002156454872944857,0.00215389223998618,0.002151338721317232,0.0021487942630391533,0.002146258811698266,0.0021437323142813607,0.0021412147182110364,0.002138705971341109,0.002136206021952073,0.002133714818746622,0.00213123231084523,0.002128758447781786,0.002126293179499287,0.0021238364563455777,0.0021213882290691587,0.0021189484488150327,0.002116517067120614,0.0021140940359116824,0.002111679307498394,0.0021092728345713345,0.0021068745701976316,0.0021044844678171056,0.0021021024812384764,0.002099728564635612,0.002097362672543826,0.002095004759856222,0.0020926547818200785,0.0020903126940332853,0.0020879784524408156,0.0020856520133312496,0.0020833333333333333,0.002081022369412584,0.0020787190788679353,0.002076423419328423,0.0020741353487499126,0.0020718548254118623,0.002069581807914131,0.0020673162551738205,0.002065058126422156,0.002062807381201405,0.0020605639793618348,0.002058327881058701,0.002056099046749278,0.002053877437189922,0.002051663013433165,0.0020494557368248532,0.0020472555690013074,0.0020450624718865267,0.002042876407689417,0.00204069733890106,0.002038525228292007,0.0020363600389096083,0.0020342017340753728,0.00203205027738236,0.002029905632692597,0.002027767764134532,0.0020256366361005138,0.0020235122132443006,0.002021394460478597,0.00201928334297262,0.002017178826149696,0.0020150808756848786,0.0020129894575025968,0.002010904537774334,0.0020088260829163283,0.0020067540595872986,0.002004688434686201,0.0020026291753500046,0.0020005762489514996,0.001998529623097123,0.0019964892656248122,0.001994455144601884,0.0019924272283229323,0.0019904054853077564,0.001988389884299306,0.001986380394261651,0.0019843769843779766,0.0019823796240485978,0.0019803882828889935,0.00197840293072787,0.0019764235376052374,0.001974450073770511,0.001972482509680635,0.001970520815998224,0.0019685649635897253,0.001966614923523602,0.001964670667068536,0.0019627321656916492,0.0019607993910567456,0.001958872315022571,0.0019569509096410923,0.0019550351471557953,0.0019531250000000004,0.001951220440795196,0.0019493214423493917,0.001947427977655487,0.0019455400198896576,0.0019436575424097591,0.0019417805187537504,0.001939908922638128,0.001938042727956382,0.0019361819087774681,0.0019343264393442904,0.0019324762940722074,0.0019306314475475484,0.001928791874526149,0.0019269575499318982,0.0019251284488553044,0.0019233045465520742,0.0019214858184417054,0.0019196722401060976,0.0019178637872881738,0.0019160604358905182,0.0019142621619740278,0.001912468941756577,0.0019106807516116972,0.0019088975680672693,0.0019071193678042297,0.0019053461276552887,0.0019035778246036647,0.001901814435781827,0.0019000559384702552,0.0018983023100962097,0.001896553528232514,0.0018948095705963515,0.0018930704150480712,0.0018913360395900077,0.001889606422365314,0.001887881541656803,0.0018861613758858029,0.0018844459036110228,0.0018827351035274314,0.001881028954465144,0.0018793274353883242,0.001877630525394093,0.0018759382037114509,0.0018742504497002098,0.0018725672428499367,0.001870888562778905,0.00186921438923306,0.00186754470208499,0.001865879481332913,0.0018642187070996676,0.0018625623596317182,0.0018609104192981677,0.0018592628665897802,0.0018576196821180127,0.0018559808466140583,0.001854346340927896,0.001852716146027351,0.001851090242997164,0.0018494686130380693,0.0018478512374658833,0.0018462380977105975,0.0018446291753154854,0.0018430244519362143,0.0018414239093399675,0.0018398275294045745,0.0018382352941176473,0.0018366471855757293,0.0018350631859834485,0.00183348327765268,0.0018319074430017163,0.0018303356645544462,0.0018287679249395401,0.0018272042068896441,0.0018256444932405814,0.0018240887669305594,0.0018225370109993886,0.0018209892085877032,0.0018194453429361938,0.001817905397384844,0.0018163693553721763,0.0018148372004345031,0.001813308916205186,0.0018117844864139012,0.0018102638948859133,0.0018087471255413521,0.0018072341623945009,0.0018057249895530865,0.0018042195912175807,0.001802717951680503,0.0018012200553257343,0.0017997258866278335,0.0017982354301513625,0.0017967486705502158,0.0017952655925669568,0.001793786181032161,0.001792310420863764,0.0017908382970664152,0.0017893697947308383,0.0017879048990331972,0.0017864435952344672,0.0017849858686798121,0.0017835317047979675,0.0017820810891006284,0.0017806340071818431,0.0017791904447174126,0.0017777503874642948,0.0017763138212600145,0.0017748807320220777,0.001773451105747393,0.001772024928511696,0.0017706021864689798,0.0017691828658509309,0.001767766952966369,0.0017663544342006923,0.0017649452960153285,0.0017635395249471885,0.001762137107608128,0.0017607380306844096,0.001759342280936174,0.0017579498451969126,0.0017565607103729461,0.0017551748634429079,0.0017537922914572304,0.0017524129815376386,0.0017510369208766435,0.0017496640967370448,0.0017482944964514358,0.0017469281074217109,0.0017455649171185803,0.0017442049130810863,0.0017428480829161264,0.0017414944142979775,0.0017401438949678266,0.0017387965127333039,0.0017374522554680207,0.001736111111111111,0.0017347730676667782,0.0017334381132038412,0.0017321062358552916,0.001730777423817848,0.0017294516653515173,0.0017281289487791596,0.0017268092624860552,0.0017254925949194775,0.0017241789345882666,0.0017228682700624104,0.001721560589972624,0.0017202558830099386,0.0017189541379252877,0.0017176553435291023,0.0017163594886909054,0.0017150665623389117,0.0017137765534596305,0.0017124894510974716,0.0017112052443543548,0.0017099239223893213,0.0017086454744181506,0.0017073698897129785,0.001706097157601919,0.0017048272674686905,0.001703560208752242,0.0017022959709463853,0.0017010345435994293,0.0016997759163138164,0.0016985200787457625,0.0016972670206049012,0.0016960167316539287,0.0016947692017082515,0.0016935244206356403,0.0016922823783558822,0.0016910430648404402,0.00168980647011211,0.0016885725842446851,0.0016873413973626217,0.001686112899640706,0.0016848870813037254,0.0016836639326261419,0.0016824434439317673,0.001681225605593443,0.00168001040803272,0.0016787978417195425,0.0016775878971719345,0.0016763805649556878,0.0016751758356840544,0.0016739737000174384,0.0016727741486630915,0.001671577172374814,0.0016703827619526524,0.001669190908242605,0.0016680016021363246,0.0016668148345708282,0.0016656305965282066,0.0016644488790353359,0.0016632696731635921,0.0016620929700285688,0.0016609187607897933,0.0016597470366504525,0.0016585777888571101,0.0016574110086994378,0.0016562466875099375,0.001655084816663675,0.00165392538757801,0.0016527683917123286,0.0016516138205677814,0.0016504616656870196,0.001649311918653936,0.001648164571093406,0.001647019614671031,0.0016458770410928854,0.001644736842105263,0.001643599009494428,0.0016424635350863648,0.0016413304107465321,0.001640199628379619,0.0016390711799293002,0.0016379450573779973,0.0016368212527466377,0.001635699758094418,0.0016345805655185671,0.0016334636671541149,0.001632349055173657,0.001631236721787127,0.001630126659241566,0.0016290188598208966,0.0016279133158456978,0.0016268100196729798,0.0016257089636959646,0.0016246101403438636,0.0016235135420816598,0.0016224191614098908,0.0016213269908644334,0.0016202370230162897,0.0016191492504713746,0.0016180636658703054,0.0016169802618881935,0.001615899031234435,0.0016148199666525058,0.001613743060919757,0.0016126683068472124,0.0016115956972793648,0.0016105252250939789,0.0016094568832018899,0.0016083906645468085,0.0016073265621051242,0.00160626456888571,0.0016052046779297317,0.0016041468823104544,0.0016030911751330533,0.0016020375495344253,0.001600985998683,0.001599936515778556,0.001598889094052034,0.0015978437267653554,0.0015968004072112376,0.0015957591287130168,0.001594719884624465,0.0015936826683296149,0.00159264747324258,0.0015916142928073817,0.0015905831204977737,0.0015895539498170682,0.0015885267742979654,0.0015875015875023814,0.00158647838302128,0.0015854571544745035,0.001584437895510606,0.0015834205998066873,0.0015824052610682292,0.0015813918730289297,0.0015803804294505426,0.0015793709241227155,0.0015783633508628294,0.0015773577035158401,0.00157635397595412,0.001575352162077301,0.0015743522558121202,0.0015733542511122628,0.0015723581419582113,0.001571363922357091,0.001570371586342519,0.0015693811279744545,0.001568392541339049,0.0015674058205484972,0.0015664209597408925,0.0015654379530800763,0.0015644567947554967,0.0015634774789820623,0.0015625,0.0015615243520747115,0.0015605505294966325,0.0015595785265810928,0.0015586083376681766,0.0015576399571225839,0.0015566733793334934,0.001555708598714426,0.001554745609703108,0.0015537844067613387,0.0015528249843748542,0.0015518673370531959,0.0015509114593295788,0.0015499573457607588,0.0015490049909269055,0.0015480543894314685,0.0015471055359010536,0.0015461584249852921,0.0015452130513567148,0.0015442694097106276,0.0015433274947649837,0.0015423873012602627,0.001541448823959344,0.0015405120576473873,0.0015395769971317081,0.0015386436372416593,0.0015377119728285091,0.0015367819987653234,0.0015358537099468452,0.0015349271012893798,0.0015340021677306749,0.0015330789042298067,0.0015321573057670628,0.001531237367343829,0.0015303190839824742,0.001529402450726239,0.0015284874626391204,0.0015275741148057637,0.0015266624023313486,0.0015257523203414812,0.0015248438639820833,0.0015239370284192836,0.0015230318088393106,0.0015221282004483846,0.001521226198472611,0.0015203257981578748,0.001519426994769735,0.0015185297835933205,0.0015176341599332254,0.0015167401191134068,0.0015158476564770813,0.001514956767386624,0.0015140674472234664,0.001513179691387997,0.0015122934952994601,0.0015114088543958578,0.0015105257641338497,0.001509644219988656,0.0015087642174539612,0.0015078857520418151,0.0015070088192825379,0.0015061334147246249,0.00150525953393465,0.001504387172497175,0.0015035163260146505,0.0015026469901073282,0.001501779160413165,0.0015009128325877317,0.001500048002304123,0.0014991846652528647,0.0014983228171418254,0.0014974624536961256,0.0014966035706580492,0.0014957461637869545,0.0014948902288591873,0.0014940357616679922,0.0014931827580234268,0.0014923312137522752,0.0014914811246979616,0.0014906324867204656,0.001489785295696238,0.0014889395475181158,0.001488095238095238,0.0014872523633529654,0.0014864109192327941,0.001485570901692276,0.0014847323067049374,0.0014838951302601953,0.0014830593683632797,0.0014822250170351532,0.0014813920723124288,0.001480560530247295,0.0014797303869074324,0.0014789016383759408,0.0014780742807512567,0.0014772483101470797,0.001476423722692294,0.0014756005145308928,0.0014747786818219023,0.001473958220739307,0.001473139127471974,0.00147232139822358,0.0014715050292125349,0.0014706900166719117,0.001469876356849371,0.001469064046007089,0.0014682530804216861,0.001467443456384155,0.001466635170199788,0.0014658282181881082,0.0014650225966827985,0.0014642183020316306,0.001463415330596397,0.0014626136787528408,0.0014618133428905876,0.0014610143194130763,0.001460216604737493,0.0014594201952947015,0.0014586250875291771,0.0014578312778989401,0.0014570387628754903,0.001456247538943739,0.001455457602601945,0.0014546689503616493,0.0014538815787476108,0.0014530954842977412,0.001452310663563041,0.0014515271131075368,0.0014507448295082177,0.0014499638093549722,0.0014491840492505258,0.0014484055458103798,0.0014476282956627485,0.001446852295448498,0.001446077541821086,0.001445304031446501,0.0014445317610032008,0.0014437607271820547,0.0014429909266862819,0.0014422223562313933,0.0014414550125451332,0.0014406888923674192,0.0014399239924502859,0.0014391603095578252,0.0014383978404661302,0.001437636581963238,0.0014368765308490716,0.0014361176839353844,0.0014353600380457043,0.001434603590015277,0.0014338483366910112,0.0014330942749314227,0.0014323414016065802,0.0014315897135980507,0.0014308392077988443,0.0014300898811133614,0.0014293417304573383,0.001428594752757795,0.0014278489449529809,0.0014271043039923222,0.0014263608268363704,0.0014256185104567492,0.0014248773518361038,0.0014241373479680485,0.0014233984958571155,0.0014226607925187046,0.0014219242349790316,0.001421188820275079,0.0014204545454545457,0.001419721407575796,0.001418989403707812,0.001418258530930143,0.0014175287863328577,0.0014168001670164941,0.0014160726700920118,0.001415346292680745,0.0014146210319143523,0.0014138968849347715,0.0014131738488941704,0.0014124519209549023,0.0014117310982894552,0.001411011378080409,0.001410292757520388,0.0014095752338120146,0.0014088588041678632,0.0014081434658104156,0.0014074292159720159,0.001406716051894824,0.0014060039708307735,0.0014052929700415248,0.001404583046798421,0.0014038741983824462,0.001403166422084179,0.0014024597152037508,0.001401754075050802,0.0014010494989444388,0.0014003459842131902,0.0013996435281949666,0.0013989421282370163,0.001398241781695884,0.0013975424859373686],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"group=512:400\\u003cbr\\u003estep=%{x}\\u003cbr\\u003elr=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"512:400\",\"line\":{\"color\":\"#2CA02C\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"512:400\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000],\"xaxis\":\"x\",\"y\":[5.524271728019903e-6,5.524271728019903e-6,0.000011048543456039807,0.00001657281518405971,0.000022097086912079613,0.000027621358640099516,0.00003314563036811942,0.00003866990209613932,0.000044194173824159226,0.00004971844555217913,0.00005524271728019903,0.00006076698900821893,0.00006629126073623884,0.00007181553246425875,0.00007733980419227865,0.00008286407592029854,0.00008838834764831845,0.00009391261937633836,0.00009943689110435826,0.00010496116283237816,0.00011048543456039807,0.00011600970628841796,0.00012153397801643786,0.00012705824974445777,0.00013258252147247768,0.0001381067932004976,0.0001436310649285175,0.00014915533665653738,0.0001546796083845573,0.0001602038801125772,0.00016572815184059709,0.000171252423568617,0.0001767766952966369,0.00018230096702465682,0.00018782523875267673,0.0001933495104806966,0.00019887378220871652,0.0002043980539367364,0.0002099223256647563,0.00021544659739277622,0.00022097086912079613,0.00022649514084881604,0.00023201941257683592,0.00023754368430485583,0.00024306795603287572,0.0002485922277608956,0.00025411649948891554,0.0002596407712169354,0.00026516504294495536,0.00027068931467297524,0.0002762135864009952,0.00028173785812901506,0.000287262129857035,0.0002927864015850548,0.00029831067331307476,0.00030383494504109465,0.0003093592167691146,0.00031488348849713447,0.0003204077602251544,0.0003259320319531743,0.00033145630368119417,0.00033698057540921405,0.000342504847137234,0.0003480291188652539,0.0003535533905932738,0.0003590776623212937,0.00036460193404931363,0.0003701262057773335,0.00037565047750535345,0.00038117474923337333,0.0003866990209613932,0.00039222329268941315,0.00039774756441743304,0.00040327183614545287,0.0004087961078734728,0.0004143203796014927,0.0004198446513295126,0.0004253689230575325,0.00043089319478555244,0.0004364174665135723,0.00044194173824159226,0.00044746600996961215,0.0004529902816976321,0.00045851455342565197,0.00046403882515367185,0.0004695630968816918,0.00047508736860971167,0.0004806116403377316,0.00048613591206575144,0.0004916601837937713,0.0004971844555217912,0.0005027087272498112,0.0005082329989778311,0.000513757270705851,0.0005192815424338708,0.0005248058141618908,0.0005303300858899107,0.0005358543576179306,0.0005413786293459505,0.0005469029010739704,0.0005524271728019904,0.0005579514445300102,0.0005634757162580301,0.00056899998798605,0.00057452425971407,0.0005800485314420898,0.0005855728031701097,0.0005910970748981296,0.0005966213466261495,0.0006021456183541694,0.0006076698900821893,0.0006131941618102092,0.0006187184335382292,0.000624242705266249,0.0006297669769942689,0.0006352912487222888,0.0006408155204503088,0.0006463397921783287,0.0006518640639063486,0.0006573883356343685,0.0006629126073623883,0.0006684368790904082,0.0006739611508184281,0.0006794854225464481,0.000685009694274468,0.0006905339660024879,0.0006960582377305077,0.0007015825094585276,0.0007071067811865476,0.0007126310529145675,0.0007181553246425874,0.0007236795963706073,0.0007292038680986273,0.0007347281398266471,0.000740252411554667,0.0007457766832826869,0.0007513009550107069,0.0007568252267387268,0.0007623494984667467,0.0007678737701947666,0.0007733980419227864,0.0007789223136508064,0.0007844465853788263,0.0007899708571068462,0.0007954951288348661,0.0008010194005628858,0.0008065436722909057,0.0008120679440189257,0.0008175922157469456,0.0008231164874749655,0.0008286407592029854,0.0008341650309310054,0.0008396893026590252,0.0008452135743870451,0.000850737846115065,0.0008562621178430849,0.0008617863895711049,0.0008673106612991248,0.0008728349330271447,0.0008783592047551645,0.0008838834764831845,0.0008894077482112044,0.0008949320199392243,0.0009004562916672442,0.0009059805633952642,0.000911504835123284,0.0009170291068513039,0.0009225533785793238,0.0009280776503073437,0.0009336019220353637,0.0009391261937633836,0.0009446504654914035,0.0009501747372194233,0.0009556990089474433,0.0009612232806754632,0.0009667475524034831,0.0009722718241315029,0.0009777960958595228,0.0009833203675875426,0.0009888446393155625,0.0009943689110435824,0.0009998931827716025,0.0010054174544996224,0.0010109417262276423,0.0010164659979556622,0.001021990269683682,0.001027514541411702,0.0010330388131397218,0.0010385630848677417,0.0010440873565957616,0.0010496116283237817,0.0010551359000518015,0.0010606601717798214,0.0010661844435078413,0.0010717087152358612,0.001077232986963881,0.001082757258691901,0.0010882815304199208,0.0010938058021479407,0.0010993300738759608,0.0011048543456039807,0.0011103786173320006,0.0011159028890600205,0.0011214271607880404,0.0011269514325160602,0.0011324757042440801,0.0011379999759721,0.00114352424770012,0.00114904851942814,0.0011545727911561597,0.0011600970628841795,0.0011656213346121994,0.0011711456063402193,0.0011766698780682392,0.0011821941497962593,0.0011877184215242792,0.001193242693252299,0.001198766964980319,0.0012042912367083388,0.0012098155084363587,0.0012153397801643786,0.0012208640518923985,0.0012263883236204184,0.0012319125953484385,0.0012374368670764583,0.0012429611388044782,0.001248485410532498,0.001254009682260518,0.0012595339539885379,0.0012650582257165578,0.0012705824974445776,0.0012761067691725977,0.0012816310409006176,0.0012871553126286375,0.0012926795843566574,0.0012982038560846773,0.0013037281278126971,0.001309252399540717,0.001314776671268737,0.0013203009429967568,0.0013258252147247767,0.0013313494864527966,0.0013368737581808164,0.0013423980299088363,0.0013479223016368562,0.001353446573364876,0.0013589708450928962,0.001364495116820916,0.001370019388548936,0.0013755436602769558,0.0013810679320049757,0.0013865922037329956,0.0013921164754610155,0.0013976407471890354,0.0014031650189170553,0.0014086892906450754,0.0014142135623730952,0.0014197378341011151,0.001425262105829135,0.0014307863775571549,0.0014363106492851748,0.0014418349210131947,0.0014473591927412145,0.0014528834644692344,0.0014584077361972545,0.0014639320079252744,0.0014694562796532943,0.0014749805513813142,0.001480504823109334,0.001486029094837354,0.0014915533665653738,0.0014970776382933937,0.0015026019100214138,0.0015081261817494337,0.0015136504534774536,0.0015191747252054735,0.0015246989969334933,0.0015302232686615132,0.001535747540389533,0.001541271812117553,0.0015467960838455729,0.001552320355573593,0.0015578446273016129,0.0015633688990296327,0.0015688931707576526,0.0015744174424856725,0.0015799417142136924,0.0015854659859417123,0.0015909902576697321,0.0015965145293977518,0.0016020388011257717,0.0016075630728537916,0.0016130873445818115,0.0016186116163098316,0.0016241358880378514,0.0016296601597658713,0.0016351844314938912,0.001640708703221911,0.001646232974949931,0.0016517572466779509,0.0016572815184059707,0.0016628057901339906,0.0016683300618620107,0.0016738543335900306,0.0016793786053180505,0.0016849028770460704,0.0016904271487740903,0.0016959514205021101,0.00170147569223013,0.00170699996395815,0.0017125242356861698,0.0017180485074141899,0.0017235727791422098,0.0017290970508702297,0.0017346213225982495,0.0017401455943262694,0.0017456698660542893,0.0017511941377823092,0.001756718409510329,0.001762242681238349,0.001767766952966369,0.001773291224694389,0.0017788154964224088,0.0017843397681504287,0.0017898640398784486,0.0017953883116064685,0.0018009125833344884,0.0018064368550625082,0.0018119611267905283,0.0018174853985185482,0.001823009670246568,0.001828533941974588,0.0018340582137026079,0.0018395824854306277,0.0018451067571586476,0.0018506310288866675,0.0018561553006146874,0.0018616795723427075,0.0018672038440707274,0.0018727281157987473,0.0018782523875267671,0.001883776659254787,0.001889300930982807,0.0018948252027108268,0.0019003494744388467,0.0019058737461668666,0.0019113980178948867,0.0019169222896229065,0.0019224465613509264,0.0019279708330789463,0.0019334951048069662,0.001939019376534986,0.0019445436482630057,0.0019500679199910256,0.0019555921917190455,0.0019611164634470656,0.0019666407351750853,0.0019721650069031054,0.001977689278631125,0.001983213550359145,0.001988737822087165,0.001994262093815185,0.001999786365543205,0.0020053106372712247,0.0020108349089992448,0.0020163591807272644,0.0020218834524552845,0.002027407724183304,0.0020329319959113243,0.002038456267639344,0.002043980539367364,0.002049504811095384,0.002055029082823404,0.002060553354551424,0.0020660776262794436,0.0020716018980074637,0.0020771261697354834,0.0020826504414635035,0.002088174713191523,0.0020936989849195432,0.0020992232566475633,0.002104747528375583,0.002110271800103603,0.0021157960718316228,0.002121320343559643,0.0021268446152876625,0.0021323688870156826,0.0021378931587437023,0.0021434174304717224,0.0021489417021997425,0.002154465973927762,0.0021599902456557823,0.002165514517383802,0.002171038789111822,0.0021765630608398417,0.002182087332567862,0.0021876116042958815,0.0021931358760239016,0.0021986601477519217,0.0022041844194799413,0.0022097086912079614,0.002206951723582652,0.0022042050495581196,0.0022014686052385843,0.0021987423272821624,0.002196026152894708,0.002193320019823739,0.0021906238663524425,0.0021879376312937656,0.00218526125398458,0.0021825946742799317,0.002179937832547362,0.0021772906696613053,0.0021746531269975656,0.002172025146427862,0.002169406670314448,0.0021667976415048014,0.0021641980033263865,0.0021616076995814833,0.0021590266745420837,0.002156454872944857,0.00215389223998618,0.002151338721317232,0.0021487942630391533,0.002146258811698266,0.0021437323142813607,0.0021412147182110364,0.002138705971341109,0.002136206021952073,0.002133714818746622,0.00213123231084523,0.002128758447781786,0.002126293179499287,0.0021238364563455777,0.0021213882290691587,0.0021189484488150327,0.002116517067120614,0.0021140940359116824,0.002111679307498394,0.0021092728345713345,0.0021068745701976316,0.0021044844678171056,0.0021021024812384764,0.002099728564635612,0.002097362672543826,0.002095004759856222,0.0020926547818200785,0.0020903126940332853,0.0020879784524408156,0.0020856520133312496,0.0020833333333333333,0.002081022369412584,0.0020787190788679353,0.002076423419328423,0.0020741353487499126,0.0020718548254118623,0.002069581807914131,0.0020673162551738205,0.002065058126422156,0.002062807381201405,0.0020605639793618348,0.002058327881058701,0.002056099046749278,0.002053877437189922,0.002051663013433165,0.0020494557368248532,0.0020472555690013074,0.0020450624718865267,0.002042876407689417,0.00204069733890106,0.002038525228292007,0.0020363600389096083,0.0020342017340753728,0.00203205027738236,0.002029905632692597,0.002027767764134532,0.0020256366361005138,0.0020235122132443006,0.002021394460478597,0.00201928334297262,0.002017178826149696,0.0020150808756848786,0.0020129894575025968,0.002010904537774334,0.0020088260829163283,0.0020067540595872986,0.002004688434686201,0.0020026291753500046,0.0020005762489514996,0.001998529623097123,0.0019964892656248122,0.001994455144601884,0.0019924272283229323,0.0019904054853077564,0.001988389884299306,0.001986380394261651,0.0019843769843779766,0.0019823796240485978,0.0019803882828889935,0.00197840293072787,0.0019764235376052374,0.001974450073770511,0.001972482509680635,0.001970520815998224,0.0019685649635897253,0.001966614923523602,0.001964670667068536,0.0019627321656916492,0.0019607993910567456,0.001958872315022571,0.0019569509096410923,0.0019550351471557953,0.0019531250000000004,0.001951220440795196,0.0019493214423493917,0.001947427977655487,0.0019455400198896576,0.0019436575424097591,0.0019417805187537504,0.001939908922638128,0.001938042727956382,0.0019361819087774681,0.0019343264393442904,0.0019324762940722074,0.0019306314475475484,0.001928791874526149,0.0019269575499318982,0.0019251284488553044,0.0019233045465520742,0.0019214858184417054,0.0019196722401060976,0.0019178637872881738,0.0019160604358905182,0.0019142621619740278,0.001912468941756577,0.0019106807516116972,0.0019088975680672693,0.0019071193678042297,0.0019053461276552887,0.0019035778246036647,0.001901814435781827,0.0019000559384702552,0.0018983023100962097,0.001896553528232514,0.0018948095705963515,0.0018930704150480712,0.0018913360395900077,0.001889606422365314,0.001887881541656803,0.0018861613758858029,0.0018844459036110228,0.0018827351035274314,0.001881028954465144,0.0018793274353883242,0.001877630525394093,0.0018759382037114509,0.0018742504497002098,0.0018725672428499367,0.001870888562778905,0.00186921438923306,0.00186754470208499,0.001865879481332913,0.0018642187070996676,0.0018625623596317182,0.0018609104192981677,0.0018592628665897802,0.0018576196821180127,0.0018559808466140583,0.001854346340927896,0.001852716146027351,0.001851090242997164,0.0018494686130380693,0.0018478512374658833,0.0018462380977105975,0.0018446291753154854,0.0018430244519362143,0.0018414239093399675,0.0018398275294045745,0.0018382352941176473,0.0018366471855757293,0.0018350631859834485,0.00183348327765268,0.0018319074430017163,0.0018303356645544462,0.0018287679249395401,0.0018272042068896441,0.0018256444932405814,0.0018240887669305594,0.0018225370109993886,0.0018209892085877032,0.0018194453429361938,0.001817905397384844,0.0018163693553721763,0.0018148372004345031,0.001813308916205186,0.0018117844864139012,0.0018102638948859133,0.0018087471255413521,0.0018072341623945009,0.0018057249895530865,0.0018042195912175807,0.001802717951680503,0.0018012200553257343,0.0017997258866278335,0.0017982354301513625,0.0017967486705502158,0.0017952655925669568,0.001793786181032161,0.001792310420863764,0.0017908382970664152,0.0017893697947308383,0.0017879048990331972,0.0017864435952344672,0.0017849858686798121,0.0017835317047979675,0.0017820810891006284,0.0017806340071818431,0.0017791904447174126,0.0017777503874642948,0.0017763138212600145,0.0017748807320220777,0.001773451105747393,0.001772024928511696,0.0017706021864689798,0.0017691828658509309,0.001767766952966369,0.0017663544342006923,0.0017649452960153285,0.0017635395249471885,0.001762137107608128,0.0017607380306844096,0.001759342280936174,0.0017579498451969126,0.0017565607103729461,0.0017551748634429079,0.0017537922914572304,0.0017524129815376386,0.0017510369208766435,0.0017496640967370448,0.0017482944964514358,0.0017469281074217109,0.0017455649171185803,0.0017442049130810863,0.0017428480829161264,0.0017414944142979775,0.0017401438949678266,0.0017387965127333039,0.0017374522554680207,0.001736111111111111,0.0017347730676667782,0.0017334381132038412,0.0017321062358552916,0.001730777423817848,0.0017294516653515173,0.0017281289487791596,0.0017268092624860552,0.0017254925949194775,0.0017241789345882666,0.0017228682700624104,0.001721560589972624,0.0017202558830099386,0.0017189541379252877,0.0017176553435291023,0.0017163594886909054,0.0017150665623389117,0.0017137765534596305,0.0017124894510974716,0.0017112052443543548,0.0017099239223893213,0.0017086454744181506,0.0017073698897129785,0.001706097157601919,0.0017048272674686905,0.001703560208752242,0.0017022959709463853,0.0017010345435994293,0.0016997759163138164,0.0016985200787457625,0.0016972670206049012,0.0016960167316539287,0.0016947692017082515,0.0016935244206356403,0.0016922823783558822,0.0016910430648404402,0.00168980647011211,0.0016885725842446851,0.0016873413973626217,0.001686112899640706,0.0016848870813037254,0.0016836639326261419,0.0016824434439317673,0.001681225605593443,0.00168001040803272,0.0016787978417195425,0.0016775878971719345,0.0016763805649556878,0.0016751758356840544,0.0016739737000174384,0.0016727741486630915,0.001671577172374814,0.0016703827619526524,0.001669190908242605,0.0016680016021363246,0.0016668148345708282,0.0016656305965282066,0.0016644488790353359,0.0016632696731635921,0.0016620929700285688,0.0016609187607897933,0.0016597470366504525,0.0016585777888571101,0.0016574110086994378,0.0016562466875099375,0.001655084816663675,0.00165392538757801,0.0016527683917123286,0.0016516138205677814,0.0016504616656870196,0.001649311918653936,0.001648164571093406,0.001647019614671031,0.0016458770410928854,0.001644736842105263,0.001643599009494428,0.0016424635350863648,0.0016413304107465321,0.001640199628379619,0.0016390711799293002,0.0016379450573779973,0.0016368212527466377,0.001635699758094418,0.0016345805655185671,0.0016334636671541149,0.001632349055173657,0.001631236721787127,0.001630126659241566,0.0016290188598208966,0.0016279133158456978,0.0016268100196729798,0.0016257089636959646,0.0016246101403438636,0.0016235135420816598,0.0016224191614098908,0.0016213269908644334,0.0016202370230162897,0.0016191492504713746,0.0016180636658703054,0.0016169802618881935,0.001615899031234435,0.0016148199666525058,0.001613743060919757,0.0016126683068472124,0.0016115956972793648,0.0016105252250939789,0.0016094568832018899,0.0016083906645468085,0.0016073265621051242,0.00160626456888571,0.0016052046779297317,0.0016041468823104544,0.0016030911751330533,0.0016020375495344253,0.001600985998683,0.001599936515778556,0.001598889094052034,0.0015978437267653554,0.0015968004072112376,0.0015957591287130168,0.001594719884624465,0.0015936826683296149,0.00159264747324258,0.0015916142928073817,0.0015905831204977737,0.0015895539498170682,0.0015885267742979654,0.0015875015875023814,0.00158647838302128,0.0015854571544745035,0.001584437895510606,0.0015834205998066873,0.0015824052610682292,0.0015813918730289297,0.0015803804294505426,0.0015793709241227155,0.0015783633508628294,0.0015773577035158401,0.00157635397595412,0.001575352162077301,0.0015743522558121202,0.0015733542511122628,0.0015723581419582113,0.001571363922357091,0.001570371586342519,0.0015693811279744545,0.001568392541339049,0.0015674058205484972,0.0015664209597408925,0.0015654379530800763,0.0015644567947554967,0.0015634774789820623,0.0015625,0.0015615243520747115,0.0015605505294966325,0.0015595785265810928,0.0015586083376681766,0.0015576399571225839,0.0015566733793334934,0.001555708598714426,0.001554745609703108,0.0015537844067613387,0.0015528249843748542,0.0015518673370531959,0.0015509114593295788,0.0015499573457607588,0.0015490049909269055,0.0015480543894314685,0.0015471055359010536,0.0015461584249852921,0.0015452130513567148,0.0015442694097106276,0.0015433274947649837,0.0015423873012602627,0.001541448823959344,0.0015405120576473873,0.0015395769971317081,0.0015386436372416593,0.0015377119728285091,0.0015367819987653234,0.0015358537099468452,0.0015349271012893798,0.0015340021677306749,0.0015330789042298067,0.0015321573057670628,0.001531237367343829,0.0015303190839824742,0.001529402450726239,0.0015284874626391204,0.0015275741148057637,0.0015266624023313486,0.0015257523203414812,0.0015248438639820833,0.0015239370284192836,0.0015230318088393106,0.0015221282004483846,0.001521226198472611,0.0015203257981578748,0.001519426994769735,0.0015185297835933205,0.0015176341599332254,0.0015167401191134068,0.0015158476564770813,0.001514956767386624,0.0015140674472234664,0.001513179691387997,0.0015122934952994601,0.0015114088543958578,0.0015105257641338497,0.001509644219988656,0.0015087642174539612,0.0015078857520418151,0.0015070088192825379,0.0015061334147246249,0.00150525953393465,0.001504387172497175,0.0015035163260146505,0.0015026469901073282,0.001501779160413165,0.0015009128325877317,0.001500048002304123,0.0014991846652528647,0.0014983228171418254,0.0014974624536961256,0.0014966035706580492,0.0014957461637869545,0.0014948902288591873,0.0014940357616679922,0.0014931827580234268,0.0014923312137522752,0.0014914811246979616,0.0014906324867204656,0.001489785295696238,0.0014889395475181158,0.001488095238095238,0.0014872523633529654,0.0014864109192327941,0.001485570901692276,0.0014847323067049374,0.0014838951302601953,0.0014830593683632797,0.0014822250170351532,0.0014813920723124288,0.001480560530247295,0.0014797303869074324,0.0014789016383759408,0.0014780742807512567,0.0014772483101470797,0.001476423722692294,0.0014756005145308928,0.0014747786818219023,0.001473958220739307,0.001473139127471974,0.00147232139822358,0.0014715050292125349,0.0014706900166719117,0.001469876356849371,0.001469064046007089,0.0014682530804216861,0.001467443456384155,0.001466635170199788,0.0014658282181881082,0.0014650225966827985,0.0014642183020316306,0.001463415330596397,0.0014626136787528408,0.0014618133428905876,0.0014610143194130763,0.001460216604737493,0.0014594201952947015,0.0014586250875291771,0.0014578312778989401,0.0014570387628754903,0.001456247538943739,0.001455457602601945,0.0014546689503616493,0.0014538815787476108,0.0014530954842977412,0.001452310663563041,0.0014515271131075368,0.0014507448295082177,0.0014499638093549722,0.0014491840492505258,0.0014484055458103798,0.0014476282956627485,0.001446852295448498,0.001446077541821086,0.001445304031446501,0.0014445317610032008,0.0014437607271820547,0.0014429909266862819,0.0014422223562313933,0.0014414550125451332,0.0014406888923674192,0.0014399239924502859,0.0014391603095578252,0.0014383978404661302,0.001437636581963238,0.0014368765308490716,0.0014361176839353844,0.0014353600380457043,0.001434603590015277,0.0014338483366910112,0.0014330942749314227,0.0014323414016065802,0.0014315897135980507,0.0014308392077988443,0.0014300898811133614,0.0014293417304573383,0.001428594752757795,0.0014278489449529809,0.0014271043039923222,0.0014263608268363704,0.0014256185104567492,0.0014248773518361038,0.0014241373479680485,0.0014233984958571155,0.0014226607925187046,0.0014219242349790316,0.001421188820275079,0.0014204545454545457,0.001419721407575796,0.001418989403707812,0.001418258530930143,0.0014175287863328577,0.0014168001670164941,0.0014160726700920118,0.001415346292680745,0.0014146210319143523,0.0014138968849347715,0.0014131738488941704,0.0014124519209549023,0.0014117310982894552,0.001411011378080409,0.001410292757520388,0.0014095752338120146,0.0014088588041678632,0.0014081434658104156,0.0014074292159720159,0.001406716051894824,0.0014060039708307735,0.0014052929700415248,0.001404583046798421,0.0014038741983824462,0.001403166422084179,0.0014024597152037508,0.001401754075050802,0.0014010494989444388,0.0014003459842131902,0.0013996435281949666,0.0013989421282370163,0.001398241781695884,0.0013975424859373686],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"scatter\":[{\"type\":\"scatter\"}]}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"step\"},\"tickmode\":\"linear\",\"tick0\":0,\"dtick\":100,\"range\":[0,1002]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"lr\"},\"tickmode\":\"linear\",\"tick0\":0,\"dtick\":0.001,\"range\":[0,0.00503]},\"legend\":{\"title\":{\"text\":\"group\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Learning Rate Schedule\"},\"width\":800,\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('26099489-8fe5-48c7-8f0a-b6255aa8d61b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# three examples: [model_size, factor, warmup]\n",
        "examples = [\n",
        "    [256, 1, 200],\n",
        "    [512, 1, 200],\n",
        "    [512, 1, 400],\n",
        "]\n",
        "\n",
        "dummy_model = torch.nn.Linear(1, 1)\n",
        "\n",
        "# three examples\n",
        "results = []\n",
        "num_steps = 1001\n",
        "for idx, example in enumerate(examples):\n",
        "    # run each example\n",
        "    optimizer = torch.optim.Adam(\n",
        "        dummy_model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9\n",
        "    )\n",
        "    lr_scheduler = LambdaLR(\n",
        "        optimizer=optimizer, lr_lambda=lambda step: rate(step, *example)\n",
        "    )\n",
        "\n",
        "    # save the learning rate at each step\n",
        "    for step in range(num_steps):\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        # record each step\n",
        "        d = {\n",
        "            'step': step,\n",
        "            'lr': lr,\n",
        "            'group': f\"{example[0]}:{example[2]}\"\n",
        "        }\n",
        "        results.append(d)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# plot\n",
        "fig = px.line(df, x=\"step\", y=\"lr\", color=\"group\", title='Learning Rate Schedule', template='none',)\n",
        "fig.update_layout(\n",
        "    width=800, height=400,\n",
        "    xaxis=dict(\n",
        "        tickmode='linear',\n",
        "        tick0=0,\n",
        "        dtick=100,\n",
        "        range=[0, 1002],\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        tickmode='linear',\n",
        "        tick0=0,\n",
        "        dtick=0.001,\n",
        "        range=[0, 0.00503],\n",
        "    ),\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "719792c2",
      "metadata": {
        "id": "719792c2"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7b46c27",
      "metadata": {
        "id": "c7b46c27"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a416f9a",
      "metadata": {
        "id": "5a416f9a"
      },
      "source": [
        "### Cosine Annealing with Warmup\n",
        "\n",
        "> The scheduler described above depends heavily on model size ($d_{model}$ or $embed\\_dim$) which makes it hard to compare across models.\n",
        "> <br>In practice, we would like to adopt *Cosine Annealing with Warmup*, a widely used learning rate scheduler nowadays, as the scheduler.\n",
        ">\n",
        "> **Cosine Annealing with Warmup**:\n",
        "> <br>This creates a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "initial lr set in the optimizer.\n",
        "> <br>Reference code can be found at: https://github.com/huggingface/transformers/blob/v4.45.2/src/transformers/optimization.py#L144"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ed8864b",
      "metadata": {
        "id": "7ed8864b"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Optimizer\n",
        "from functools import partial\n",
        "\n",
        "def cosine_schedule_with_warmup_lr_lambda(\n",
        "    current_step: int, *, num_warmup_steps: int, num_training_steps: int, num_cycles: float = 0.5\n",
        "):\n",
        "    if current_step < num_warmup_steps:\n",
        "        return float(current_step) / float(max(1, num_warmup_steps))\n",
        "    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
        "\n",
        "\n",
        "def cosine_schedule_with_warmup(\n",
        "    optimizer: Optimizer, num_warmup_steps: int, num_training_steps: int, num_cycles: float = 0.5, last_epoch: int = -1\n",
        "):\n",
        "    \"\"\"\n",
        "    Create a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "    initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "    initial lr set in the optimizer.\n",
        "\n",
        "    Args:\n",
        "        optimizer ([`~torch.optim.Optimizer`]):\n",
        "            The optimizer for which to schedule the learning rate.\n",
        "        num_warmup_steps (`int`):\n",
        "            The number of steps for the warmup phase.\n",
        "        num_training_steps (`int`):\n",
        "            The total number of training steps.\n",
        "        num_cycles (`float`, *optional*, defaults to 0.5):\n",
        "            The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "            following a half-cosine).\n",
        "        last_epoch (`int`, *optional*, defaults to -1):\n",
        "            The index of the last epoch when resuming training.\n",
        "\n",
        "    Return:\n",
        "        `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "    \"\"\"\n",
        "\n",
        "    lr_lambda = partial(\n",
        "        cosine_schedule_with_warmup_lr_lambda,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps,\n",
        "        num_cycles=num_cycles,\n",
        "    )\n",
        "    return LambdaLR(optimizer, lr_lambda, last_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646e57c0",
      "metadata": {
        "id": "646e57c0"
      },
      "source": [
        "\n",
        "> Example of the curves of cosine annealing with warmup scheduler for different number of warmup steps\n",
        "> using AdamW as the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea41f973",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "ea41f973",
        "outputId": "b4c1bac3-e9b8-483b-dc57-0abfe5c51759"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d875d772-6abf-4b99-b556-1f307b638a12\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d875d772-6abf-4b99-b556-1f307b638a12\")) {                    Plotly.newPlot(                        \"d875d772-6abf-4b99-b556-1f307b638a12\",                        [{\"hovertemplate\":\"group=100:1000\\u003cbr\\u003estep=%{x}\\u003cbr\\u003elr=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"100:1000\",\"line\":{\"color\":\"#1F77B4\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"100:1000\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000],\"xaxis\":\"x\",\"y\":[0.0,0.0001,0.0002,0.0003,0.0004,0.0005,0.0006,0.0007000000000000001,0.0008,0.0009,0.001,0.0011,0.0012,0.0013000000000000002,0.0014000000000000002,0.0015,0.0016,0.0017000000000000001,0.0018,0.0019,0.002,0.0021,0.0022,0.0023,0.0024,0.0025,0.0026000000000000003,0.0027,0.0028000000000000004,0.0029,0.003,0.0031,0.0032,0.0033000000000000004,0.0034000000000000002,0.0034999999999999996,0.0036,0.0037,0.0038,0.0039000000000000003,0.004,0.0040999999999999995,0.0042,0.0043,0.0044,0.0045000000000000005,0.0046,0.0047,0.0048,0.0049,0.005,0.0051,0.005200000000000001,0.0053,0.0054,0.0055000000000000005,0.005600000000000001,0.005699999999999999,0.0058,0.0059,0.006,0.0061,0.0062,0.0063,0.0064,0.006500000000000001,0.006600000000000001,0.0067,0.0068000000000000005,0.0069,0.006999999999999999,0.0070999999999999995,0.0072,0.0073,0.0074,0.0075,0.0076,0.0077,0.0078000000000000005,0.0079,0.008,0.008100000000000001,0.008199999999999999,0.0083,0.0084,0.0085,0.0086,0.0087,0.0088,0.0089,0.009000000000000001,0.0091,0.0092,0.009300000000000001,0.0094,0.0095,0.0096,0.0097,0.0098,0.0099,0.01,0.009999969538288953,0.009999878153526973,0.00999972584682756,0.009999512620046521,0.009999238475781956,0.009998903417374227,0.009998507448905916,0.009998050575201771,0.009997532801828659,0.009996954135095479,0.009996314582053105,0.009995614150494292,0.009994852848953574,0.009994030686707171,0.009993147673772868,0.009992203820909906,0.009991199139618828,0.009990133642141357,0.00998900734146025,0.009987820251299122,0.00998657238612229,0.009985263761134603,0.009983894392281237,0.009982464296247521,0.009980973490458728,0.009979421993079851,0.0099778098230154,0.009976136999909156,0.009974403544143941,0.009972609476841367,0.009970754819861578,0.009968839595802982,0.009966863828001982,0.009964827540532685,0.00996273075820661,0.00996057350657239,0.009958355811915452,0.009956077701257709,0.009953739202357217,0.009951340343707852,0.009948881154538944,0.009946361664814942,0.00994378190523503,0.009941141907232765,0.009938441702975689,0.00993568132536494,0.009932860808034847,0.009929980185352525,0.009927039492417451,0.00992403876506104,0.009920978039846208,0.00991785735406693,0.009914676745747772,0.009911436253643444,0.00990813591723832,0.009904775776745959,0.00990135587310861,0.00989787624799672,0.009894336943808426,0.009890738003669028,0.00988707947143048,0.00988336139167084,0.009879583809693738,0.009875746771527817,0.009871850323926177,0.009867894514365802,0.009863879391046984,0.009859805002892732,0.009855671399548181,0.009851478631379982,0.009847226749475696,0.009842915805643155,0.009838545852409857,0.009834116943022298,0.009829629131445342,0.009825082472361557,0.00982047702117055,0.009815812833988292,0.009811089967646427,0.009806308479691595,0.009801468428384716,0.009796569872700287,0.009791612872325666,0.009786597487660335,0.009781523779815178,0.009776391810611717,0.009771201642581384,0.009765953338964736,0.009760646963710692,0.009755282581475769,0.009749860257623262,0.009744380058222483,0.009738842050047929,0.009733246300578481,0.009727592877996585,0.009721881851187405,0.009716113289738005,0.009710287263936484,0.009704403844771128,0.009698463103929543,0.00969246511379778,0.009686409947459458,0.009680297678694867,0.009674128381980071,0.009667902132486009,0.009661619006077562,0.009655279079312643,0.009648882429441256,0.009642429134404568,0.009635919272833937,0.009629352924049974,0.009622730168061566,0.009616051085564905,0.009609315757942502,0.009602524267262203,0.009595676696276171,0.009588773128419905,0.009581813647811199,0.009574798339249124,0.009567727288213004,0.009560600580861365,0.009553418304030885,0.009546180545235343,0.009538887392664544,0.009531538935183251,0.009524135262330098,0.009516676464316505,0.00950916263202557,0.009501593857010968,0.009493970231495836,0.009486291848371643,0.009478558801197065,0.00947077118419684,0.009462929092260628,0.00945503262094184,0.009447081866456488,0.009439076925682006,0.009431017896156073,0.00942290487607542,0.009414737964294635,0.009406517260324961,0.009398242864333084,0.009389914877139902,0.009381533400219317,0.00937309853569698,0.009364610386349049,0.009356069055600947,0.009347474647526095,0.009338827266844643,0.009330127018922194,0.009321374009768525,0.009312568346036288,0.009303710135019719,0.009294799484653322,0.009285836503510562,0.009276821300802533,0.009267753986376637,0.009258634670715239,0.00924946346493432,0.00924024048078213,0.009230965830637821,0.009221639627510075,0.009212261985035738,0.009202833017478422,0.009193352839727121,0.009183821567294808,0.009174239316317032,0.009164606203550498,0.00915492234637164,0.009145187862775208,0.009135402871372808,0.009125567491391475,0.00911568184267221,0.00910574604566852,0.00909576022144496,0.009085724491675643,0.009075638978642771,0.009065503805235138,0.009055319094946633,0.009045084971874737,0.00903480156071901,0.00902446898677957,0.009014087375955573,0.009003656854743667,0.008993177550236464,0.008982649590120982,0.008972073102677091,0.008961448216775953,0.008950775061878453,0.008940053768033609,0.00892928446587701,0.008918467286629199,0.008907602362094093,0.008896689824657371,0.008885729807284855,0.008874722443520899,0.008863667867486755,0.008852566213878947,0.008841417617967617,0.00883022221559489,0.008818980143173212,0.008807691537683683,0.008796356536674403,0.008784975278258783,0.00877354790111386,0.008762074544478622,0.008750555348152299,0.00873899045249266,0.008727379998414312,0.008715724127386972,0.00870402298143375,0.00869227670312942,0.008680485435598673,0.008668649322514382,0.008656768508095852,0.008644843137107058,0.008632873354854879,0.008620859307187338,0.00860880114049181,0.008596699001693256,0.008584553038252413,0.008572363398164017,0.008560130229954983,0.008547853682682604,0.008535533905932738,0.008523171049817974,0.008510765264975812,0.008498316702566828,0.008485825514272823,0.008473291852294987,0.008460715869352035,0.00844809771867835,0.008435437554022115,0.008422735529643444,0.008409991800312494,0.008397206521307583,0.008384379848413304,0.008371511937918616,0.008358602946614951,0.008345653031794291,0.008332662351247262,0.008319631063261208,0.00830655932661826,0.008293447300593402,0.008280295144952536,0.008267103019950529,0.008253871086329254,0.008240599505315655,0.008227288438619753,0.008213938048432696,0.008200548497424779,0.008187119948743448,0.008173652566011338,0.008160146513324255,0.008146601955249187,0.008133019056822302,0.008119397983546932,0.008105738901391551,0.00809204197678777,0.008078307376628291,0.008064535268264884,0.00805072581950634,0.008036879198616434,0.008022995574311876,0.008009075115760243,0.007995117992577929,0.00798112437482808,0.007967094433018507,0.007953028338099627,0.007938926261462366,0.007924788374936079,0.007910614850786448,0.007896405861713394,0.007882161580848967,0.00786788218175523,0.00785356783842216,0.007839218725265506,0.00782483501712469,0.007810416889260653,0.007795964517353734,0.007781478077501525,0.007766957746216721,0.007752403700424978,0.007737816117462751,0.007723195175075136,0.0077085410514137,0.007693853925034315,0.007679133974894983,0.00766438138035365,0.007649596321166025,0.0076347789774833886,0.007619929529850397,0.007605048159202883,0.007590135046865652,0.007575190374550272,0.007560214324352858,0.0075452070787518566,0.007530168820605818,0.007515099733151176,0.0075,0.0074848698051377775,0.007469709332921155,0.007454518768075704,0.007439298295693664,0.007424048101231686,0.0074087683705085765,0.007393459289703035,0.007378121045351377,0.0073627538243452705,0.007347357813929454,0.007331933201699456,0.00731648017559931,0.007300998923919258,0.0072854896352934715,0.007269952498697734,0.007254387703447154,0.007238795439193848,0.0072231758959246375,0.007207529263958726,0.007191855733945388,0.007176155496861639,0.007160428744009913,0.00714467566701573,0.007128896457825364,0.007113091308703498,0.007097260412230886,0.007081403961302007,0.007065522149122709,0.007049615169207863,0.007033683215379002,0.007017726481761952,0.007001745162784476,0.006985739453173902,0.0069697095479547555,0.006953655642446368,0.006937577932260515,0.0069214766132990185,0.006905351881751371,0.0068892039340923365,0.006873032967079561,0.006856839177751175,0.006840622763423391,0.006824383921688097,0.006808122850410461,0.0067918397477265005,0.006775534812040685,0.006759208242023509,0.006742860236609076,0.006726490994992673,0.006710100716628344,0.0066936896012264584,0.006677257848751276,0.006660805659418516,0.006644333233692916,0.006627840772285783,0.006611328476152556,0.00659479654649035,0.006578245184735513,0.006561674592561163,0.006545084971874737,0.006528476524815529,0.006511849453752223,0.0064952039612804335,0.006478540250220234,0.006461858523613684,0.006445158984722358,0.006428441837024868,0.006411707284214383,0.006394955530196147,0.006378186779084995,0.006361401235202872,0.006344599103076328,0.006327780587434044,0.006310945893204324,0.006294095225512604,0.006277228789678953,0.00626034679121557,0.006243449435824276,0.0062265369293940135,0.0062096094779983384,0.006192667287892905,0.00617571056551295,0.006158739517470786,0.006141754350553279,0.006124755271719326,0.006107742488097338,0.0060907162069827134,0.006073676635835317,0.006056623982276944,0.006039558454088796,0.006022480259208951,0.006005389605729824,0.005988286701895631,0.005971171756099861,0.005954044976882724,0.005936906572928624,0.005919756753063601,0.005902595726252801,0.005885423701597918,0.005868240888334653,0.005851047495830163,0.0058338437335805115,0.005816629811208111,0.005799405938459175,0.0057821723252011546,0.005764929181420191,0.005747676717218549,0.005730415142812059,0.005713144668527559,0.005695865504800327,0.005678577862171522,0.0056612819512856126,0.005643977982887814,0.005626666167821521,0.005609346717025738,0.005592019841532506,0.005574685752464333,0.005557344661031627,0.005539996778530114,0.0055226423163382676,0.005505281485914732,0.005487914498795748,0.005470541566592573,0.005453162900988902,0.005435778713738292,0.005418389216661579,0.005400994621644294,0.0053835951406340935,0.005366190985638159,0.005348782368720626,0.005331369502000002,0.005313952597646567,0.005296531867879809,0.005279107524965819,0.00526167978121472,0.0052442488489780675,0.005226814940646268,0.0052093782686459976,0.0051919390454376,0.005174497483512506,0.005157053795390641,0.005139608193617845,0.005122160890763267,0.005104712099416785,0.005087262032186418,0.005069810901695727,0.005052358920581229,0.0050349063014898075,0.005017453257076119,0.005,0.004982546742923883,0.004965093698510193,0.004947641079418773,0.004930189098304274,0.004912737967813582,0.0048952879005832155,0.004877839109236734,0.004860391806382157,0.004842946204609359,0.004825502516487497,0.004808060954562401,0.004790621731354003,0.004773185059353731,0.004755751151021934,0.0047383202187852805,0.004720892475034181,0.004703468132120193,0.004686047402353433,0.004668630498000001,0.004651217631279373,0.0046338090143618425,0.004616404859365907,0.004599005378355706,0.0045816107833384235,0.004564221286261709,0.0045468370990111,0.004529458433407428,0.004512085501204253,0.004494718514085268,0.0044773576836617335,0.0044600032214698855,0.0044426553389683736,0.004425314247535668,0.004407980158467495,0.004390653282974263,0.004373333832178478,0.004356022017112187,0.004338718048714388,0.004321422137828479,0.004304134495199674,0.004286855331472442,0.004269584857187943,0.0042523232827814525,0.00423507081857981,0.004217827674798845,0.0042005940615408265,0.00418337018879189,0.004166156266419489,0.004148952504169839,0.0041317591116653484,0.004114576298402084,0.004097404273747201,0.004080243246936399,0.004063093427071376,0.004045955023117276,0.004028828243900141,0.004011713298104369,0.003994610394270178,0.003977519740791049,0.003960441545911205,0.003943376017723057,0.003926323364164684,0.0039092837930172885,0.0038922575119026636,0.0038752447282806757,0.003858245649446721,0.003841260482529214,0.00382428943448705,0.0038073327121070965,0.003790390522001662,0.003773463070605987,0.003756550564175727,0.0037396532087844315,0.003722771210321048,0.003705904774487396,0.003689054106795677,0.003672219412565956,0.0036554008969236717,0.0036385987647971287,0.0036218132209150044,0.003605044469803854,0.0035882927157856173,0.0035715581629751324,0.003554841015277641,0.003538141476386317,0.0035214597497797684,0.003504796038719567,0.003488150546247778,0.0034715234751844723,0.003454915028125263,0.003438325407438837,0.0034217548152644882,0.00340520345350965,0.0033886715238474452,0.0033721592277142177,0.003355666766307084,0.003339194340581485,0.0033227421512487254,0.003306310398773543,0.0032898992833716566,0.003273509005007327,0.003257139763390925,0.0032407917579764913,0.003224465187959316,0.003208160252273499,0.003191877149589539,0.0031756160783119013,0.0031593772365766104,0.003143160822248827,0.00312696703292044,0.003110796065907665,0.00309464811824863,0.003078523386700982,0.0030624220677394854,0.003046344357553632,0.0030302904520452447,0.0030142605468260974,0.002998254837215526,0.0029822735182380494,0.0029663167846209998,0.002950384830792136,0.002934477850877292,0.0029185960386979948,0.0029027395877691143,0.0028869086912965036,0.0028711035421746366,0.0028553243329842715,0.0028395712559900876,0.002823844503138363,0.0028081442660546126,0.0027924707360412744,0.002776824104075364,0.002761204560806152,0.0027456122965528475,0.0027300475013022664,0.0027145103647065304,0.002699001076080742,0.0026835198244006923,0.0026680667983005448,0.0026526421860705476,0.0026372461756547306,0.0026218789546486234,0.0026065407102969663,0.002591231629491423,0.002575951898768315,0.0025607017043063358,0.002545481231924296,0.0025302906670788463,0.0025151301948622235,0.0025000000000000014,0.0024849002668488247,0.002469831179394182,0.0024547929212481437,0.002439785675647143,0.002424809625449729,0.00240986495313435,0.00239495184079712,0.002380070470149605,0.002365221022516612,0.002350403678833976,0.0023356186196463497,0.0023208660251050157,0.0023061460749656845,0.002291458948586301,0.0022768048249248644,0.002262183882537249,0.002247596299575022,0.00223304225378328,0.002218521922498476,0.0022040354826462667,0.0021895831107393484,0.0021751649828753105,0.002160781274734495,0.002146432161577842,0.0021321178182447708,0.002117838419151034,0.002103594138286607,0.0020893851492135534,0.0020752116250639225,0.0020610737385376348,0.0020469716619003725,0.0020329055669814932,0.00201887562517192,0.0020048820074220716,0.001990924884239758,0.001977004425688126,0.0019631208013835676,0.001949274180493662,0.0019354647317351187,0.0019216926233717087,0.00190795802321223,0.0018942610986084486,0.0018806020164530701,0.001866980943177699,0.0018533980447508135,0.0018398534866757455,0.0018263474339886626,0.0018128800512565513,0.0017994515025752218,0.0017860619515673033,0.0017727115613802463,0.0017594004946843455,0.0017461289136707458,0.0017328969800494726,0.001719704855047464,0.0017065526994065972,0.0016934406733817415,0.001680368936738792,0.001667337648752738,0.0016543469682057106,0.0016413970533850498,0.0016284880620813847,0.0016156201515866969,0.0016027934786924187,0.0015900081996875082,0.0015772644703565563,0.0015645624459778857,0.001551902281321651,0.0015392841306479665,0.0015267081477050133,0.0015141744857271777,0.0015016832974331722,0.001489234735024188,0.0014768289501820265,0.0014644660940672626,0.0014521463173173966,0.001439869770045018,0.0014276366018359844,0.0014154469617475862,0.0014033009983067451,0.0013911988595081892,0.0013791406928126638,0.001367126645145121,0.0013551568628929435,0.0013432314919041477,0.0013313506774856178,0.0013195145644013283,0.0013077232968705804,0.0012959770185662501,0.0012842758726130281,0.0012726200015856892,0.0012610095475073413,0.001249444651847702,0.0012379254555213786,0.00122645209888614,0.0012150247217412185,0.001203643463325596,0.0011923084623163172,0.0011810198568267905,0.0011697777844051104,0.0011585823820323843,0.0011474337861210543,0.0011363321325132448,0.0011252775564791024,0.0011142701927151456,0.0011033101753426284,0.0010923976379059058,0.0010815327133708013,0.0010707155341229903,0.0010599462319663905,0.001049224938121548,0.001038551783224047,0.0010279268973229089,0.0010173504098790187,0.001006822449763537,0.0009963431452563332,0.0009859126240444284,0.0009755310132204298,0.0009651984392809915,0.0009549150281252633,0.0009446809050533678,0.0009344961947648623,0.0009243610213572284,0.0009142755083243575,0.0009042397785550405,0.0008942539543314799,0.0008843181573277903,0.0008744325086085247,0.0008645971286271903,0.0008548121372247919,0.0008450776536283594,0.0008353937964495028,0.0008257606836829679,0.0008161784327051919,0.0008066471602728803,0.0007971669825215788,0.0007877380149642626,0.0007783603724899257,0.0007690341693621806,0.0007597595192178702,0.0007505365350656812,0.0007413653292847617,0.0007322460136233622,0.0007231786991974671,0.0007141634964894389,0.0007052005153466779,0.0006962898649802824,0.0006874316539637127,0.0006786259902314768,0.0006698729810778065,0.0006611727331553585,0.000652525352473905,0.0006439309443990532,0.0006353896136509524,0.0006269014643030213,0.0006184665997806832,0.0006100851228600973,0.0006017571356669182,0.0005934827396750392,0.0005852620357053651,0.0005770951239245802,0.0005689821038439264,0.0005609230743179939,0.0005529181335435124,0.0005449673790581611,0.000537070907739372,0.0005292288158031594,0.0005214411988029355,0.0005137081516283582,0.000506029768504166,0.0004984061429890325,0.0004908373679744316,0.00048332353568349585,0.00047586473766990324,0.0004684610648167503,0.0004611126073354571,0.00045381945476465735,0.0004465816959691149,0.00043939941913863524,0.0004322727117869951,0.0004252016607508763,0.00041818635218880186,0.00041122687158009433,0.0004043233037238281,0.0003974757327377981,0.000390684242057498,0.0003839489144350955,0.00037726983193843487,0.0003706470759500263,0.00036408072716606344,0.0003575708655954324,0.0003511175705587433,0.00034472092068735916,0.00033838099392243914,0.00033209786751399185,0.0003258716180199278,0.00031970232130513365,0.00031359005254054276,0.00030753488620222037,0.00030153689607045843,0.00029559615522887275,0.0002897127360635166,0.00028388671026199517,0.000278118148812595,0.0002724071220034158,0.00026675369942151864,0.0002611579499520722,0.00025561994177751736,0.0002501397423767382,0.00024471741852423234,0.00023935303628930705,0.0002340466610352654,0.00022879835741861586,0.00022360818938828186,0.00021847622018482282,0.0002134025123396638,0.00020838712767433376,0.00020343012729971243,0.00019853157161528467,0.00019369152030840553,0.00018891003235357306,0.0001841871660117095,0.00017952297882945002,0.00017491752763844294,0.000170370868554659,0.00016588305697770312,0.00016145414759014432,0.00015708419435684463,0.00015277325052430568,0.00014852136862001763,0.00014432860045182017,0.00014019499710726913,0.0001361206089530176,0.00013210548563419855,0.00012814967607382432,0.00012425322847218367,0.00012041619030626283,0.0001166386083291604,0.00011292052856952061,0.00010926199633097155,0.00010566305619157501,0.00010212375200327973,0.00009864412689139123,0.00009522422325404234,0.00009186408276168012,0.00008856374635655695,0.0000853232542522292,0.00008214264593307097,0.0000790219601537906,0.0000759612349389599,0.00007296050758254958,0.00007001981464747564,0.00006713919196515317,0.00006431867463506047,0.0000615582970243117,0.000058858092767236084,0.00005621809476497097,0.00005363833518505834,0.000051118845461055055,0.00004865965629214819,0.00004626079764278202,0.00004392229874229159,0.00004164418808454806,0.000039426493427611173,0.000037269241793390084,0.00003517245946731529,0.00003313617199801777,0.000031160404197018154,0.000029245180138423033,0.00002739052315863355,0.000025596455856058966,0.00002386300009084408,0.00002219017698460002,0.000020578006920148328,0.000019026509541272274,0.000017535703752478148,0.00001610560771876435,0.000014736238865398765,0.000013427613877709522,0.000012179748700879012,0.000010992658539750178,9.866357858642205e-6,8.800860381173447e-6,7.79617909009489e-6,6.852326227130834e-6,5.9693132928301254e-6,5.147151046426823e-6,4.385849505708084e-6,3.6854179468942538e-6,3.0458649045211896e-6,2.467198171342e-6,1.949424798228239e-6,1.4925510940844157e-6,1.096582625772502e-6,7.615242180436522e-7,4.873799534788059e-7,2.741531724392843e-7,1.2184647302626584e-7,3.046171104803541e-8,0.0],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"group=200:1000\\u003cbr\\u003estep=%{x}\\u003cbr\\u003elr=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"200:1000\",\"line\":{\"color\":\"#FF7F0E\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"200:1000\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000],\"xaxis\":\"x\",\"y\":[0.0,0.00005,0.0001,0.00015,0.0002,0.00025,0.0003,0.00035000000000000005,0.0004,0.00045,0.0005,0.00055,0.0006,0.0006500000000000001,0.0007000000000000001,0.00075,0.0008,0.0008500000000000001,0.0009,0.00095,0.001,0.00105,0.0011,0.00115,0.0012,0.00125,0.0013000000000000002,0.00135,0.0014000000000000002,0.00145,0.0015,0.00155,0.0016,0.0016500000000000002,0.0017000000000000001,0.0017499999999999998,0.0018,0.00185,0.0019,0.0019500000000000001,0.002,0.0020499999999999997,0.0021,0.00215,0.0022,0.0022500000000000003,0.0023,0.00235,0.0024,0.00245,0.0025,0.00255,0.0026000000000000003,0.00265,0.0027,0.0027500000000000003,0.0028000000000000004,0.0028499999999999997,0.0029,0.00295,0.003,0.00305,0.0031,0.00315,0.0032,0.0032500000000000003,0.0033000000000000004,0.00335,0.0034000000000000002,0.00345,0.0034999999999999996,0.0035499999999999998,0.0036,0.00365,0.0037,0.00375,0.0038,0.00385,0.0039000000000000003,0.00395,0.004,0.004050000000000001,0.0040999999999999995,0.00415,0.0042,0.00425,0.0043,0.00435,0.0044,0.00445,0.0045000000000000005,0.00455,0.0046,0.0046500000000000005,0.0047,0.00475,0.0048,0.00485,0.0049,0.00495,0.005,0.00505,0.0051,0.00515,0.005200000000000001,0.00525,0.0053,0.005350000000000001,0.0054,0.005450000000000001,0.0055000000000000005,0.00555,0.005600000000000001,0.00565,0.005699999999999999,0.00575,0.0058,0.00585,0.0059,0.0059499999999999996,0.006,0.00605,0.0061,0.00615,0.0062,0.00625,0.0063,0.006350000000000001,0.0064,0.00645,0.006500000000000001,0.00655,0.006600000000000001,0.0066500000000000005,0.0067,0.006750000000000001,0.0068000000000000005,0.006850000000000001,0.0069,0.00695,0.006999999999999999,0.00705,0.0070999999999999995,0.00715,0.0072,0.0072499999999999995,0.0073,0.00735,0.0074,0.00745,0.0075,0.00755,0.0076,0.0076500000000000005,0.0077,0.007750000000000001,0.0078000000000000005,0.007850000000000001,0.0079,0.00795,0.008,0.00805,0.008100000000000001,0.00815,0.008199999999999999,0.00825,0.0083,0.00835,0.0084,0.00845,0.0085,0.00855,0.0086,0.00865,0.0087,0.00875,0.0088,0.00885,0.0089,0.00895,0.009000000000000001,0.00905,0.0091,0.00915,0.0092,0.009250000000000001,0.009300000000000001,0.00935,0.0094,0.00945,0.0095,0.00955,0.0096,0.00965,0.0097,0.00975,0.0098,0.00985,0.0099,0.00995,0.01,0.009999961446907353,0.00999984578822395,0.009999653025733387,0.009999383162408303,0.009999036202410324,0.009998612151090004,0.009998111014986735,0.009997532801828659,0.009996877520532535,0.009996145181203616,0.009995335795135476,0.00999444937480985,0.009993485933896437,0.00999244548725269,0.00999132805092358,0.009990133642141357,0.009988862279325286,0.00998751398208135,0.009986088771201964,0.00998458666866564,0.009983007697636659,0.009981351882464707,0.009979619248684502,0.0099778098230154,0.009975923633360985,0.009973960708808632,0.009971921079629069,0.009969804777275899,0.009967611834385121,0.009965342284774633,0.00996299616344369,0.00996057350657239,0.009958074351521096,0.009955498736829875,0.009952846702217886,0.009950118288582789,0.009947313538000092,0.009944432493722524,0.009941475200179347,0.009938441702975689,0.009935332048891828,0.009932146285882477,0.009928884463076045,0.00992554663077387,0.009922132840449458,0.00991864314474768,0.009915077597483958,0.009911436253643444,0.009907719169380163,0.009903926402016152,0.009900058010040578,0.009896114053108829,0.0098920945920416,0.009887999688823954,0.009883829406604362,0.009879583809693738,0.009875262963564436,0.009870866934849247,0.009866395791340375,0.009861849601988383,0.009857228436901136,0.009852532367342712,0.009847761465732317,0.009842915805643155,0.009837995461801299,0.009833000510084537,0.009827931027521204,0.00982278709228899,0.009817568783713744,0.009812276182268235,0.00980690936957093,0.009801468428384716,0.009795953442615636,0.009790364497311597,0.009784701678661044,0.00977896507399165,0.009773154771768955,0.009767270861595005,0.009761313434206978,0.009755282581475769,0.009749178396404587,0.009743000973127523,0.00973675040690808,0.009730426794137726,0.009724030232334391,0.009717560820140967,0.0097110186573238,0.009704403844771128,0.009697716484491546,0.00969095667961242,0.009684124534378306,0.009677220154149338,0.009670243645399592,0.009663195115715471,0.009656074673794018,0.009648882429441256,0.009641618493570495,0.009634282978200603,0.009626875996454311,0.009619397662556433,0.009611848091832133,0.009604227400705132,0.00959653570669591,0.009588773128419905,0.00958093978558568,0.009573035798993068,0.009565061290531321,0.009557016383177226,0.009548901200993205,0.009540715869125407,0.009532460513801773,0.009524135262330098,0.009515740243096055,0.009507275585561229,0.009498741420261107,0.009490137878803078,0.009481465093864395,0.009472723199190125,0.009463912329591104,0.00945503262094184,0.009446084210178422,0.009437067235296416,0.00942798183534873,0.009418828150443467,0.009409606321741775,0.00940031649145566,0.009390958802845796,0.009381533400219317,0.009372040428927595,0.009362480035363985,0.009352852366961588,0.009343157572190957,0.009333395800557821,0.009323567202600776,0.00931367192988896,0.009303710135019719,0.009293681971616253,0.00928358759432525,0.009273427158814488,0.009263200821770462,0.00925290874089593,0.00924255107490752,0.009232127983533246,0.009221639627510075,0.009211086168581432,0.00920046776949471,0.009189784593998756,0.009179036806841352,0.009168224573766672,0.009157348061512726,0.009146407437808788,0.009135402871372808,0.009124334531908819,0.0091132025901043,0.009102007217627568,0.009090748587125117,0.009079426872218957,0.009068042247503936,0.00905659488854505,0.009045084971874737,0.00903351267499015,0.009021878176350423,0.009010181655373917,0.008998423292435455,0.008986603268863537,0.00897472176693755,0.008962778969884955,0.008950775061878453,0.008938710228033154,0.008926584654403725,0.008914398527981508,0.008902152036691648,0.008889845369390192,0.008877478715861172,0.008865052266813684,0.008852566213878947,0.008840020749607339,0.00882741606746544,0.008814752361833043,0.008802029828000156,0.008789248662163985,0.008776409061425919,0.008763511223788486,0.008750555348152299,0.008737541634312984,0.00872447028295811,0.008711341495664085,0.00869815547489305,0.008684912423989754,0.008671612547178428,0.008658256049559623,0.008644843137107058,0.008631374016664433,0.008617848895942247,0.008604267983514595,0.008590631488815944,0.008576939622137915,0.008563192594626026,0.008549390618276451,0.008535533905932738,0.008521622671282533,0.00850765712885428,0.008493637494013922,0.00847956398296157,0.00846543681272818,0.008451256201172186,0.008437022366976164,0.008422735529643444,0.008408395909494732,0.00839400372766471,0.008379559206098624,0.008365062567548867,0.008350514035571539,0.008335913834523,0.008321262189556408,0.00830655932661826,0.008291805472444886,0.008277000854558968,0.008262145701266033,0.008247240241650917,0.00823228470557425,0.008217279323668895,0.008202224327336406,0.008187119948743448,0.008171966420818227,0.008156763977246888,0.00814151285246992,0.008126213281678528,0.008110865500811021,0.00809546974654917,0.00808002625631455,0.008064535268264884,0.00804899702129037,0.008033411755009998,0.008017779709767857,0.008002101126629422,0.007986376247377835,0.007970605314510193,0.007954788571233787,0.007938926261462366,0.00792301862981237,0.007907065921599154,0.007891068382833216,0.007875026260216394,0.007858939801138061,0.007842809253671321,0.007826634866569164,0.007810416889260653,0.007794155571847058,0.007777851165098011,0.007761503920447634,0.007745114089990659,0.00772868192647855,0.007712207683315594,0.0076956916145550025,0.007679133974894983,0.007662535019674827,0.007645895004870953,0.007629214187092978,0.0076124928235797445,0.007595731172195364,0.007578929491425237,0.007562088040372066,0.0075452070787518566,0.007528286866889924,0.007511327665716863,0.007494329736764537,0.007477293342162038,0.007460218744631645,0.007443106207484776,0.007425955994617919,0.0074087683705085765,0.007391543600211173,0.007374281949352972,0.00735698368412999,0.007339649071302867,0.007322278378192782,0.0073048718726773125,0.007287429823186302,0.007269952498697734,0.007252440168733572,0.007234893103355606,0.007217311573161292,0.007199695849279576,0.00718204620336671,0.007164362907602071,0.00714664623468395,0.007128896457825364,0.007111113850749827,0.007093298687687141,0.007075451243369156,0.007057571793025545,0.007039660612379546,0.007021717977643726,0.0070037441655157046,0.006985739453173902,0.006967704118273257,0.006949638438940942,0.00693154269377208,0.00691341716182545,0.006895262122619174,0.006877077856126416,0.006858864642771061,0.006840622763423391,0.00682235249939575,0.006804054132438209,0.0067857279447342276,0.006767374218896286,0.006748993237961544,0.006730585285387465,0.00671215064504745,0.0066936896012264584,0.00667520243861662,0.006656689442312854,0.006638150897808468,0.006619587090990748,0.006600998308136559,0.006582384835907931,0.00656374696134763,0.006545084971874737,0.006526399155280218,0.006507689799722478,0.0064889571937229275,0.006470201626161519,0.006451423386272311,0.006432622763638992,0.006413800048190417,0.006394955530196147,0.006376089500261958,0.006357202249325371,0.006338294068651162,0.006319365249826865,0.006300416084758283,0.006281446865664984,0.0062624578850757895,0.006243449435824276,0.006224421811044238,0.006205375304165194,0.006186310208907839,0.0061672268192795275,0.006148125429569734,0.006129006334345519,0.00610986982844698,0.0060907162069827134,0.006071545765325254,0.006052358799106527,0.006033155604213291,0.006013936476782562,0.005994701713197063,0.005975451610080642,0.005956186464293703,0.005936906572928624,0.005917612233305183,0.005898303742965964,0.005878981399671773,0.005859645501397047,0.00584029634632526,0.005820934232844315,0.005801559459541956,0.0057821723252011546,0.005762773128795505,0.005743362169484616,0.005723939746609489,0.005704506159687913,0.005685061708409841,0.005665606692632762,0.0056461414123770886,0.005626666167821521,0.005607181259298424,0.0055876869872891885,0.005568183652419606,0.005548671555455226,0.0055291509972967235,0.0055096222789752505,0.0054900857016478045,0.005470541566592573,0.005450990175204296,0.005431431828989618,0.005411866829562429,0.0053922954786392256,0.005372718078034449,0.005353134929655834,0.005333546335499756,0.005313952597646567,0.005294354018255945,0.005274750899562229,0.005255143543869758,0.005235532253548213,0.005215917331027952,0.005196299078795343,0.005176677799388106,0.005157053795390641,0.005137427369429367,0.005117798824168052,0.005098168462303141,0.005078536586559104,0.005058903499683746,0.005039269504443556,0.0050196349036190305,0.005,0.0049803650963809705,0.004960730495556446,0.0049410965003162536,0.004921463413440898,0.004901831537696859,0.00488220117583195,0.004862572630570633,0.004842946204609359,0.004823322200611894,0.004803700921204659,0.004784082668972048,0.004764467746451787,0.0047448564561302425,0.004725249100437773,0.004705645981744055,0.004686047402353433,0.004666453664500246,0.004646865070344168,0.004627281921965551,0.004607704521360776,0.004588133170437572,0.004568568171010384,0.004549009824795704,0.004529458433407428,0.0045099142983521965,0.004490377721024751,0.004470849002703278,0.0044513284445447734,0.004431816347580395,0.004412313012710813,0.004392818740701579,0.004373333832178478,0.0043538585876229125,0.004334393307367239,0.004314938291590161,0.004295493840312087,0.004276060253390512,0.004256637830515385,0.004237226871204496,0.004217827674798845,0.004198440540458045,0.004179065767155686,0.004159703653674741,0.004140354498602952,0.004121018600328227,0.0041016962570340374,0.004082387766694819,0.004063093427071376,0.004043813535706299,0.004024548389919359,0.004005298286802937,0.003986063523217439,0.003966844395786709,0.003947641200893473,0.003928454234674747,0.0039092837930172885,0.0038901301715530204,0.003870993665654482,0.003851874570430266,0.003832773180720475,0.003813689791092161,0.0037946246958348072,0.003775578188955763,0.003756550564175727,0.00373754211492421,0.0037185531343350165,0.0036995839152417173,0.003680634750173137,0.003661705931348838,0.003642797750674629,0.0036239104997380428,0.003605044469803854,0.003586199951809582,0.003567377236361008,0.0035485766137276892,0.003529798373838481,0.003511042806277075,0.003492310200277522,0.0034736008447197827,0.003454915028125263,0.0034362530386523728,0.0034176151640920695,0.0033990016918634416,0.003380412909009254,0.003361849102191533,0.0033433105576871447,0.0033247975613833803,0.003306310398773543,0.003287849354952552,0.003269414714612534,0.0032510067620384565,0.0032326257811037154,0.0032142720552657744,0.003195945867561791,0.0031776475006042517,0.0031593772365766104,0.00314113535722894,0.003122922143873584,0.0031047378773808275,0.0030865828381745515,0.0030684573062279208,0.00305036156105906,0.003032295881726743,0.0030142605468260974,0.002996255834484296,0.0029782820223562757,0.002960339387620454,0.002942428206974456,0.0029245487566308443,0.002906701312312861,0.002888886149250173,0.0028711035421746366,0.0028533537653160513,0.0028356370923979324,0.0028179537966332886,0.002800304150720424,0.0027826884268387087,0.002765106896644395,0.0027475598312664286,0.0027300475013022664,0.0027125701768136974,0.002695128127322689,0.002677721621807217,0.002660350928697134,0.0026430163158700118,0.0026257180506470278,0.00260845639978883,0.002591231629491423,0.0025740440053820812,0.002556893792515227,0.0025397812553683554,0.002522706657837962,0.002505670263235464,0.0024886723342831376,0.002471713133110078,0.0024547929212481437,0.0024379119596279366,0.002421070508574763,0.002404268827804637,0.002387507176420256,0.002370785812907022,0.002354104995129048,0.0023374649803251757,0.0023208660251050157,0.0023043083854449985,0.0022877923166844073,0.0022713180735214507,0.0022548859100093403,0.0022384960795523673,0.00222214883490199,0.002205844428152942,0.0021895831107393484,0.0021733651334308363,0.00215719074632868,0.0021410601988619393,0.002124973739783609,0.002108931617166784,0.0020929340784008473,0.0020769813701876335,0.0020610737385376348,0.0020452114287662125,0.0020293946854898076,0.0020136237526221647,0.0019978988733705804,0.001982220290232143,0.0019665882449900023,0.0019510029787096312,0.0019354647317351187,0.0019199737436854515,0.0019045302534508297,0.0018891344991889796,0.0018737867183214758,0.0018584871475300813,0.0018432360227531115,0.0018280335791817732,0.0018128800512565513,0.0017977756726635958,0.0017827206763311055,0.0017677152944257514,0.0017527597583490823,0.0017378542987339673,0.001722999145441031,0.001708194527555114,0.0016934406733817415,0.001678737810443593,0.0016640861654770005,0.001649485964428462,0.0016349374324511345,0.001620440793901377,0.0016059962723352912,0.0015916040905052692,0.0015772644703565563,0.001562977633023837,0.0015487437988278142,0.0015345631872718214,0.0015204360170384284,0.0015063625059860797,0.0014923428711457215,0.0014783773287174685,0.0014644660940672626,0.0014506093817235493,0.0014368074053739733,0.0014230603778620855,0.0014093685111840565,0.001395732016485406,0.0013821511040577538,0.001368625983335568,0.0013551568628929435,0.0013417439504403766,0.0013283874528215733,0.0013150875760102466,0.0013018445251069511,0.0012886585043359155,0.0012755297170418912,0.0012624583656870153,0.001249444651847702,0.0012364887762115152,0.0012235909385740823,0.0012107513378360163,0.0011979701719998454,0.0011852476381669559,0.00117258393253456,0.001159979250392661,0.0011474337861210543,0.0011349477331863151,0.0011225212841388282,0.0011101546306098093,0.001097847963308351,0.0010856014720184925,0.0010734153455962765,0.0010612897719668457,0.001049224938121548,0.0010372210301150464,0.0010252782330624499,0.001013396731136465,0.001001576707564547,0.000989818344626085,0.0009781218236495776,0.000966487325009851,0.0009549150281252633,0.0009434051114549497,0.0009319577524960654,0.0009205731277810447,0.0009092514128748819,0.000897992782372432,0.0008867974098957015,0.000875665468091183,0.0008645971286271903,0.0008535925621912122,0.0008426519384872733,0.0008317754262333282,0.0008209631931586497,0.0008102154060012456,0.0007995322305052905,0.0007889138314185679,0.0007783603724899257,0.0007678720164667541,0.0007574489250924821,0.0007470912591040697,0.0007367991782295391,0.0007265728411855104,0.0007164124056747523,0.0007063180283837472,0.0006962898649802824,0.0006863280701110408,0.0006764327973992251,0.0006666041994421796,0.0006568424278090445,0.000647147633038413,0.0006375199646360141,0.0006279595710724063,0.0006184665997806832,0.0006090411971542037,0.0005996835085443403,0.0005903936782582253,0.0005811718495565327,0.0005720181646512718,0.0005629327647035842,0.0005539157898215786,0.0005449673790581611,0.0005360876704088962,0.0005272768008098749,0.0005185349061356065,0.0005098621211969223,0.0005012585797388936,0.000492724414438771,0.00048425975690394475,0.00047586473766990324,0.00046753948619822686,0.0004592841308745932,0.00045109879900679495,0.00044298361682277356,0.0004349387094686785,0.0004269642010069319,0.00041906021441432073,0.00041122687158009433,0.00040346429330409106,0.00039577259929486907,0.0003881519081678658,0.0003806023374435663,0.00037312400354569007,0.00036571702179939605,0.0003583815064295065,0.0003511175705587433,0.0003439253262059822,0.00033680488428453005,0.0003297563546004073,0.0003227798458506637,0.0003158754656216928,0.00030904332038757975,0.00030228351550845524,0.00029559615522887275,0.0002889813426762011,0.00028243917985903256,0.0002759697676656098,0.0002695732058622735,0.00026324959309191874,0.000256999026872477,0.0002508216035954114,0.00024471741852423234,0.00023868656579302262,0.000232729138404994,0.0002268452282310446,0.0002210349260083494,0.00021529832133895588,0.00020963550268840447,0.00020404655738436419,0.00019853157161528467,0.00019309063042907026,0.00018772381773176416,0.00018243121628625625,0.00017721290771100962,0.00017206897247879716,0.00016699948991546364,0.0001620045381987012,0.00015708419435684463,0.0001522385342676824,0.0001474676326572877,0.00014277156309886575,0.0001381503980116172,0.0001336042086596251,0.00012913306515075328,0.000124737036435566,0.00012041619030626283,0.00011617059339563807,0.00011200031117604703,0.0001079054079584002,0.0001038859468911707,0.00009994198995942227,0.00009607359798384785,0.00009228083061983805,0.00008856374635655695,0.00008492240251604222,0.00008135685525232028,0.00007786715955054203,0.00007445336922613067,0.00007111553692395633,0.00006785371411752284,0.00006466795110817214,0.0000615582970243117,0.0000585247998206534,0.00005556750627747742,0.0000526864619999079,0.000049881711417212316,0.00004715329778211375,0.00004450126317012637,0.00004192564847890379,0.000039426493427611173,0.00003700383655631079,0.00003465771522536854,0.00003238816561487834,0.000030195222724102024,0.000028078920370931406,0.000026039291191367608,0.000024076366639015912,0.00002219017698460002,0.000020380751315498545,0.000018648117535293718,0.000016992302363341707,0.00001541333133436018,0.000013911228798036413,0.000012486017918649783,0.000011137720674714302,9.866357858642205e-6,8.671949076420883e-6,7.5545127473103385e-6,6.514066103562311e-6,5.550625190150482e-6,4.664204864525123e-6,3.854818796385496e-6,3.1224794674650227e-6,2.467198171342e-6,1.8889850132658426e-6,1.3878489099972135e-6,9.637975896759078e-7,6.168375916970615e-7,3.4697426661345345e-7,1.5421177605168258e-7,3.855309264721996e-8,0.0],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"group=300:1000\\u003cbr\\u003estep=%{x}\\u003cbr\\u003elr=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"300:1000\",\"line\":{\"color\":\"#2CA02C\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"300:1000\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000],\"xaxis\":\"x\",\"y\":[0.0,0.000033333333333333335,0.00006666666666666667,0.0001,0.00013333333333333334,0.00016666666666666666,0.0002,0.00023333333333333336,0.0002666666666666667,0.0003,0.0003333333333333333,0.00036666666666666667,0.0004,0.00043333333333333337,0.0004666666666666667,0.0005,0.0005333333333333334,0.0005666666666666666,0.0006,0.0006333333333333334,0.0006666666666666666,0.0007000000000000001,0.0007333333333333333,0.0007666666666666666,0.0008,0.0008333333333333333,0.0008666666666666667,0.0009,0.0009333333333333334,0.0009666666666666667,0.001,0.0010333333333333334,0.0010666666666666667,0.0011,0.0011333333333333332,0.0011666666666666668,0.0012,0.0012333333333333335,0.0012666666666666668,0.0013000000000000002,0.0013333333333333333,0.0013666666666666666,0.0014000000000000002,0.0014333333333333333,0.0014666666666666667,0.0015,0.0015333333333333332,0.0015666666666666667,0.0016,0.0016333333333333334,0.0016666666666666666,0.0017000000000000001,0.0017333333333333335,0.0017666666666666666,0.0018,0.0018333333333333333,0.0018666666666666669,0.0019,0.0019333333333333333,0.0019666666666666665,0.002,0.0020333333333333336,0.0020666666666666667,0.0021,0.0021333333333333334,0.002166666666666667,0.0022,0.0022333333333333333,0.0022666666666666664,0.0023,0.0023333333333333335,0.0023666666666666667,0.0024,0.0024333333333333334,0.002466666666666667,0.0025,0.0025333333333333336,0.0025666666666666667,0.0026000000000000003,0.002633333333333333,0.0026666666666666666,0.0027,0.0027333333333333333,0.002766666666666667,0.0028000000000000004,0.002833333333333333,0.0028666666666666667,0.0029,0.0029333333333333334,0.002966666666666667,0.003,0.0030333333333333336,0.0030666666666666663,0.0031,0.0031333333333333335,0.0031666666666666666,0.0032,0.0032333333333333333,0.003266666666666667,0.0033000000000000004,0.003333333333333333,0.0033666666666666667,0.0034000000000000002,0.0034333333333333334,0.003466666666666667,0.0034999999999999996,0.003533333333333333,0.0035666666666666668,0.0036,0.0036333333333333335,0.0036666666666666666,0.0037,0.0037333333333333337,0.0037666666666666664,0.0038,0.0038333333333333336,0.0038666666666666667,0.0039000000000000003,0.003933333333333333,0.003966666666666667,0.004,0.004033333333333333,0.004066666666666667,0.0040999999999999995,0.0041333333333333335,0.004166666666666667,0.0042,0.004233333333333334,0.004266666666666667,0.0043,0.004333333333333334,0.004366666666666666,0.0044,0.004433333333333333,0.0044666666666666665,0.0045000000000000005,0.004533333333333333,0.004566666666666667,0.0046,0.004633333333333333,0.004666666666666667,0.0047,0.004733333333333333,0.004766666666666667,0.0048,0.004833333333333334,0.004866666666666667,0.0049,0.004933333333333334,0.004966666666666667,0.005,0.005033333333333333,0.005066666666666667,0.0051,0.0051333333333333335,0.0051666666666666675,0.005200000000000001,0.005233333333333333,0.005266666666666666,0.0053,0.005333333333333333,0.005366666666666666,0.0054,0.005433333333333333,0.0054666666666666665,0.0055000000000000005,0.005533333333333334,0.005566666666666667,0.005600000000000001,0.005633333333333334,0.005666666666666666,0.005699999999999999,0.005733333333333333,0.0057666666666666665,0.0058,0.005833333333333334,0.005866666666666667,0.0059,0.005933333333333334,0.005966666666666667,0.006,0.006033333333333334,0.006066666666666667,0.0061,0.006133333333333333,0.0061666666666666675,0.0062,0.006233333333333333,0.006266666666666667,0.0063,0.006333333333333333,0.006366666666666667,0.0064,0.0064333333333333334,0.006466666666666667,0.006500000000000001,0.006533333333333334,0.006566666666666666,0.006600000000000001,0.006633333333333333,0.006666666666666666,0.0067,0.006733333333333333,0.0067666666666666665,0.0068000000000000005,0.006833333333333334,0.006866666666666667,0.0069,0.006933333333333334,0.006966666666666667,0.006999999999999999,0.007033333333333334,0.007066666666666666,0.0070999999999999995,0.0071333333333333335,0.007166666666666667,0.0072,0.007233333333333334,0.007266666666666667,0.0073,0.007333333333333333,0.007366666666666667,0.0074,0.0074333333333333335,0.0074666666666666675,0.0075,0.007533333333333333,0.007566666666666667,0.0076,0.007633333333333333,0.007666666666666667,0.0077,0.007733333333333333,0.0077666666666666665,0.0078000000000000005,0.007833333333333333,0.007866666666666666,0.0079,0.007933333333333334,0.007966666666666667,0.008,0.008033333333333333,0.008066666666666666,0.008100000000000001,0.008133333333333334,0.008166666666666666,0.008199999999999999,0.008233333333333334,0.008266666666666667,0.0083,0.008333333333333333,0.008366666666666666,0.0084,0.008433333333333334,0.008466666666666667,0.0085,0.008533333333333334,0.008566666666666667,0.0086,0.008633333333333333,0.008666666666666668,0.0087,0.008733333333333333,0.008766666666666667,0.0088,0.008833333333333334,0.008866666666666667,0.0089,0.008933333333333333,0.008966666666666666,0.009000000000000001,0.009033333333333334,0.009066666666666666,0.0091,0.009133333333333334,0.009166666666666667,0.0092,0.009233333333333333,0.009266666666666666,0.009300000000000001,0.009333333333333334,0.009366666666666667,0.0094,0.009433333333333334,0.009466666666666667,0.0095,0.009533333333333335,0.009566666666666666,0.0096,0.009633333333333334,0.009666666666666667,0.0097,0.009733333333333333,0.009766666666666667,0.0098,0.009833333333333333,0.009866666666666668,0.0099,0.009933333333333334,0.009966666666666667,0.01,0.009999949644960027,0.009999798580854355,0.009999546810725724,0.00999919433964529,0.009998741174712533,0.009998187325055106,0.009997532801828659,0.009996777618216606,0.009995921789429874,0.009994965332706574,0.009993908267311676,0.009992750614536606,0.009991492397698825,0.009990133642141357,0.00998867437523228,0.00998711462636417,0.009985454426953514,0.009983693810440073,0.009981832812286215,0.009979871469976196,0.0099778098230154,0.009975647912929556,0.009973385783263893,0.009971023479582257,0.009968561049466213,0.009965998542514065,0.009963336010339868,0.00996057350657239,0.009957711086854023,0.009954748808839673,0.009951686732195594,0.009948524918598173,0.009945263431732722,0.009941902337292155,0.009938441702975689,0.009934881598487478,0.009931222095535205,0.009927463267828633,0.009923605191078133,0.009919647942993149,0.009915591603280632,0.009911436253643444,0.009907181977778703,0.009902828861376101,0.009898376992116178,0.009893826459668558,0.009889177355690136,0.009884429773823238,0.009879583809693738,0.009874639560909117,0.00986959712705652,0.009864456609700725,0.009859218112382115,0.00985388174061459,0.009848447601883435,0.009842915805643155,0.009837286463315283,0.009831559688286121,0.009825735595904462,0.009819814303479266,0.009813795930277305,0.009807680597520746,0.009801468428384716,0.009795159547994828,0.009788754083424653,0.009782252163693158,0.009775653919762116,0.009768959484533461,0.009762168992846614,0.009755282581475769,0.009748300389127131,0.00974122255643613,0.00973404922596459,0.009726780542197845,0.009719416651541838,0.009711957702320174,0.009704403844771128,0.009696755231044619,0.009689012015199146,0.009681174353198686,0.009673242402909555,0.009665216324097222,0.009657096278423092,0.009648882429441256,0.009640574942595195,0.009632173985214437,0.009623679726511203,0.009615092337576988,0.009606411991379113,0.009597638862757255,0.009588773128419905,0.009579814966940834,0.009570764558755466,0.009561622086157273,0.00955238773329408,0.009543061686164372,0.00953364413261354,0.009524135262330098,0.009514535266841862,0.009504844339512096,0.009495062675535612,0.009485190471934843,0.009475227927555872,0.009465175243064427,0.00945503262094184,0.009444800265480967,0.009434478382782075,0.009424067180748692,0.009413566869083415,0.00940297765928369,0.00939229976463755,0.009381533400219317,0.00937067878288528,0.009359736131269312,0.009348705665778478,0.009337587608588589,0.00932638218363973,0.009315089616631751,0.009303710135019719,0.009292243968009331,0.009280691346552308,0.009269052503341736,0.009257327672807382,0.00924551709111097,0.00923362099614142,0.009221639627510075,0.00920957322654585,0.009197422036290386,0.009185186301493151,0.009172866268606514,0.00916046218578077,0.009147974302859156,0.009135402871372808,0.009122748144535705,0.00911001037723955,0.00909718982604866,0.009084286749194781,0.009071301406571893,0.009058234059730977,0.009045084971874737,0.009031854407852315,0.009018542634153944,0.009005149918905579,0.008991676531863507,0.008978122744408906,0.008964488829542377,0.008950775061878453,0.00893698171764006,0.00892310907465296,0.008909157412340149,0.008895127011716233,0.008881018155381766,0.008866831127517556,0.008852566213878947,0.008838223701790056,0.008823803880137994,0.008809307039367035,0.008794733471472778,0.008780083469996263,0.008765357330018056,0.008750555348152299,0.008735677822540748,0.008720725052846766,0.008705697340249275,0.008690594987436705,0.008675418298600883,0.008660167579430927,0.008644843137107058,0.008629445280294443,0.008613974319136958,0.008598430565250953,0.00858281433171896,0.008567125933083414,0.008551365685340286,0.008535533905932738,0.008519630913744724,0.00850365702909457,0.008487612573728513,0.00847149787081423,0.008455313244934324,0.00843905902207979,0.008422735529643444,0.00840634309641333,0.008389882052566104,0.008373352729660373,0.00835675546063002,0.008340090579777507,0.008323358422767128,0.00830655932661826,0.008289693629698563,0.008272761671717177,0.008255763793717867,0.008238700338072167,0.008221571648472472,0.00820437806992512,0.008187119948743448,0.00816979763254081,0.008152411470223568,0.008134961811984089,0.008117449009293669,0.008099873414895454,0.00808223538279735,0.008064535268264884,0.008046773427814041,0.0080289502192041,0.008011066001430412,0.007993121134717176,0.007975115980510187,0.007957050901469545,0.007938926261462366,0.007920742425555434,0.007902499760007868,0.007884198632263724,0.007865839410944611,0.00784742246584226,0.007828948167911073,0.007810416889260653,0.007791829003148312,0.007773184883971551,0.007754484907260513,0.0077357294496704304,0.0077169188889740295,0.007698053604053923,0.007679133974894983,0.007660160382576683,0.007641133209265423,0.007622052838206828,0.007602919653718044,0.007583734041179973,0.007564496387029531,0.0075452070787518566,0.007525866504872506,0.007506475054949625,0.00748703311956611,0.007467541090321735,0.007447999359825263,0.007428408321686542,0.0074087683705085765,0.007389079901879579,0.007369343312364994,0.007349558999499527,0.0073297273617791234,0.007309848798652949,0.007289923710515338,0.007269952498697734,0.007249935565460606,0.0072298733139853424,0.007209766148366135,0.007189614473601832,0.007169418695587791,0.007149179221107694,0.007128896457825364,0.007108570814276538,0.007088202699860656,0.007067792524832603,0.0070473407002944535,0.00702684763818718,0.0070063137512823715,0.006985739453173902,0.006965125158269619,0.006944471281782974,0.0069237782397246804,0.006903046448894321,0.00688227632687196,0.006861468292009726,0.006840622763423391,0.006819740160983923,0.006798820905309036,0.006777865417754709,0.0067568741204067145,0.006735847436072093,0.006714785788270658,0.0066936896012264584,0.0066725592998592275,0.006651395309775836,0.00663019805726171,0.006608967969272248,0.006587705473424223,0.006566410997987163,0.006545084971874737,0.006523727824636103,0.00650233998644726,0.006480921888102389,0.006459473961005168,0.0064379966371600865,0.006416490349163747,0.006394955530196147,0.006373392614011951,0.006351802034931764,0.006330184227833375,0.0063085396281430004,0.006286868671826512,0.006265171795380659,0.006243449435824276,0.00622170203068947,0.006199930018012829,0.006178133836326581,0.006156313924649761,0.006134470722479383,0.006112604669781572,0.0060907162069827134,0.006068805774960573,0.006046873815035422,0.006024920768961153,0.0060029470789163646,0.0059809531874954755,0.0059589395376998,0.005936906572928624,0.005914854736970274,0.005892784473993183,0.005870696228536944,0.005848590445503344,0.005826467570147426,0.005804328048068492,0.0057821723252011546,0.005760000847806337,0.005737814062462289,0.005715612416055598,0.00569339635577218,0.0056711663290882775,0.0056489227837614436,0.005626666167821521,0.005604396929561628,0.005582115517529114,0.005559822380516539,0.005537517967552625,0.005515202727893213,0.005492877111012218,0.005470541566592573,0.005448196544517168,0.005425842494859797,0.005403479867876086,0.005381109113994426,0.0053587306838068964,0.005336345028060198,0.005313952597646567,0.005291553843594694,0.005269149217060641,0.005246739169318756,0.005224324151752576,0.005201904615845743,0.005179481013172912,0.005157053795390641,0.0051346234142283145,0.005112190321479026,0.005089754968990486,0.005067317808655927,0.0050448792924049895,0.005022439872194628,0.005,0.004977560127805373,0.004955120707595011,0.004932682191344072,0.004910245031009515,0.004887809678520975,0.004865376585771687,0.004842946204609359,0.004820518986827089,0.004798095384154257,0.004775675848247427,0.0047532608306812465,0.004730850782939359,0.004708446156405307,0.004686047402353433,0.004663654971939802,0.004641269316193104,0.004618890886005576,0.004596520132123914,0.004574157505140204,0.004551803455482833,0.004529458433407428,0.004507122888987782,0.004484797272106789,0.004462482032447377,0.004440177619483461,0.0044178844824708866,0.004395603070438373,0.004373333832178478,0.0043510772162385575,0.004328833670911724,0.004306603644227821,0.004284387583944403,0.004262185937537712,0.004239999152193664,0.004217827674798845,0.004195671951931509,0.004173532429852576,0.004151409554496656,0.0041293037714630575,0.004107215526006817,0.004085145263029727,0.004063093427071376,0.0040410604623002,0.0040190468125045255,0.0039970529210836365,0.003975079231038848,0.003953126184964577,0.003931194225039427,0.0039092837930172885,0.003887395330218428,0.0038655292775206184,0.0038436860753502393,0.003821866163673421,0.0038000699819871705,0.003778297969310529,0.003756550564175727,0.0037348282046193422,0.003713131328173489,0.0036914603718569993,0.003669815772166625,0.003648197965068235,0.00362660738598805,0.003605044469803854,0.003583509650836254,0.003562003362839914,0.0035405260389948334,0.0035190781118976124,0.00349766001355274,0.0034762721753638995,0.003454915028125263,0.003433589002012838,0.003412294526575779,0.003391032030727752,0.003369801942738291,0.0033486046902241663,0.0033274407001407736,0.003306310398773543,0.003285214211729343,0.003264152563927908,0.003243125879593286,0.0032221345822452895,0.003201179094690967,0.003180259839016079,0.0031593772365766104,0.003138531707990274,0.00311772367312804,0.003096953551105679,0.0030762217602753206,0.0030555287182170276,0.0030348748417303823,0.0030142605468260974,0.002993686248717629,0.00297315236181282,0.0029526592997055484,0.0029322074751673977,0.002911797300139345,0.0028914291857234636,0.0028711035421746366,0.002850820778892305,0.00283058130441221,0.0028103855263981693,0.0027902338516338676,0.0027701266860146573,0.0027500644345393945,0.0027300475013022664,0.0027100762894846633,0.002690151201347052,0.0026702726382208776,0.0026504410005004733,0.002630656687635007,0.0026109200981204238,0.002591231629491423,0.002571591678313458,0.0025520006401747396,0.002532458909678266,0.0025129668804338904,0.002493524945050376,0.0024741334951274944,0.0024547929212481437,0.00243550361297047,0.0024162659588200285,0.0023970803462819586,0.002377947161793171,0.0023588667907345783,0.0023398396174233176,0.0023208660251050157,0.0023019463959460785,0.002283081111025973,0.00226427055032957,0.002245515092739488,0.0022268151160284503,0.0022081709968516865,0.0021895831107393484,0.002171051832088928,0.0021525775341577403,0.0021341605890553895,0.002115801367736276,0.002097500239992132,0.002079257574444565,0.0020610737385376348,0.0020429490985304556,0.0020248840194898154,0.002006878865282824,0.001988933998569589,0.001971049780795901,0.00195322657218596,0.0019354647317351187,0.0019177646172026514,0.0019001265851045469,0.0018825509907063327,0.0018650381880159106,0.0018475885297764305,0.0018302023674591932,0.0018128800512565513,0.0017956219300748794,0.001778428351527529,0.001761299661927832,0.0017442362062821321,0.0017272383282828253,0.001710306370301437,0.0016934406733817415,0.001676641577232873,0.0016599094202224935,0.0016432445393699802,0.0016266472703396284,0.0016101179474338966,0.0015936569035866698,0.0015772644703565563,0.0015609409779202105,0.0015446867550656768,0.0015285021291857703,0.0015123874262714893,0.0014963429709054321,0.0014803690862552755,0.0014644660940672626,0.0014486343146597152,0.0014328740669165858,0.0014171856682810386,0.0014015694347490509,0.0013860256808630427,0.0013705547197055583,0.0013551568628929435,0.0013398324205690744,0.0013245817013991163,0.0013094050125632972,0.0012943026597507267,0.0012792749471532362,0.0012643221774592517,0.001249444651847702,0.0012346426699819458,0.0012199165300037357,0.001205266528527223,0.001190692960632968,0.0011761961198620081,0.0011617762982099444,0.0011474337861210543,0.001133168872482444,0.001118981844618236,0.0011048729882837671,0.001090842587659851,0.001076890925347041,0.00106301828235994,0.001049224938121548,0.0010355111704576237,0.0010218772555910954,0.0010083234681364933,0.0009948500810944216,0.0009814573658460562,0.000968145592147684,0.0009549150281252633,0.0009417659402690254,0.0009286985934281078,0.0009157132508052207,0.0009028101739513406,0.000889989622760451,0.0008772518554642972,0.0008645971286271903,0.0008520256971408452,0.0008395378142192306,0.0008271337313934868,0.0008148136985068489,0.0008025779637096137,0.0007904267734541498,0.0007783603724899257,0.0007663790038585794,0.0007544829088890326,0.0007426723271926195,0.0007309474966582636,0.0007193086534476922,0.0007077560319906695,0.0006962898649802824,0.0006849103833682491,0.0006736178163602702,0.0006624123914114122,0.0006512943342215232,0.0006402638687306872,0.0006293212171147206,0.0006184665997806832,0.0006077002353624505,0.00059702234071631,0.0005864331309165849,0.0005759328192513074,0.0005655216172179245,0.0005551997345190341,0.0005449673790581611,0.0005348247569355735,0.0005247720724441285,0.0005148095280651566,0.0005049373244643879,0.0004951556604879049,0.00048546473315813854,0.00047586473766990324,0.00046635586738645986,0.00045693831383562757,0.0004476122667059207,0.0004383779138427274,0.00042923544124453487,0.00042018503305916777,0.00041122687158009433,0.0004023611372427471,0.0003935880086208882,0.00038490766242301356,0.0003763202734887977,0.0003678260147855628,0.0003594250574048058,0.0003511175705587433,0.0003429037215769082,0.0003347836759027789,0.0003267575970904457,0.00031882564680131396,0.00031098798480085565,0.000303244768955383,0.00029559615522887275,0.0002880422976798264,0.0002805833484581621,0.0002732194578021557,0.00026595077403541,0.0002587774435638679,0.00025169961087286973,0.00024471741852423234,0.00023783100715338623,0.00023104051546654015,0.00022434608023788494,0.00021774783630684248,0.00021124591657534775,0.0002048404520051722,0.00019853157161528467,0.00019231940247925572,0.00018620406972269578,0.0001801856965207338,0.0001742644040955399,0.00016844031171388052,0.00016271353668471656,0.00015708419435684463,0.00015155239811656562,0.00014611825938540935,0.000140781887617884,0.0001355433902992753,0.0001304028729434803,0.0001253604390908819,0.00012041619030626283,0.00011557022617676217,0.00011082264430986533,0.00010617354033144288,0.00010162300788382262,0.00009717113862389992,0.00009281802222129766,0.00008856374635655695,0.00008440839671936818,0.00008035205700685166,0.00007639480892186634,0.00007253673217136658,0.0000687779044647957,0.00006511840151252169,0.0000615582970243117,0.000058097662707846664,0.00005473656826727846,0.00005147508140182555,0.000048313267804407925,0.0000452511911603265,0.000042288913145976936,0.000039426493427611173,0.00003666398966013229,0.000034001457485935414,0.00003143895053378698,0.00002897652041774279,0.000026614216736108308,0.000024352087070443896,0.00002219017698460002,0.00002012853002380466,0.00001816718771378456,0.00001630618955992702,0.000014545573046486626,0.000012885373635829756,0.000011325624767719589,9.866357858642205e-6,8.50760230117542e-6,7.2493854633953745e-6,6.091732688325302e-6,5.034667293427053e-6,4.078210570127028e-6,3.22238178339318e-6,2.467198171342e-6,1.8126749448943435e-6,1.2588252874673467e-6,8.056603547090813e-7,4.531892742754007e-7,2.0141914564453244e-7,5.035503997385949e-8,0.0],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"scatter\":[{\"type\":\"scatter\"}]}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"step\"},\"tickmode\":\"linear\",\"tick0\":0,\"dtick\":100,\"range\":[0,1002]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"lr\"}},\"legend\":{\"title\":{\"text\":\"group\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Learning Rate Schedule\"},\"width\":800,\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d875d772-6abf-4b99-b556-1f307b638a12');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# three examples: [num_warmup_steps, num_training_steps]\n",
        "examples = [\n",
        "    [100, 1000],\n",
        "    [200, 1000],\n",
        "    [300, 1000],\n",
        "]\n",
        "\n",
        "dummy_model = torch.nn.Linear(1, 1)\n",
        "\n",
        "# three examples\n",
        "results = []\n",
        "base_lr = 0.01\n",
        "num_steps = 1001\n",
        "for idx, example in enumerate(examples):\n",
        "    # run each example\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        dummy_model.parameters(), lr=base_lr, betas=(0.9, 0.98), eps=1e-9\n",
        "    )\n",
        "    # lr_scheduler = LambdaLR(\n",
        "    #     optimizer=optimizer, lr_lambda=lambda step: rate(step, *example)\n",
        "    # )\n",
        "\n",
        "    # lr_scheduler = LambdaLR(\n",
        "    #     optimizer=optimizer, lr_lambda=lambda step: _get_cosine_schedule_with_warmup_lr_lambda(\n",
        "    #         step, num_warmup_steps=example[0], num_training_steps=example[1], num_cycles=0.5\n",
        "    #     )\n",
        "    # )\n",
        "\n",
        "    lr_scheduler = cosine_schedule_with_warmup(\n",
        "        optimizer=optimizer, num_warmup_steps=example[0], num_training_steps=example[1]\n",
        "    )\n",
        "\n",
        "    # save the learning rate at each step\n",
        "    for step in range(num_steps):\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        # record each step\n",
        "        d = {\n",
        "            'step': step,\n",
        "            'lr': lr,\n",
        "            'group': f\"{example[0]}:{example[1]}\"\n",
        "        }\n",
        "        results.append(d)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# plot\n",
        "fig = px.line(df, x=\"step\", y=\"lr\", color=\"group\", title='Learning Rate Schedule', template='none',)\n",
        "fig.update_layout(\n",
        "    width=800, height=400,\n",
        "    xaxis=dict(\n",
        "        tickmode='linear',\n",
        "        tick0=0,\n",
        "        dtick=100,\n",
        "        range=[0, 1002],\n",
        "    ),\n",
        "    # yaxis=dict(\n",
        "    #     tickmode='linear',\n",
        "    #     tick0=0,\n",
        "    #     dtick=0.002,\n",
        "    #     range=[0, 0.0102],\n",
        "    # ),\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a10f463",
      "metadata": {
        "id": "8a10f463"
      },
      "source": [
        "<br>\n",
        "\n",
        "# Part 3: Toy Training Example: Copy input\n",
        "\n",
        "> We can begin by trying out a simple copy-task. Given a random set\n",
        "> of input symbols from a small vocabulary, the goal is to generate\n",
        "> back those same symbols.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ee6655",
      "metadata": {
        "id": "18ee6655"
      },
      "source": [
        "## Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "334bdb3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:23.456326Z",
          "iopub.status.busy": "2022-05-02T01:25:23.455411Z",
          "iopub.status.idle": "2022-05-02T01:25:23.457254Z",
          "shell.execute_reply": "2022-05-02T01:25:23.457943Z"
        },
        "id": "334bdb3f"
      },
      "outputs": [],
      "source": [
        "def data_generator(V, batch_size, nbatches):\n",
        "    \"Generate random data for a src-tgt copy task.\"\n",
        "    for i in range(nbatches):\n",
        "        data = torch.randint(1, V, size=(batch_size, 10))\n",
        "        data[:, 0] = 1\n",
        "        src = data.requires_grad_(False).clone().detach()\n",
        "        tgt = data.requires_grad_(False).clone().detach()\n",
        "        yield Batch(src, tgt, pad=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33fe4433",
      "metadata": {
        "id": "33fe4433"
      },
      "source": [
        "## Loss Computation\n",
        "\n",
        "> We simply use cross entropy loss implemented by PyTorch `nn.CrossEntropyLoss`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a88cbe5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:23.462842Z",
          "iopub.status.busy": "2022-05-02T01:25:23.461999Z",
          "iopub.status.idle": "2022-05-02T01:25:23.464005Z",
          "shell.execute_reply": "2022-05-02T01:25:23.464702Z"
        },
        "id": "4a88cbe5"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)    # cross entropy loss w/ label smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c2487d7",
      "metadata": {
        "id": "9c2487d7"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00b7bdc2",
      "metadata": {
        "id": "00b7bdc2"
      },
      "source": [
        "### Greedy Decoding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "958119b5",
      "metadata": {
        "id": "958119b5",
        "lines_to_next_cell": 0,
        "tags": []
      },
      "source": [
        "> This code predicts a translation using greedy decoding for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8426fe69",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:23.470843Z",
          "iopub.status.busy": "2022-05-02T01:25:23.469910Z",
          "iopub.status.idle": "2022-05-02T01:25:23.471795Z",
          "shell.execute_reply": "2022-05-02T01:25:23.472524Z"
        },
        "id": "8426fe69",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    model.eval()\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.zeros(1, 1).fill_(start_symbol).type_as(src.data)\n",
        "    for i in range(max_len - 1):\n",
        "        causal_mask = create_causal_mask(ys.size(1)).type_as(src.data)\n",
        "        out = model.decode(ys, memory, src_mask, causal_mask)       # decoder input is placed first\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data[0]\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.zeros(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
        "        )\n",
        "    return ys"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ab21fc",
      "metadata": {
        "id": "49ab21fc"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "094253b3",
      "metadata": {
        "id": "094253b3"
      },
      "source": [
        "> Next we create a generic training and scoring function to keep\n",
        "> track of loss. We pass in a generic loss compute function that\n",
        "> also handles parameter updates.\n",
        "\n",
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42b940f8",
      "metadata": {
        "id": "42b940f8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TrainState:\n",
        "    \"\"\"Track number of steps, examples, and tokens processed\"\"\"\n",
        "\n",
        "    step: int = 0           # Steps in the current epoch\n",
        "    accum_step: int = 0     # Number of gradient accumulation steps\n",
        "    samples: int = 0        # total # of examples used\n",
        "    num_tokens: int = 0     # total # of tokens processed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f995c968",
      "metadata": {
        "id": "f995c968"
      },
      "outputs": [],
      "source": [
        "def run_epoch(\n",
        "    data_iter,\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    mode=\"train\",\n",
        "    accum_iter=1,\n",
        "    train_state=TrainState(),\n",
        "):\n",
        "    \"\"\"Train a single epoch\"\"\"\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    tokens = 0\n",
        "    n_accum = 0\n",
        "    for i, batch in enumerate(data_iter):\n",
        "        batch = batch.to(model.device)      # move inputs to model.device\n",
        "        logits = model(\n",
        "            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n",
        "        )\n",
        "        y_pred = model.generator(logits)\n",
        "        loss = criterion(y_pred.reshape(-1, y_pred.shape[-1]), batch.tgt_y.reshape(-1))\n",
        "        if mode == \"train\" or mode == \"train+log\":\n",
        "            loss.backward()\n",
        "            train_state.step += 1\n",
        "            train_state.samples += batch.src.shape[0]\n",
        "            train_state.num_tokens += batch.num_tokens.item()\n",
        "            if i % accum_iter == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                n_accum += 1\n",
        "                train_state.accum_step += 1\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_tokens += batch.num_tokens\n",
        "        tokens += batch.num_tokens\n",
        "        if i % 40 == 1 and (mode == \"train\" or mode == \"train+log\"):\n",
        "            lr = optimizer.param_groups[0][\"lr\"]\n",
        "            elapsed = time.time() - start\n",
        "            print(\n",
        "                (\n",
        "                    \"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f \"\n",
        "                    + \"| Tokens / Sec: %7.1f | Learning Rate: %6.1e\"\n",
        "                )\n",
        "                % (i, n_accum, loss, tokens / elapsed, lr)\n",
        "            )\n",
        "            start = time.time()\n",
        "            tokens = 0\n",
        "\n",
        "    return total_loss / total_tokens, train_state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9a55a02",
      "metadata": {
        "id": "c9a55a02"
      },
      "source": [
        "<br>\n",
        "\n",
        "## Train the Simple Model\n",
        "\n",
        "> Note: If the learning rate is set too large, the results may not be good enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a93be76",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T01:25:23.481831Z",
          "iopub.status.busy": "2022-05-02T01:25:23.480882Z",
          "iopub.status.idle": "2022-05-02T01:25:23.482798Z",
          "shell.execute_reply": "2022-05-02T01:25:23.483742Z"
        },
        "id": "6a93be76",
        "lines_to_next_cell": 2,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Train the simple copy task\n",
        "\n",
        "def run_toy_example(num_epochs=10, pre_norm=True, device='cpu'):\n",
        "    V = 11\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)    # cross entropy loss w/ label smoothing\n",
        "\n",
        "    model = create_model(V, V, embed_dim=512, num_layers=2, pre_norm=pre_norm)\n",
        "    model = model.to(device)\n",
        "\n",
        "    num_batches = 20\n",
        "    batch_size = 80\n",
        "    warmup_ratio = 0.1  # 10% of total training steps used for a linear warmup\n",
        "    num_training_steps = num_epochs * num_batches\n",
        "    num_warmup_steps = math.ceil(num_training_steps * warmup_ratio)\n",
        "    base_lr=0.001   # lr is important, large lr heats the performance\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(), lr=base_lr, betas=(0.9, 0.98), eps=1e-9\n",
        "    )\n",
        "    # lr_scheduler = LambdaLR(\n",
        "    #     optimizer=optimizer,\n",
        "    #     lr_lambda=lambda step: rate(\n",
        "    #         step, model_size=512, factor=1.0, warmup=400\n",
        "    #     ),\n",
        "    # )\n",
        "    lr_scheduler = cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()\n",
        "        run_epoch(\n",
        "            data_generator(V, batch_size, nbatches=num_batches),\n",
        "            model,\n",
        "            criterion,\n",
        "            optimizer,\n",
        "            lr_scheduler,\n",
        "            mode=\"train\",\n",
        "        )\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    # Inference examples\n",
        "    src = torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]).to(model.device)\n",
        "    max_len = src.shape[1]\n",
        "    src_mask = torch.ones(1, 1, max_len).to(model.device)\n",
        "    pred = greedy_decode(model, src, src_mask, max_len=max_len, start_symbol=0) # set start_symbol as 0\n",
        "    print(f\"\\nTarget:    {src}\")\n",
        "    print(f\"Predicted: {pred}\")\n",
        "\n",
        "    src = torch.LongTensor([[0, 1, 3, 5, 7, 9]]).to(model.device)\n",
        "    max_len = src.shape[1]\n",
        "    src_mask = torch.ones(1, 1, max_len).to(model.device)\n",
        "    pred = greedy_decode(model, src, src_mask, max_len=max_len, start_symbol=0)\n",
        "    print(f\"\\nTarget:    {src}\")\n",
        "    print(f\"Predicted: {pred}\")\n",
        "\n",
        "    src = torch.LongTensor([[0, 9, 2, 6, 4, 1, 6, 9, 8, 9]]).to(model.device)\n",
        "    max_len = src.shape[1]\n",
        "    src_mask = torch.ones(1, 1, max_len).to(model.device)\n",
        "    pred = greedy_decode(model, src, src_mask, max_len=max_len, start_symbol=0)\n",
        "    print(f\"\\nTarget:    {src}\")\n",
        "    print(f\"Predicted: {pred}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3cf2798",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "b3cf2798",
        "outputId": "ec97ff62-8f9c-4042-efd8-101ccbe2ae7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source (encoder) and target (decoder) embedding weights are not tied by default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-727043829.py:43: UserWarning:\n",
            "\n",
            "Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:  16.42 | Tokens / Sec:   245.7 | Learning Rate: 5.0e-05\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.44 | Tokens / Sec:   469.1 | Learning Rate: 5.5e-04\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3689532346.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_toy_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-129417716.py\u001b[0m in \u001b[0;36mrun_toy_example\u001b[0;34m(num_epochs, pre_norm, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         run_epoch(\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbatches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-727043829.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_iter, model, criterion, optimizer, scheduler, mode, accum_iter, train_state)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train+log\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mtrain_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtrain_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# GPU\n",
        "run_toy_example(num_epochs=20, pre_norm=True, device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0671ed5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0671ed5",
        "outputId": "eca50a12-8208-4eb2-9e5a-e28ed4483734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   6.14 | Tokens / Sec: 13191.3 | Learning Rate: 3.3e-05\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.35 | Tokens / Sec:  4716.8 | Learning Rate: 3.7e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.29 | Tokens / Sec: 16614.6 | Learning Rate: 7.0e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.13 | Tokens / Sec: 10801.3 | Learning Rate: 1.0e-03\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.00 | Tokens / Sec: 20208.6 | Learning Rate: 1.0e-03\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.98 | Tokens / Sec: 20759.9 | Learning Rate: 9.9e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.96 | Tokens / Sec: 20402.0 | Learning Rate: 9.7e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.92 | Tokens / Sec: 20061.1 | Learning Rate: 9.4e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.84 | Tokens / Sec: 20674.2 | Learning Rate: 9.1e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.65 | Tokens / Sec: 20608.1 | Learning Rate: 8.8e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.38 | Tokens / Sec: 19140.8 | Learning Rate: 8.4e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.26 | Tokens / Sec: 23368.0 | Learning Rate: 7.9e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.02 | Tokens / Sec: 22856.1 | Learning Rate: 7.4e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.80 | Tokens / Sec: 22467.4 | Learning Rate: 6.9e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.81 | Tokens / Sec: 23571.2 | Learning Rate: 6.4e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.68 | Tokens / Sec: 23109.1 | Learning Rate: 5.8e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.66 | Tokens / Sec: 23240.3 | Learning Rate: 5.2e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.65 | Tokens / Sec: 22960.7 | Learning Rate: 4.7e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.63 | Tokens / Sec: 19803.0 | Learning Rate: 4.1e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.62 | Tokens / Sec: 21746.8 | Learning Rate: 3.5e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.58 | Tokens / Sec: 20905.7 | Learning Rate: 3.0e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.59 | Tokens / Sec: 18741.2 | Learning Rate: 2.4e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.58 | Tokens / Sec: 22945.7 | Learning Rate: 2.0e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.56 | Tokens / Sec: 22881.6 | Learning Rate: 1.5e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.57 | Tokens / Sec: 22550.6 | Learning Rate: 1.1e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.56 | Tokens / Sec: 23349.0 | Learning Rate: 7.9e-05\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.56 | Tokens / Sec: 23455.6 | Learning Rate: 5.1e-05\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.55 | Tokens / Sec: 22301.7 | Learning Rate: 2.8e-05\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.54 | Tokens / Sec: 22305.3 | Learning Rate: 1.2e-05\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.54 | Tokens / Sec: 23108.8 | Learning Rate: 2.7e-06\n",
            "\n",
            "Target:    tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], device='cuda:0')\n",
            "Predicted: tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], device='cuda:0')\n",
            "\n",
            "Target:    tensor([[0, 1, 3, 5, 7, 9]], device='cuda:0')\n",
            "Predicted: tensor([[0, 1, 3, 5, 7, 9]], device='cuda:0')\n",
            "\n",
            "Target:    tensor([[0, 9, 2, 6, 4, 1, 6, 9, 8, 9]], device='cuda:0')\n",
            "Predicted: tensor([[0, 9, 2, 6, 4, 1, 6, 9, 8, 9]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# GPU\n",
        "run_toy_example(num_epochs=30, pre_norm=False, device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "351c0dee",
      "metadata": {
        "id": "351c0dee",
        "outputId": "cdcc1294-b646-458c-ff8c-c64717d2fc87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source (encoder) and target (decoder) embedding weights are not tied by default.\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:  16.72 | Tokens / Sec:   318.1 | Learning Rate: 5.0e-05\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.48 | Tokens / Sec:   346.9 | Learning Rate: 5.5e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.36 | Tokens / Sec:   464.2 | Learning Rate: 1.0e-03\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.35 | Tokens / Sec:   465.5 | Learning Rate: 9.9e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.34 | Tokens / Sec:   392.4 | Learning Rate: 9.7e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.35 | Tokens / Sec:   468.6 | Learning Rate: 9.3e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.21 | Tokens / Sec:   375.4 | Learning Rate: 8.8e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.01 | Tokens / Sec:   468.8 | Learning Rate: 8.1e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.92 | Tokens / Sec:   465.4 | Learning Rate: 7.4e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.82 | Tokens / Sec:   359.8 | Learning Rate: 6.6e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.63 | Tokens / Sec:   461.6 | Learning Rate: 5.8e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.34 | Tokens / Sec:   407.2 | Learning Rate: 4.9e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.08 | Tokens / Sec:   463.4 | Learning Rate: 4.0e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.86 | Tokens / Sec:   464.3 | Learning Rate: 3.2e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.77 | Tokens / Sec:   346.7 | Learning Rate: 2.4e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.75 | Tokens / Sec:   465.2 | Learning Rate: 1.7e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.68 | Tokens / Sec:   469.4 | Learning Rate: 1.1e-04\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.66 | Tokens / Sec:   439.7 | Learning Rate: 6.3e-05\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.66 | Tokens / Sec:   462.9 | Learning Rate: 2.7e-05\n",
            "Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.65 | Tokens / Sec:   348.5 | Learning Rate: 6.2e-06\n",
            "\n",
            "Target:    tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
            "Predicted: tensor([[0, 0, 0, 2, 3, 4, 6, 7, 8, 9]])\n",
            "\n",
            "Target:    tensor([[0, 1, 3, 5, 7, 9]])\n",
            "Predicted: tensor([[0, 0, 3, 5, 7, 9]])\n",
            "\n",
            "Target:    tensor([[0, 9, 2, 6, 4, 1, 6, 9, 8, 9]])\n",
            "Predicted: tensor([[0, 9, 2, 6, 4, 1, 6, 9, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "# CPU\n",
        "run_toy_example(num_epochs=20, pre_norm=True, device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "mF24dt1VhrfM"
      },
      "id": "mF24dt1VhrfM"
    },
    {
      "cell_type": "markdown",
      "id": "9a439ef0",
      "metadata": {
        "id": "9a439ef0"
      },
      "source": [
        "<br>\n",
        "\n",
        "# Part 4: A Real World Example\n",
        "\n",
        "> Now we consider a real-world example using the\n",
        "> Chinese-English Translation task to illustrate the whole\n",
        "> system.\n",
        "\n",
        "\n",
        "> The dataset used is available at:\n",
        "https://github.com/hemingkx/ChineseNMT/tree/master.\n",
        "> <br>For simplicity, we can also use a subset of the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ceb7001",
      "metadata": {
        "id": "1ceb7001",
        "tags": []
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "> We will load the dataset using `datasets` for\n",
        "> tokenization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1137e0",
      "metadata": {
        "id": "2f1137e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "a93c47f9f9524771bfc997cf95b18246",
            "b5d19cd29c784a74bd539616ee8556c2",
            "bb253ab223274d57bc1bd57bd278470d",
            "82de570e09cd4b279c1d0d5fbdb0d2fc",
            "2c9e42e7200d427e8a067fec0634fb6e",
            "df14734bb4ff40fd8b832b835f216d30",
            "cc3f96a6a2214d8998a1c8e932dbe848",
            "aad10d59a93e479190e92e4a78782920",
            "9389608316574119a315b3347447887d",
            "fe860fa79ccf421a89138162a5de6802",
            "a327445ddf4740d69658969e2b353721",
            "48bc680ff5b54051b3334ac31c7f72ce",
            "58f62bf15c2d4e87a2841c4af83b6f8b",
            "a3abd746816b45b9936e339beab27873",
            "d705e8651b394e77840cef0f4178a457",
            "68de719e796e4c7a98bcb6649894b811",
            "73812ef70f2649b0870108c4fab8bfb6",
            "8b3a95077dea44f6a2d35f3c93bdc579",
            "240a2eb2efe34b64aceb1920e13ee6c1",
            "45f5adc4803c443aabefdf9690384fec",
            "b07873c079334e2fbdb8da85a56685da",
            "2cc8d0cc38c543a2acb0f19eb54b96df",
            "e7d39ad4a88a4ab2bc7b2885e54fcf2c",
            "a1425386a9194f8ea58b2b7541449a80",
            "e46b836264934fe99dea31967926f00f",
            "f5b0d1f3e1d74422bce41f96b4eebfb3",
            "a41cbc230a4f4fa288d55949080fa4a5",
            "4099f8a847f0427b908017a5f3f1d46a",
            "7fcc78aa3d0d4770a6768977ddf3cd06",
            "989f89b61f914ef1acee2c0c8c903ad4",
            "b816c14689b64d73a59a6e5f752ca155",
            "5928634cb6ba4d80886f83959cdbd518",
            "270a4c3556af49019e65a1ef91946e10",
            "32ec5efd697849a79d9a232739211e8f",
            "ce040bae9cb14586b5bf81fd1026771a",
            "31519438c3694db9bfa9bc8ae6f0eb35",
            "13f73975c07d40b19fe3adb0d87a64ee",
            "34bbe527548846bb876a4da41710029c",
            "3a7e1c360c7b49d39829912e608c8df1",
            "62a440d2ddac4a209b43019b7e916b98",
            "49a4504b86344992ab85916f5e4b0c79",
            "2d96cb7fda2a415ca78398bfd45e1a9a",
            "751eab0965684c978092656d8d863acb",
            "71cf84f4da8947019022cbaa3a5b4686"
          ]
        },
        "outputId": "78eb350b-749f-42f2-bc50-64a7ac5c65a4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/69.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a93c47f9f9524771bfc997cf95b18246"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48bc680ff5b54051b3334ac31c7f72ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/9.95M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7d39ad4a88a4ab2bc7b2885e54fcf2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32ec5efd697849a79d9a232739211e8f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# train_dataset = datasets.load_dataset('json', data_files='data/train.json', split=\"train\")\n",
        "# eval_dataset = datasets.load_dataset('json', data_files='data/dev.json', split=\"train\")\n",
        "\n",
        "train_dataset = datasets.load_dataset('json', data_files='https://raw.githubusercontent.com/yflyzhang/AnnotatedTransformer/refs/heads/main/data/train.json', split=\"train\")\n",
        "eval_dataset = datasets.load_dataset('json', data_files='https://raw.githubusercontent.com/yflyzhang/AnnotatedTransformer/refs/heads/main/data/dev.json', split=\"train\")\n",
        "\n",
        "# train_dataset = datasets.load_dataset('json', data_files='https://raw.githubusercontent.com/hemingkx/ChineseNMT/refs/heads/master/data/json/train.json', split=\"train\")\n",
        "# eval_dataset = datasets.load_dataset('json', data_files='https://raw.githubusercontent.com/hemingkx/ChineseNMT/refs/heads/master/data/json/dev.json', split=\"train\")\n",
        "\n",
        "train_dataset = train_dataset.rename_columns({'0': 'english', '1': 'chinese'})\n",
        "eval_dataset = eval_dataset.rename_columns({'0': 'english', '1': 'chinese'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a51e92a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a51e92a",
        "outputId": "28d792ef-be52-46fb-b7db-aa6d3cef50a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['english', 'chinese'],\n",
              "     num_rows: 176943\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['english', 'chinese'],\n",
              "     num_rows: 25278\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_dataset, eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab82a11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eab82a11",
        "outputId": "824f3c90-0740-48a0-f560-483083010763"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'english': 'When the British economist John Maynard Keynes anticipated the “euthanasia of the rentier” in his 1936 book The General Theory of Employment, Interest and Money, he was referring to a financial class that served no purpose other than to exploit scarce capital for its own benefit.',\n",
              " 'chinese': '当英国经济学家约翰·梅纳德·凯恩斯（John Maynard Keynes）在他1936年出版的《就业，利益和货币通论》一书中预测“食利者的消亡”时，他指的是一个除了为自身利益尽可能搜刮资本之外什么都不干的金融阶级。'}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "train_dataset[100]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Due to limited gpu resource, consider to use a random sample to train the model in Google Colab\n",
        "import random\n",
        "sample_ids = random.sample(range(len(train_dataset)), 50000)\n",
        "\n",
        "train_dataset = train_dataset.select(sample_ids)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRJnqHljwXrb",
        "outputId": "08c414f3-e9a8-44be-d2a3-4edc6b5b7aa1"
      },
      "id": "dRJnqHljwXrb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['english', 'chinese'],\n",
              "    num_rows: 50000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99fc3a73",
      "metadata": {
        "id": "99fc3a73"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dfddcd6",
      "metadata": {
        "id": "4dfddcd6"
      },
      "source": [
        "\n",
        "## Train Tokenizer\n",
        "\n",
        "Train tokenizer from an old one\n",
        "\n",
        "> RoBERTa is a widely used pretrained language model: https://huggingface.co/docs/transformers/en/model_doc/roberta\n",
        "> <br>We can use RoBERTa tokenizer as the base tokenizer and train it on our data so that it can better adapt to the specific domain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7c41d07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "5936b79a9c83435c8d0d9ebadf1da18f",
            "965402349a874ca7a0b7c88cb24edbd6",
            "6cf832ba855d4c4f80758ea47318154b",
            "6c57b0feb8ec4c42b2555c5d6af2a10f",
            "27f37bc26c6649d8bbcabb42b1656783",
            "99bfe6ba1ea34c0a9de441a60fe6bac6",
            "1ad5cd94af6f45768d252bba1715c274",
            "1d95b77cfdd548ff868301edd60d01eb",
            "af0ce552f63549439271e2a22b413f0f",
            "07c7c82243da4327a5f31b0b72c53719",
            "bad392f6ee7743929b1aafd54d35942f",
            "b67caae8b1b8438fba55f36e976c532b",
            "e33f35a5d87145f0b4859e98771718a8",
            "dd2c23b013cd48f88a6f4f042489b283",
            "d5ae167be06c490db896940d9f325bdd",
            "70fd2d3c080e4b4eba22492e7dfdb2ac",
            "1ee4d8e185f0474b9a781617798bb1ab",
            "45d5d65e37d4409394e512ef7007679c",
            "f6fa5da215844a20ab7829539be3c214",
            "91542acec03f4664a572b803dd5501ec",
            "c89afeb7f0514905a295524d4c2cd44f",
            "fb7d4dd968ca465d9e66a704bfa6cabc",
            "ae836899b27b47ff8270b49f41f5712a",
            "ebba15a232554b10b7fec0fd312a42ef",
            "e1293b26d33b40adb83d5013404ebb54",
            "2fffb82518fe413fa2f8a0ae32ae3f6a",
            "8882e9fc34f34681919d7d468eb39f24",
            "464e71fb8c614cbcab9db270f1e00b94",
            "1a7a0570dca24a6cbdfde1cb21caa707",
            "208ca23c381d4f78bf36bedd043c7ce8",
            "87e597e641aa41a49297dc56f9b96fb0",
            "d171c6fa90da4bfbb9586b8d0f440ae6",
            "048c14c951744150ba338110c13426e3",
            "002ad56ce9b0491298a79e046fb29859",
            "dc001015ca3b4b3199a0583b14cfb5bd",
            "c2d57f19dc544049a58cce8b80ec16e4",
            "db42350cbeaa4c8a8b1dad100eda2a1e",
            "7d681fdb70a84c2e8b895a0bde56f551",
            "05b007b8857a4a1ca5be1d0f2626d6a0",
            "af1c90febc384adfaf2091b55813b551",
            "d0ef7972a49a4ae0abb7fa970fb89fb6",
            "7be200e2090e49288c66f39e4b3228e5",
            "4876a4a4577e45dbb1f67bfe74133a33",
            "ee60114275934baa8d00221371069412",
            "3b9ba46e5da54709b3943298d3c9f429",
            "902ee27ce7c64bb0a613dbc5a9a86108",
            "e90e2bba5b15433c92c107698dcfe422",
            "e1d5b743ae9a4a4d94dde10f2d6192dd",
            "ec395712437740afacb20dc35a661043",
            "0be75ea226bb4da78201efab33cb27bb",
            "201a7a8d2ced476c857f91b172515625",
            "1d2a3801797f437c88236bd8d40e6eed",
            "8b7a212af88942d5bcb99360efbb469e",
            "9daeb8ba7437498d9e4be31884be935d",
            "e7c42b8dbdfb40a1a1191e0fc86a698a"
          ]
        },
        "id": "d7c41d07",
        "outputId": "a9c6e45b-3ce8-431d-ab14-4c31ee2822c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:\n",
            "\n",
            "\n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5936b79a9c83435c8d0d9ebadf1da18f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b67caae8b1b8438fba55f36e976c532b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae836899b27b47ff8270b49f41f5712a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "002ad56ce9b0491298a79e046fb29859"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b9ba46e5da54709b3943298d3c9f429"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "# load RoBERTa tokenizer\n",
        "old_tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ebe56a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6ebe56a",
        "outputId": "1f983bcd-d7f6-4e01-cc3a-56f1e422d9c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# shall be a fast tokenizer\n",
        "old_tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62242067",
      "metadata": {
        "id": "62242067"
      },
      "outputs": [],
      "source": [
        "# set train data iterator\n",
        "def get_training_corpus(batch_size=1000):\n",
        "    for i in range(0, len(train_dataset), batch_size):\n",
        "        samples = train_dataset[i : i + batch_size]\n",
        "        yield samples[\"english\"] + samples[\"chinese\"]\n",
        "\n",
        "# train data iterator\n",
        "training_corpus = get_training_corpus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "775560cc",
      "metadata": {
        "id": "775560cc"
      },
      "outputs": [],
      "source": [
        "# train tokenizer from an old one with specified vocabulary size\n",
        "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, vocab_size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d315e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86d315e8",
        "outputId": "9cb422b0-75a2-4a51-c68f-d8a9bccd6dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [0, 100, 657, 7137, 328, 2], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n",
            "{'input_ids': [0, 47876, 3602, 36714, 23133, 15389, 48827, 48818, 18400, 43251, 4394, 10172, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "# before training the tokenizer\n",
        "print(old_tokenizer('I love Shanghai!'))\n",
        "print(old_tokenizer('我爱上海！'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed108df1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed108df1",
        "outputId": "3c48c5a6-2690-4042-dfc3-cbe6efc681f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [0, 45, 346, 1626, 3872, 283, 758, 3356, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "{'input_ids': [0, 589, 4008, 498, 1796, 271, 228, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "# after training the tokenizer\n",
        "print(tokenizer('I love Shanghai!'))\n",
        "print(tokenizer('我爱上海！'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4644cc7c",
      "metadata": {
        "id": "4644cc7c"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c291712b",
      "metadata": {
        "id": "c291712b"
      },
      "source": [
        "## Tokenize Data\n",
        "\n",
        "> To better illustrate the process, we only keep `input_ids` from the tokenized data,\n",
        "although `attention_mask` is also very useful to construct the masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a379994",
      "metadata": {
        "id": "5a379994"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 128\n",
        "\n",
        "def preprocess_function(row):\n",
        "    tokenized_row = {}\n",
        "\n",
        "    # keep `input_ids` only\n",
        "    tokenized_row['src'] = tokenizer(row['english'], max_length=max_seq_length, truncation=True)['input_ids']\n",
        "    tokenized_row['tgt'] = tokenizer(row['chinese'], max_length=max_seq_length, truncation=True)['input_ids']\n",
        "\n",
        "    return tokenized_row\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ad8ec22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "5a8a6903d7b6473f8f03ada15535ec22",
            "be0467d812d84fe78a1705d04cb218a5",
            "2e72678b570644f1b5715dedd003749a",
            "300b20bf33ed4741b0cadacaf302c246",
            "5c27665501414ca190fb5c4e8848db3f",
            "1ccfa428499d416b8e5406a27bf56652",
            "235770e5cd374301b02760e888538ca4",
            "e1edcfdf1b6943699fcec0b5f952f43b",
            "cbada46cf59c45ce9a715756f001f882",
            "6686080ff6e549a9a7393ca9198be6e0",
            "ef20c534c37c4ef8a8e1468305eb7f01",
            "6128b06f4525458e8a66c1442cfe0ddf",
            "33f5036a316d4424a3fc13800adeeda0",
            "9cddcd1d079646ccbc58fa7de2dd62d7",
            "1471cf1c4131449fb8a9740e45b93e20",
            "3263b827e5be45a4b211210bb300a819",
            "19c621b59d4c4dfd8067d0ef54b9647a",
            "85344b982db942b687bd932633a92893",
            "59a9463f03c341608f30bc30cda03c0b",
            "ab62503d6c9747598767908c2f52ca79",
            "830ae40aa0dd4c2ea80ef29768946a54",
            "1e1a5666a6f443c38500bf9861792ed3"
          ]
        },
        "id": "7ad8ec22",
        "outputId": "bdf78ffb-3b9d-4020-a806-63734a4a5ed9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a8a6903d7b6473f8f03ada15535ec22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/25278 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6128b06f4525458e8a66c1442cfe0ddf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_dataset = train_dataset.map(\n",
        "    preprocess_function,\n",
        "    # remove_columns=column_names,\n",
        "    desc=\"Tokenizing\",\n",
        ")\n",
        "\n",
        "eval_dataset = eval_dataset.map(\n",
        "    preprocess_function,\n",
        "    # remove_columns=column_names,\n",
        "    desc=\"Tokenizing\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9830d10d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9830d10d",
        "outputId": "de90bdf6-a7d9-4e5e-c423-4860ba9cbab8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['english', 'chinese', 'src', 'tgt'],\n",
              "     num_rows: 50000\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['english', 'chinese', 'src', 'tgt'],\n",
              "     num_rows: 25278\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "train_dataset, eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50010e59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50010e59",
        "outputId": "a6b3205b-2938-430e-bd86-663a58f3e021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['english', 'chinese', 'src', 'tgt'])\n",
            "{'english': 'The cornerstone of such proposals is the implementation of better collective action clauses (CACs), which would make restructuring proposals approved by a supermajority of creditors binding on all others.', 'chinese': '这些提案的基础是施行更好的集体行动条款（CACs），这将使获得绝大多数债权人批准的重组协议书能同时对其余债权人产生强制力。', 'src': [0, 445, 1992, 2833, 324, 934, 306, 1152, 8452, 354, 270, 8906, 306, 2275, 7375, 3864, 1221, 69, 4194, 888, 5314, 39, 87, 2227, 815, 712, 1879, 9823, 8452, 1852, 2303, 541, 263, 9192, 1002, 69, 1747, 469, 306, 6932, 292, 8430, 405, 811, 3060, 18, 2], 'tgt': [0, 894, 789, 1479, 6118, 336, 1066, 483, 5749, 6404, 1823, 6799, 579, 5314, 39, 87, 2385, 7832, 885, 1757, 7796, 7413, 5556, 268, 6334, 2263, 3608, 425, 1530, 5959, 3488, 7413, 2095, 7309, 532, 287, 2]}\n"
          ]
        }
      ],
      "source": [
        "example = train_dataset[100]\n",
        "print(example.keys())\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a792550",
      "metadata": {
        "id": "2a792550"
      },
      "source": [
        "<br>\n",
        "\n",
        "## Pad Sequence Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d55f2615",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d55f2615",
        "outputId": "88f29764-01df-4752-8cb2-bb7a5d2270d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'english': 'China’s government is production-oriented by nature.', 'chinese': '中国政府是生产导向的。', 'src': [0, 3385, 372, 87, 852, 354, 4088, 17, 9681, 297, 541, 6089, 18, 2], 'tgt': [0, 7574, 336, 1955, 8884, 268, 287, 2]}\n",
            "{'english': 'In all of these efforts, there is one common imperative: matching words with deeds.', 'chinese': '在所有这些工作中，有一项共同的当务之急：言行一致。', 'src': [0, 782, 811, 306, 1343, 3015, 16, 1137, 354, 1058, 3315, 6697, 1203, 30, 2701, 7427, 5203, 485, 386, 297, 87, 18, 2], 'tgt': [0, 334, 5463, 1847, 400, 276, 369, 4754, 2529, 268, 677, 905, 615, 3019, 1032, 1554, 483, 4138, 287, 2]}\n",
            "{'english': 'Chinese families have been reluctant to convert much of this newfound income into discretionary spending.', 'chinese': '中国家庭不愿意将新增收入的大头用于自由支配支出。', 'src': [0, 3128, 1636, 7059, 561, 929, 9810, 626, 302, 429, 6124, 1363, 306, 764, 965, 74, 1689, 2757, 1309, 2226, 2438, 307, 746, 2846, 18, 2], 'tgt': [0, 400, 558, 2367, 356, 3901, 537, 645, 688, 1670, 3719, 2137, 3308, 1621, 875, 2956, 2932, 287, 2]}\n"
          ]
        }
      ],
      "source": [
        "features = train_dataset.select(range(3))   # a subset of dataset\n",
        "\n",
        "for row in features:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef0b2a08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef0b2a08",
        "outputId": "e38ddb4e-d864-4f58-fc91-3125cd260a66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0, 3385,  372,   87,  852,  354, 4088,   17, 9681,  297,  541, 6089,\n",
              "           18,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1],\n",
              "        [   0,  782,  811,  306, 1343, 3015,   16, 1137,  354, 1058, 3315, 6697,\n",
              "         1203,   30, 2701, 7427, 5203,  485,  386,  297,   87,   18,    2,    1,\n",
              "            1,    1],\n",
              "        [   0, 3128, 1636, 7059,  561,  929, 9810,  626,  302,  429, 6124, 1363,\n",
              "          306,  764,  965,   74, 1689, 2757, 1309, 2226, 2438,  307,  746, 2846,\n",
              "           18,    2]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "to_pad = []\n",
        "for row in features:\n",
        "    to_pad.append(torch.LongTensor(row['src']))\n",
        "\n",
        "pad_sequence(to_pad, batch_first=True, padding_value=tokenizer.pad_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "287224bd",
      "metadata": {
        "id": "287224bd"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa607c5e",
      "metadata": {
        "id": "aa607c5e"
      },
      "source": [
        "## Data Collator and Dataloader\n",
        "\n",
        "> Data collators are objects that will form a batch by using a list of dataset elements as input.\n",
        "> These elements are of the same type as the elements of `train_dataset` or `eval_dataset`.\n",
        "> To be able to build batches, data collators may apply some processing (like padding).\n",
        "> Some data collators may also apply some random data augmentation (like random masking) on the formed batch.\n",
        "> More sophisticate data collator examples can be found at: https://huggingface.co/docs/transformers/en/main_classes/data_collator\n",
        "\n",
        "> Here we implement the data collator in two ways:\n",
        "> <br>Either `data_collator_with_padding` or `DataCollatorWithPadding` is ok."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5cab53",
      "metadata": {
        "id": "8c5cab53"
      },
      "outputs": [],
      "source": [
        "def data_collator_with_padding(features, padding_value):\n",
        "    src_to_pad = []\n",
        "    tgt_to_pad = []\n",
        "    for row in features:\n",
        "        src_to_pad.append(torch.LongTensor(row['src']))\n",
        "        tgt_to_pad.append(torch.LongTensor(row['tgt']))\n",
        "\n",
        "    padded_batch = {}\n",
        "    padded_batch['src'] = pad_sequence(\n",
        "        src_to_pad,\n",
        "        batch_first=True,\n",
        "        padding_value=padding_value\n",
        "    )\n",
        "    padded_batch['tgt'] = pad_sequence(\n",
        "        tgt_to_pad,\n",
        "        batch_first=True,\n",
        "        padding_value=padding_value\n",
        "    )\n",
        "    # return padded_batch\n",
        "\n",
        "    return Batch(padded_batch['src'], padded_batch['tgt'], pad=padding_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4371907",
      "metadata": {
        "id": "d4371907"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataCollatorWithPadding:\n",
        "    \"\"\"\n",
        "    Only parameter tokenizer is used in the example,\n",
        "    but other parameters may provide additional controls.\n",
        "    \"\"\"\n",
        "    padding_value: int = None      # padding\n",
        "    # padding: Union[bool, str] = True\n",
        "    # pad_to_multiple_of: Optional[int] = None\n",
        "    # return_tensors: str = \"pt\"\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        src_to_pad = []\n",
        "        tgt_to_pad = []\n",
        "        for row in features:\n",
        "            src_to_pad.append(torch.LongTensor(row['src']))\n",
        "            tgt_to_pad.append(torch.LongTensor(row['tgt']))\n",
        "\n",
        "        padded_batch = {}\n",
        "        padded_batch['src'] = pad_sequence(\n",
        "            src_to_pad,\n",
        "            batch_first=True,\n",
        "            padding_value=self.padding_value\n",
        "        )\n",
        "        padded_batch['tgt'] = pad_sequence(\n",
        "            tgt_to_pad,\n",
        "            batch_first=True,\n",
        "            padding_value=self.padding_value\n",
        "        )\n",
        "\n",
        "        # return padded_batch   # return simple padded batch\n",
        "\n",
        "        # return batched sample with processed `tgt_y` and masks\n",
        "        return Batch(padded_batch['src'], padded_batch['tgt'], pad=tokenizer.pad_token_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "505e7386",
      "metadata": {
        "id": "505e7386"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "# from functools import partial\n",
        "# data_collator = partial(data_collator_with_padding, padding_value=tokenizer.pad_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8a5de61",
      "metadata": {
        "id": "e8a5de61"
      },
      "outputs": [],
      "source": [
        "# create data loader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,     # drop last\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f295c13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f295c13",
        "outputId": "787e4184-21ec-46a4-fc1d-b13bd744d27a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': torch.Size([128, 92]),\n",
              " 'src_mask': torch.Size([128, 1, 92]),\n",
              " 'tgt': torch.Size([128, 77]),\n",
              " 'tgt_y': torch.Size([128, 77]),\n",
              " 'tgt_mask': torch.Size([128, 77, 77]),\n",
              " 'num_tokens': torch.Size([])}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "for batch in train_dataloader:\n",
        "    break\n",
        "\n",
        "{k: v.shape for k,v in batch.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dffc6e91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dffc6e91",
        "outputId": "0789c899-4a73-42f4-f592-3fa8bf9b41e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3896)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "batch.num_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4604b99e",
      "metadata": {
        "id": "4604b99e"
      },
      "source": [
        "<br>\n",
        "\n",
        "## Train the System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "162ee398",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "162ee398",
        "outputId": "a5cdbf0b-94a2-4f0b-98e1-69dd3ce7c256"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3910b597",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3910b597",
        "outputId": "e82474df-5e57-48ad-bf0b-86c3f8d3ba57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 is enabled.\n"
          ]
        }
      ],
      "source": [
        "device = 0\n",
        "if not torch.cuda.is_available():\n",
        "    # use cpu if cuda is not available\n",
        "    device = 'cpu'\n",
        "print(f'device-{torch.device(device)} is used.')\n",
        "\n",
        "model = create_model(\n",
        "    src_vocab_size=tokenizer.vocab_size,\n",
        "    tgt_vocab_size=tokenizer.vocab_size,\n",
        "    embed_dim=512,\n",
        "    num_layers=6,\n",
        "    pre_norm=True,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model parameters\n",
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "TUXoD4igGFTy"
      },
      "id": "TUXoD4igGFTy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b131afe2",
      "metadata": {
        "id": "b131afe2"
      },
      "outputs": [],
      "source": [
        "# Since we use one tokenier for both source and target inputs in the example,\n",
        "# we can tie source embedding and target embedding weights\n",
        "model.tie_weights()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model parameters\n",
        "sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Note the differences of number of trainable parameters\n",
        "# before and after the weight tie"
      ],
      "metadata": {
        "id": "e1E89ktvGIwi"
      },
      "id": "e1E89ktvGIwi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bc23683",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bc23683",
        "outputId": "d01e2bb9-1ac5-44a4-8d92-f991f0b769f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[ 0.0048,  0.0099, -0.0103,  ..., -0.0069,  0.0011, -0.0177],\n",
              "         [ 0.0085, -0.0100, -0.0006,  ..., -0.0068,  0.0202,  0.0073],\n",
              "         [ 0.0186,  0.0130,  0.0179,  ...,  0.0214, -0.0074, -0.0235],\n",
              "         ...,\n",
              "         [-0.0231, -0.0191,  0.0112,  ..., -0.0082, -0.0047, -0.0104],\n",
              "         [-0.0106, -0.0232, -0.0012,  ...,  0.0116, -0.0215,  0.0014],\n",
              "         [ 0.0049, -0.0020, -0.0092,  ..., -0.0015, -0.0064,  0.0144]],\n",
              "        device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0048,  0.0099, -0.0103,  ..., -0.0069,  0.0011, -0.0177],\n",
              "         [ 0.0085, -0.0100, -0.0006,  ..., -0.0068,  0.0202,  0.0073],\n",
              "         [ 0.0186,  0.0130,  0.0179,  ...,  0.0214, -0.0074, -0.0235],\n",
              "         ...,\n",
              "         [-0.0231, -0.0191,  0.0112,  ..., -0.0082, -0.0047, -0.0104],\n",
              "         [-0.0106, -0.0232, -0.0012,  ...,  0.0116, -0.0215,  0.0014],\n",
              "         [ 0.0049, -0.0020, -0.0092,  ..., -0.0015, -0.0064,  0.0144]],\n",
              "        device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0048,  0.0099, -0.0103,  ..., -0.0069,  0.0011, -0.0177],\n",
              "         [ 0.0085, -0.0100, -0.0006,  ..., -0.0068,  0.0202,  0.0073],\n",
              "         [ 0.0186,  0.0130,  0.0179,  ...,  0.0214, -0.0074, -0.0235],\n",
              "         ...,\n",
              "         [-0.0231, -0.0191,  0.0112,  ..., -0.0082, -0.0047, -0.0104],\n",
              "         [-0.0106, -0.0232, -0.0012,  ...,  0.0116, -0.0215,  0.0014],\n",
              "         [ 0.0049, -0.0020, -0.0092,  ..., -0.0015, -0.0064,  0.0144]],\n",
              "        device='cuda:0', requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# Check if weights are tied\n",
        "model.src_embed.embed.weight, model.tgt_embed.embed.weight, model.generator.final_proj.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeef8b77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeef8b77",
        "outputId": "11535c6a-f496-4431-b6d2-e023d993f795"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "model.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c4d1e1",
      "metadata": {
        "id": "a2c4d1e1"
      },
      "outputs": [],
      "source": [
        "# Train several epochs\n",
        "\n",
        "def train_epochs(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    lr_scheduler=None,\n",
        "    num_epochs=1,\n",
        "    save_checkpoint=False,\n",
        "):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        pbar = tqdm(train_dataloader)\n",
        "        for i, batch in enumerate(pbar):\n",
        "            batch = batch.to(model.device)      # move inputs to model.device\n",
        "            logits = model.forward(             # decoder output\n",
        "                batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n",
        "            )\n",
        "            y_pred = model.generator(logits)\n",
        "\n",
        "            loss = criterion(y_pred.reshape(-1, y_pred.shape[-1]), batch.tgt_y.reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            lr = optimizer.param_groups[0][\"lr\"]    # current learning rate\n",
        "\n",
        "            if lr_scheduler is not None:\n",
        "                lr_scheduler.step()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # print(\n",
        "            #     f\"  Training  >  Batch: {i:3d},    Batch loss: {loss.item():.6f},    \",\n",
        "            #     end='\\r',\n",
        "            # )\n",
        "\n",
        "            del batch\n",
        "            del logits\n",
        "            if isinstance(model.device, torch.device):\n",
        "                torch.cuda.empty_cache()    # release gpu memory\n",
        "\n",
        "            # add stuff to progress bar in the end\n",
        "            pbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")     # set description\n",
        "            pbar.set_postfix(loss=loss.item(), lr=lr)      # set postfix\n",
        "\n",
        "        if save_checkpoint:  # save model checkpoint at the end of each epoch\n",
        "            file_path = f\"checkpoint_{epoch+1}.pt\"\n",
        "            torch.save(model.state_dict(), file_path)\n",
        "\n",
        "\n",
        "    # save the final checkpoint\n",
        "    if save_checkpoint:\n",
        "        file_path = f\"checkpoint_final.pt\"\n",
        "        torch.save(model.state_dict(), file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c825061",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c825061",
        "outputId": "0dcc0798-7aee-4c1c-d9c9-36b332db81d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['english', 'chinese', 'src', 'tgt'],\n",
              "    num_rows: 50000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ed39dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32ed39dd",
        "outputId": "bbe85624-853e-4fa1-f236-a23c99d3f9e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "520"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# create train dataloader\n",
        "\n",
        "batch_size = 128\n",
        "batch_size = 96\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,     # drop last\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "449a976b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "449a976b",
        "outputId": "a41498d1-c87f-4436-b5df-ccd51fb3541d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_lr=0.001, num_warmup_steps=156, num_training_steps=1560\n"
          ]
        }
      ],
      "source": [
        "# Configuration for training\n",
        "\n",
        "num_epochs = 10\n",
        "num_epochs = 3\n",
        "\n",
        "base_lr = 0.001\n",
        "warmup_ratio = 0.1  # ratio of total training steps used for a linear warmup from 0 to `learning_rate`.\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "num_warmup_steps =  math.ceil(num_training_steps * warmup_ratio)\n",
        "\n",
        "print(f\"{base_lr=}, {num_warmup_steps=}, {num_training_steps=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "336f2526",
      "metadata": {
        "id": "336f2526"
      },
      "outputs": [],
      "source": [
        "# Compte loss: CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, label_smoothing=0.1)   # ignore pad token\n",
        "\n",
        "# Optimizer: AdamW\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(), lr=base_lr, betas=(0.9, 0.98), eps=1e-9\n",
        ")\n",
        "\n",
        "# lr_scheduler: cosine annealing with warmup\n",
        "lr_scheduler = cosine_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bb2a122",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bb2a122",
        "outputId": "fec26834-474d-4b19-9f46-a91ff3db1057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/3]: 100%|██████████| 520/520 [09:13<00:00,  1.06s/it, loss=6.63, lr=0.000844]\n",
            "Epoch [2/3]: 100%|██████████| 520/520 [09:02<00:00,  1.04s/it, loss=6.17, lr=0.000303]\n",
            "Epoch [3/3]: 100%|██████████| 520/520 [09:03<00:00,  1.05s/it, loss=5.94, lr=1.25e-9]\n"
          ]
        }
      ],
      "source": [
        "# Train several epochs\n",
        "train_epochs(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    lr_scheduler,\n",
        "    num_epochs,\n",
        "    save_checkpoint=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "ihmIUXHgx8iB"
      },
      "id": "ihmIUXHgx8iB"
    },
    {
      "cell_type": "markdown",
      "id": "d1de7028",
      "metadata": {
        "id": "d1de7028"
      },
      "source": [
        "<br>\n",
        "\n",
        "## Greedy Decoding\n",
        "\n",
        "> For simplicity, this code predicts a translation using greedy decoding.\n",
        "> <br>There are more advanced decoding methods, for example beam search, that can bring better performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19238ad7",
      "metadata": {
        "id": "19238ad7"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbaa5e2a",
      "metadata": {
        "id": "bbaa5e2a"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(checkpoint, device):\n",
        "    \"\"\"Load trained checkpoint\"\"\"\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        # use cpu if cuda is not available\n",
        "        device = 'cpu'\n",
        "    print(f'device-{torch.device(device)} is used.')\n",
        "\n",
        "    model = create_model(\n",
        "        src_vocab_size=tokenizer.vocab_size,\n",
        "        tgt_vocab_size=tokenizer.vocab_size,\n",
        "        embed_dim=512,\n",
        "        num_layers=6,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # Tie source and target weights\n",
        "    model.tie_weights()\n",
        "\n",
        "    print(f\"Load {checkpoint=}\")\n",
        "    # Make sure `state_dict` is mapped to `model.device`:\n",
        "    # 'map_location=model.device' or 'map_location=torch.device(device)'\n",
        "    # Otherwise, `state_dict` may not be successfully loaded into the model without warning\n",
        "    state_dict = torch.load(checkpoint, weights_only=True, map_location=model.device)\n",
        "    # state_dict = torch.load(checkpoint, weights_only=True, map_location=torch.device(device))\n",
        "    model.load_state_dict(state_dict)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "962fc3d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "962fc3d5",
        "outputId": "8736b317-a730-497b-897d-7d9bc45667d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 is enabled.\n",
            "Load checkpoint='checkpoint_final.pt'\n"
          ]
        }
      ],
      "source": [
        "device = 0\n",
        "model = load_checkpoint('checkpoint_final.pt', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25852b54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25852b54",
        "outputId": "4a37c212-9b24-4fa6-82cf-f462c7b7b6df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[-0.0057,  0.0492, -0.0367,  ..., -0.0133,  0.0047, -0.0325],\n",
              "         [-0.0073, -0.0090, -0.0059,  ..., -0.0104,  0.0105, -0.0007],\n",
              "         [ 0.0292,  0.0050,  0.0283,  ...,  0.0533, -0.0510, -0.0448],\n",
              "         ...,\n",
              "         [ 0.0051, -0.0565,  0.0461,  ..., -0.0042,  0.0211, -0.0788],\n",
              "         [ 0.0005, -0.0323, -0.0198,  ...,  0.0127, -0.0042,  0.0071],\n",
              "         [ 0.0012, -0.0370,  0.0323,  ...,  0.0287,  0.0232, -0.0160]],\n",
              "        device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0057,  0.0492, -0.0367,  ..., -0.0133,  0.0047, -0.0325],\n",
              "         [-0.0073, -0.0090, -0.0059,  ..., -0.0104,  0.0105, -0.0007],\n",
              "         [ 0.0292,  0.0050,  0.0283,  ...,  0.0533, -0.0510, -0.0448],\n",
              "         ...,\n",
              "         [ 0.0051, -0.0565,  0.0461,  ..., -0.0042,  0.0211, -0.0788],\n",
              "         [ 0.0005, -0.0323, -0.0198,  ...,  0.0127, -0.0042,  0.0071],\n",
              "         [ 0.0012, -0.0370,  0.0323,  ...,  0.0287,  0.0232, -0.0160]],\n",
              "        device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0057,  0.0492, -0.0367,  ..., -0.0133,  0.0047, -0.0325],\n",
              "         [-0.0073, -0.0090, -0.0059,  ..., -0.0104,  0.0105, -0.0007],\n",
              "         [ 0.0292,  0.0050,  0.0283,  ...,  0.0533, -0.0510, -0.0448],\n",
              "         ...,\n",
              "         [ 0.0051, -0.0565,  0.0461,  ..., -0.0042,  0.0211, -0.0788],\n",
              "         [ 0.0005, -0.0323, -0.0198,  ...,  0.0127, -0.0042,  0.0071],\n",
              "         [ 0.0012, -0.0370,  0.0323,  ...,  0.0287,  0.0232, -0.0160]],\n",
              "        device='cuda:0', requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "model.src_embed.embed.weight, model.tgt_embed.embed.weight, model.generator.final_proj.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82123b25",
      "metadata": {
        "id": "82123b25"
      },
      "outputs": [],
      "source": [
        "# Batch greedy decoding under the inference mode\n",
        "@torch.inference_mode\n",
        "def batch_greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    memory = model.encode(src, src_mask)            # encoder output\n",
        "\n",
        "    batch_size = src.size(0)\n",
        "    ys = torch.zeros(batch_size, 1).fill_(start_symbol).type_as(src.data)   # first/start token (e.g., <s>)\n",
        "\n",
        "    for i in range(max_len - 1):    # -1: exclude the start symbol\n",
        "        tgt_mask = create_causal_mask(ys.size(1)).type_as(src.data)\n",
        "        logits = model.decode(ys, memory, src_mask, tgt_mask)\n",
        "        prob = model.generator(logits[:, -1])       # last token as sentence representation, like [CLS]\n",
        "        _, next_token = torch.max(prob, dim=1)\n",
        "\n",
        "        ys = torch.cat([ys, next_token.unsqueeze(1)], dim=1)\n",
        "\n",
        "    return ys"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181a77fe",
      "metadata": {
        "id": "181a77fe"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2944b81",
      "metadata": {
        "id": "b2944b81"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(eval_dataloader))\n",
        "batch = batch.to(model.device)      # move inputs to model.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd2d15b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fd2d15b",
        "outputId": "84ee9c76-7c0c-4821-8514-5bee0dcd8e4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': torch.Size([128, 90]),\n",
              " 'src_mask': torch.Size([128, 1, 90]),\n",
              " 'tgt': torch.Size([128, 124]),\n",
              " 'tgt_y': torch.Size([128, 124]),\n",
              " 'tgt_mask': torch.Size([128, 124, 124]),\n",
              " 'num_tokens': torch.Size([])}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "{k:v.shape for k,v in batch.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc1dc11b",
      "metadata": {
        "id": "dc1dc11b"
      },
      "outputs": [],
      "source": [
        "output_ids = batch_greedy_decode(model, batch.src, batch.src_mask, max_len=50, start_symbol=tokenizer.bos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8820eac7",
      "metadata": {
        "id": "8820eac7"
      },
      "outputs": [],
      "source": [
        "results = tokenizer.batch_decode(output_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e639b126",
      "metadata": {
        "id": "e639b126"
      },
      "outputs": [],
      "source": [
        "# results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d80cc4f9",
      "metadata": {
        "id": "d80cc4f9"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "221d0d2d",
      "metadata": {
        "id": "221d0d2d"
      },
      "source": [
        "### Breakdown of `batch_greedy_decode`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5317d057",
      "metadata": {
        "id": "5317d057"
      },
      "outputs": [],
      "source": [
        "src = batch.src\n",
        "src_mask = batch.src_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6640d9c6",
      "metadata": {
        "id": "6640d9c6"
      },
      "outputs": [],
      "source": [
        "start_symbol = tokenizer.bos_token_id\n",
        "max_len = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6b0eed3",
      "metadata": {
        "id": "c6b0eed3"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    memory = model.encode(src, src_mask)\n",
        "\n",
        "    batch_size = src.size(0)\n",
        "    ys = torch.zeros(batch_size, 1).fill_(start_symbol).type_as(src.data)\n",
        "\n",
        "    for i in range(max_len - 1):\n",
        "        tgt_mask = create_causal_mask(ys.size(1)).type_as(src.data)\n",
        "        out = model.decode(ys, memory, src_mask, tgt_mask)\n",
        "        prob = model.generator(out[:, -1])      # last token as [CLS]\n",
        "        _, next_token = torch.max(prob, dim=1)\n",
        "\n",
        "        ys = torch.cat([ys, next_token.unsqueeze(1)], dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d4ebe58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d4ebe58",
        "outputId": "72676710-3745-4d98-dc7e-6fcb95faa3c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 10000])\n",
            "torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "print(prob.shape)\n",
        "print(next_token.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd760a92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd760a92",
        "outputId": "f3be15af-b789-4f5a-945b-fa2f92c6a623"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "ys.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf59948",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bf59948",
        "outputId": "232566d4-f3bf-460b-b748-d3b6cf64928f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0,  334,  894, 5666,  276,  334, 1464,  268, 5062, 1243,  276,  364,\n",
              "        2262,  276,  817, 1534,  537,  617,  356, 1888,  457,  268,  287,    2,\n",
              "           2,    2,    2,  498,  276,  817, 1749,  336,  617,  356, 1888,  457,\n",
              "         268,  287,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
              "           2,    2], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "ys[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40aef036",
      "metadata": {
        "id": "40aef036"
      },
      "outputs": [],
      "source": [
        "results = tokenizer.batch_decode(ys)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa86474d",
      "metadata": {
        "id": "fa86474d"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0eb33c3",
      "metadata": {
        "id": "f0eb33c3"
      },
      "source": [
        "\n",
        "### Check Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2e1df1",
      "metadata": {
        "id": "8f2e1df1"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer.batch_decode(batch['src'])\n",
        "targets = tokenizer.batch_decode(batch['tgt_y'])\n",
        "targets = [tokenizer.bos_token + s for s in targets]    # add prefix: bos_token\n",
        "\n",
        "output_ids = batch_greedy_decode(model, batch.src, batch.src_mask, max_len=50, start_symbol=tokenizer.bos_token_id)\n",
        "results = tokenizer.batch_decode(output_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "130b0a62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "130b0a62",
        "outputId": "1f3cb5ee-150a-4ab6-b031-c014167b173c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "==========\n",
            "Source:       <s>The Fed apparently could not stomach the sell-off in global financial markets in January and February, which was driven largely by concerns about further tightening.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Target:       <s>美联储显然无法消化1月和2月的全球金融市场抛售，而这一抛售潮主要是因为对美联储进一步紧缩的担忧导致的。</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Model output: <s>美联储还不是在2008年金融危机中，欧洲银行和银行和银行都无法实现这一政策，而危机上就需要解决。</s></s></s></s></s>。</s></s></s></s>。</s></s></s></s>。</s></s></s></s></s>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "i = 1\n",
        "\n",
        "print(\n",
        "    f\"Example {i}:\\n\"\n",
        "    f\"{'='*10}\\n\"\n",
        "    f\"Source:       {inputs[i]}\\n\"\n",
        "    f\"Target:       {targets[i]}\\n\"\n",
        "    f\"Model output: {results[i]}\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71fea9a1",
      "metadata": {
        "id": "71fea9a1"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62f894bb",
      "metadata": {
        "id": "62f894bb"
      },
      "source": [
        "#### Model performance over the learning course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e83c6ae",
      "metadata": {
        "id": "3e83c6ae"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer.batch_decode(batch['src'])\n",
        "targets = tokenizer.batch_decode(batch['tgt_y'])\n",
        "targets = [tokenizer.bos_token + s for s in targets]    # add prefix: bos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb8bec25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb8bec25",
        "outputId": "99a7b36a-00f1-4c96-f74f-7a2cbeb4c1f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load checkpoint_1.pt\n",
            "Load checkpoint_2.pt\n",
            "Load checkpoint_3.pt\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "epochs = range(3)\n",
        "for epoch in epochs:\n",
        "    checkpoint = f'checkpoint_{epoch+1}.pt'   # model checkpoint file path\n",
        "    print(f\"Load {checkpoint}\")\n",
        "    # remember to specify `map_location`\n",
        "    state_dict = torch.load(checkpoint, weights_only=True, map_location=model.device)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    # model = load_checkpoint(checkpoint, device)\n",
        "\n",
        "    output_ids = batch_greedy_decode(model, batch.src, batch.src_mask, max_len, start_symbol=tokenizer.bos_token_id)\n",
        "    decoded_text = tokenizer.batch_decode(output_ids)\n",
        "    results[epoch] = decoded_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5a7ac3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5a7ac3f",
        "outputId": "d8c43c5b-b611-448c-c15d-f93cea464b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "==========\n",
            "Source:       <s>The Fed apparently could not stomach the sell-off in global financial markets in January and February, which was driven largely by concerns about further tightening.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Target:       <s>美联储显然无法消化1月和2月的全球金融市场抛售，而这一抛售潮主要是因为对美联储进一步紧缩的担忧导致的。</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Model output:\n",
            "Epoch  0:     <s>这一方法是，在欧洲政府，但这些政策，但这些政策，但它们将在其他国家的经济，而它们会为其他国家的国家。</s></s></s>。</s></s></s>。</s></s>。</s></s></s></s></s>。\n",
            "Epoch  1:     <s>IMF的危机表明，在2008年金融危机上，欧洲银行和银行银行都将对金融稳定的危机上，而欧洲经济上也需要解决。</s></s></s></s>。</s></s></s></s>。</s></s></s></s></s></s>\n",
            "Epoch  2:     <s>美联储还不是在2008年金融危机中，欧洲银行和银行和银行都无法实现这一政策，而危机上就需要解决。</s></s></s></s></s>。</s></s></s></s>。</s></s></s></s>。</s></s></s></s></s>\n"
          ]
        }
      ],
      "source": [
        "i = 1   # i-th example\n",
        "\n",
        "print(\n",
        "    f\"Example {i}:\\n\"\n",
        "    f\"{'='*10}\\n\"\n",
        "    f\"Source:       {inputs[i]}\\n\"\n",
        "    f\"Target:       {targets[i]}\\n\"\n",
        "    f\"Model output:\"\n",
        ")\n",
        "\n",
        "for epoch in epochs:\n",
        "    print(f\"Epoch {epoch:2}:     {results[epoch][i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d3f4db9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d3f4db9",
        "outputId": "0efdee18-6d3c-4830-9e62-7e55626d0af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 10:\n",
            "==========\n",
            "Source:       <s>This will not only delay the restoration of economic growth, but will also have dire political consequences.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Target:       <s>而这不仅会延缓经济增长恢复的时间，还会产生可怕的政治后果。</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Model output:\n",
            "Epoch  0:     <s>当然，如果我们必须为经济，但它们会将更好好。</s>。</s></s>。</s></s>。</s></s></s>。</s></s></s>。</s></s></s></s>。</s></s></s>。</s></s>。</s></s></s></s></s>\n",
            "Epoch  1:     <s>这并不意味着，因为经济上，但经济上，但经济上，但经济上也有可能成为政治。</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
            "Epoch  2:     <s>这并不意味着经济复苏，但经济问题，但经济也可能变得越来越低。</s></s></s></s></s></s>。</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n"
          ]
        }
      ],
      "source": [
        "i = 10  # i-th example\n",
        "\n",
        "print(\n",
        "    f\"Example {i}:\\n\"\n",
        "    f\"{'='*10}\\n\"\n",
        "    f\"Source:       {inputs[i]}\\n\"\n",
        "    f\"Target:       {targets[i]}\\n\"\n",
        "    f\"Model output:\"\n",
        ")\n",
        "\n",
        "for epoch in epochs:\n",
        "    print(f\"Epoch {epoch:2}:     {results[epoch][i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5281f04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5281f04",
        "outputId": "6646c584-8d84-418c-9045-bdc6e4c8dbba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 29:\n",
            "==========\n",
            "Source:       <s>And the budget deficit has reached 7% of GDP.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Target:       <s>而预算赤字已经达到GDP的7%。</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Model output:\n",
            "Epoch  0:     <s>此外，在20世纪年，中国增长率。</s></s></s></s>。</s></s></s>。</s></s></s></s>。</s></s></s></s></s>。</s></s></s></s></s></s>。</s></s></s></s>。</s></s></s></s></s></s></s>\n",
            "Epoch  1:     <s>在2008年，中国债务占GDP的GDP。</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
            "Epoch  2:     <s>在20%的GDP下降到GDP的0.</s></s></s>。</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n"
          ]
        }
      ],
      "source": [
        "i = 29  # i-th example\n",
        "\n",
        "print(\n",
        "    f\"Example {i}:\\n\"\n",
        "    f\"{'='*10}\\n\"\n",
        "    f\"Source:       {inputs[i]}\\n\"\n",
        "    f\"Target:       {targets[i]}\\n\"\n",
        "    f\"Model output:\"\n",
        ")\n",
        "\n",
        "for epoch in epochs:\n",
        "    print(f\"Epoch {epoch:2}:     {results[epoch][i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd7a883",
      "metadata": {
        "id": "4cd7a883"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac3aba7c",
      "metadata": {
        "id": "ac3aba7c"
      },
      "source": [
        "# Part 5: Attention Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35ab4a3e",
      "metadata": {
        "id": "35ab4a3e"
      },
      "source": [
        "#### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d1b072a",
      "metadata": {
        "id": "4d1b072a",
        "outputId": "4b622d2e-4207-4687-cd76-37a88fcaafed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 is enabled.\n",
            "Load checkpoint='checkpoint_final.pt'\n"
          ]
        }
      ],
      "source": [
        "device = 0\n",
        "checkpoint = 'checkpoint_final.pt'\n",
        "model = load_checkpoint(checkpoint, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a30ddf",
      "metadata": {
        "id": "29a30ddf"
      },
      "source": [
        "#### Visualization function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bdaf918",
      "metadata": {
        "id": "2bdaf918"
      },
      "outputs": [],
      "source": [
        "def vis_attn(matrix, xlabels, ylabels, title):\n",
        "    \"\"\"\n",
        "    Visualize the heatmap given the matrix and x/y labels.\n",
        "\n",
        "    Note:\n",
        "        1. By default, Plotly automatically deduplicates axis labels to avoid overlap or confusion.\n",
        "        If you want to explicitly allow duplicate x-labels in a Plotly heatmap, you may need to disable\n",
        "        the axis' automatic tick deduplication by setting the tickvals and ticktext properties explicitly.\n",
        "        This forces Plotly to display the exact labels you provide, even if they are duplicates.\n",
        "\n",
        "        Solution: Take index as prefix for axis labels so as to create unique ticktext.\n",
        "\n",
        "        2. Plotly interprets certain symbols (like `<s>` or `</s>`) as HTML tags or invalid characters,\n",
        "        so they aren't displayed by default.\n",
        "\n",
        "        Solution: Escaping Special Characters\n",
        "        We can escape `<` and `>` using their HTML entity equivalents:\n",
        "            '<' becomes '&lt;'\n",
        "            '>' becomes '&gt;'\n",
        "\n",
        "        3. y-axis is the query side in our setting.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    import plotly.graph_objects as go\n",
        "    # pio.templates.default = \"none\"\n",
        "\n",
        "    # change '<s>' -> 'xxx &lt;s&gt;'\n",
        "    xlabels = [f\"{x.replace('<', '&lt;').replace('>', '&gt;')}\" if x in ['<s>', '</s>'] else x for i, x in enumerate(xlabels)]\n",
        "    ylabels = [f\"{x.replace('<', '&lt;').replace('>', '&gt;')}\" if x in ['<s>', '</s>'] else x for i, x in enumerate(ylabels)]\n",
        "\n",
        "    # ylabel 'query' xlabel\n",
        "    hovertext = [[f'attn({ylabels[i]}, {xlabels[j]})= {matrix[i][j]:.2f}' for j in range(len(xlabels))] for i in range(len(ylabels))]\n",
        "\n",
        "    # equip x and y labels with styled text\n",
        "    # xlabels = [f\"{i:03} <span style='color:red'><b>{x}</b></span>\" for i, x in enumerate(xlabels)]\n",
        "    xlabels = [f\"<span style='font-size: 10px;color:grey'>{i:03}</span>  {x}\" for i, x in enumerate(xlabels)]\n",
        "    ylabels = [f\"<span style='font-size: 10px;color:grey'>{i:03}</span>  {x}\" for i, x in enumerate(ylabels)]\n",
        "\n",
        "    heat = go.Heatmap(\n",
        "        z=matrix,\n",
        "        x=xlabels,\n",
        "        y=ylabels,\n",
        "        xgap=1, ygap=1,\n",
        "        colorscale='PuBu',\n",
        "        colorbar_thickness=15,\n",
        "        colorbar_ticklen=3,\n",
        "        hovertext =hovertext,\n",
        "        hoverinfo='text',\n",
        "    )\n",
        "\n",
        "    layout = go.Layout(\n",
        "        title_text=title,\n",
        "        title_x=0.5,\n",
        "        width=1000, height=1000,\n",
        "        xaxis_showgrid=False,\n",
        "        yaxis_showgrid=False,\n",
        "        yaxis_autorange='reversed',\n",
        "        # margin=dict(\n",
        "        #     l=100,  # Left margin\n",
        "        #     r=50,  # Right margin\n",
        "        #     t=50,   # Top margin\n",
        "        #     b=100   # Bottom margin (to fit long x-axis labels)\n",
        "        # ),\n",
        "        xaxis=dict(\n",
        "            tickangle=-45,  # Rotate x-axis labels for better readability\n",
        "            ticklen=5,      # tick length\n",
        "            ticks=\"outside\",# tick direction\n",
        "            title=\"Key\",    # Optional: Add an axis title\n",
        "            automargin=True,\n",
        "            title_font=dict(size=18, family='Courier', color='crimson'),\n",
        "            # side='top',\n",
        "        ),\n",
        "        yaxis=dict(\n",
        "            ticklen=5,\n",
        "            ticks=\"outside\",\n",
        "            title=\"Query\",  # Optional: Add an axis title\n",
        "            automargin=True,\n",
        "            title_font=dict(size=18, family='Courier', color='crimson')\n",
        "        )\n",
        "    )\n",
        "\n",
        "    fig=go.Figure(data=[heat], layout=layout)\n",
        "\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd31fded",
      "metadata": {
        "id": "fd31fded"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b5a7a1e2",
      "metadata": {
        "id": "b5a7a1e2"
      },
      "source": [
        "### Example from Eval Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe5bcdab",
      "metadata": {
        "id": "fe5bcdab",
        "outputId": "72e31ee6-399d-4707-fb27-d0ecc23eb4a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['english', 'chinese', 'src', 'tgt'],\n",
              "    num_rows: 25278\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aae11a3",
      "metadata": {
        "id": "4aae11a3"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "\n",
        "example = eval_dataset[i]\n",
        "# example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af8e799",
      "metadata": {
        "id": "1af8e799",
        "outputId": "2c2a905e-8300-46d4-c1e5-b83d4d8a22ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Fed apparently could not stomach the sell-off in global financial markets in January and February, which was driven largely by concerns about further tightening.\n",
            "美联储显然无法消化1月和2月的全球金融市场抛售，而这一抛售潮主要是因为对美联储进一步紧缩的担忧导致的。\n"
          ]
        }
      ],
      "source": [
        "print(example['english'])\n",
        "print(example['chinese'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6a1064",
      "metadata": {
        "id": "2c6a1064"
      },
      "outputs": [],
      "source": [
        "src = example['src']\n",
        "tgt = example['tgt']\n",
        "\n",
        "src = torch.LongTensor(src).unsqueeze(0)\n",
        "tgt = torch.LongTensor(tgt).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78b03a18",
      "metadata": {
        "id": "78b03a18"
      },
      "outputs": [],
      "source": [
        "batch = Batch(src, tgt, pad=tokenizer.pad_token_id)\n",
        "batch = batch.to(model.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa75c28",
      "metadata": {
        "id": "4aa75c28",
        "outputId": "22fe0238-980e-406c-97f4-9e2ba3e66fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': torch.Size([1, 38]),\n",
              " 'src_mask': torch.Size([1, 1, 38]),\n",
              " 'tgt': torch.Size([1, 31]),\n",
              " 'tgt_y': torch.Size([1, 31]),\n",
              " 'tgt_mask': torch.Size([1, 31, 31]),\n",
              " 'num_tokens': torch.Size([])}"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "{k:v.shape for k,v in batch.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d50c9e1b",
      "metadata": {
        "id": "d50c9e1b"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer.batch_decode(batch['src'])\n",
        "targets = tokenizer.batch_decode(batch['tgt_y'])\n",
        "targets = [tokenizer.bos_token + s for s in targets]\n",
        "\n",
        "# max_tokens = len(batch['tgt'][0]) + 1   # +1: because current batch['tgt'] is one token less than original batch['tgt] (due to shifted right)\n",
        "\n",
        "# 然而，greedy_decode 并未用到 decoder input，即 batch['tgt']，\n",
        "# 因此，在此 decoder 的 self-attention 应该展示为 greedy decode 产生的文本（又作为decoder输入）之间的 self-attention，\n",
        "# 并非 batch['tgt'] 的 self-attention\n",
        "\n",
        "max_tokens = 50\n",
        "output_ids = batch_greedy_decode(model, batch.src, batch.src_mask, max_len=max_tokens, start_symbol=tokenizer.bos_token_id)\n",
        "results = tokenizer.batch_decode(output_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d6a9dc",
      "metadata": {
        "id": "01d6a9dc",
        "outputId": "a2895356-76ee-4f8f-8169-763686a92688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['<s>The Fed apparently could not stomach the sell-off in global financial markets in January and February, which was driven largely by concerns about further tightening.</s>'],\n",
              " ['<s>美联储显然无法消化1月和2月的全球金融市场抛售，而这一抛售潮主要是因为对美联储进一步紧缩的担忧导致的。</s>'],\n",
              " ['<s>美联储还不是在2008年金融危机中，欧洲银行和银行和银行都无法实现这一政策，而危机上就需要解决。</s></s></s></s></s>。</s></s></s></s>。</s></s></s></s>。</s></s></s></s></s>'])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "inputs, targets, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a4cda0",
      "metadata": {
        "id": "54a4cda0",
        "outputId": "ad502776-5754-494d-afd4-ef030a0334a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "max_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "368b6124",
      "metadata": {
        "id": "368b6124",
        "outputId": "c727aa57-73a4-4b17-a8d0-139acdc5b3f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "batch['tgt'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8816de93",
      "metadata": {
        "id": "8816de93"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b52296bf",
      "metadata": {
        "id": "b52296bf"
      },
      "source": [
        "## Encoder Visualization\n",
        "* self-attention"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ced32ecd",
      "metadata": {
        "id": "ced32ecd"
      },
      "source": [
        "### Encoder self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95600448",
      "metadata": {
        "id": "95600448"
      },
      "outputs": [],
      "source": [
        "# layer and head to visualize\n",
        "layer = 3\n",
        "head = 2\n",
        "\n",
        "# Encoder self-attention score\n",
        "attn_score = model.encoder.layers[layer].self_attn.attn_score    # [batch_size, num_heads, seq_len, seq_len]\n",
        "attn_score = attn_score.cpu().numpy()\n",
        "\n",
        "matrix = attn_score[0][head]\n",
        "\n",
        "title = f'Encoder self-attn, Layer {layer}, Head {head}'\n",
        "\n",
        "xlabels = [tokenizer.decode(x) for x in batch['src'][0]]\n",
        "ylabels = xlabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20fe6803",
      "metadata": {
        "id": "20fe6803",
        "outputId": "7a1c5a12-4e77-4fb2-f559-32c8988a4af3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 38, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "attn_score.shape        # [batch_size, num_heads, seq_len, seq_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bfd3f2",
      "metadata": {
        "id": "82bfd3f2",
        "outputId": "e65ef7c2-c6bb-4dcf-eeb7-a589e4938c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"53bfb659-76c7-46d8-ba5e-e48d94dcba1f\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"53bfb659-76c7-46d8-ba5e-e48d94dcba1f\")) {                    Plotly.newPlot(                        \"53bfb659-76c7-46d8-ba5e-e48d94dcba1f\",                        [{\"colorbar\":{\"thickness\":15,\"ticklen\":3},\"colorscale\":[[0.0,\"rgb(255,247,251)\"],[0.125,\"rgb(236,231,242)\"],[0.25,\"rgb(208,209,230)\"],[0.375,\"rgb(166,189,219)\"],[0.5,\"rgb(116,169,207)\"],[0.625,\"rgb(54,144,192)\"],[0.75,\"rgb(5,112,176)\"],[0.875,\"rgb(4,90,141)\"],[1.0,\"rgb(2,56,88)\"]],\"hoverinfo\":\"text\",\"hovertext\":[[\"attn(&lt;s&gt;, &lt;s&gt;)= 0.06\",\"attn(&lt;s&gt;, The)= 0.85\",\"attn(&lt;s&gt;,  Fed)= 0.02\",\"attn(&lt;s&gt;,  apparent)= 0.02\",\"attn(&lt;s&gt;, ly)= 0.01\",\"attn(&lt;s&gt;,  could)= 0.02\",\"attn(&lt;s&gt;,  not)= 0.01\",\"attn(&lt;s&gt;,  st)= 0.00\",\"attn(&lt;s&gt;, om)= 0.00\",\"attn(&lt;s&gt;, ach)= 0.00\",\"attn(&lt;s&gt;,  the)= 0.00\",\"attn(&lt;s&gt;,  sell)= 0.00\",\"attn(&lt;s&gt;, -)= 0.00\",\"attn(&lt;s&gt;, off)= 0.00\",\"attn(&lt;s&gt;,  in)= 0.00\",\"attn(&lt;s&gt;,  global)= 0.00\",\"attn(&lt;s&gt;,  financial)= 0.00\",\"attn(&lt;s&gt;,  markets)= 0.00\",\"attn(&lt;s&gt;,  in)= 0.00\",\"attn(&lt;s&gt;,  January)= 0.01\",\"attn(&lt;s&gt;,  and)= 0.00\",\"attn(&lt;s&gt;,  F)= 0.00\",\"attn(&lt;s&gt;, eb)= 0.00\",\"attn(&lt;s&gt;, ru)= 0.00\",\"attn(&lt;s&gt;, ary)= 0.00\",\"attn(&lt;s&gt;, ,)= 0.00\",\"attn(&lt;s&gt;,  which)= 0.00\",\"attn(&lt;s&gt;,  was)= 0.00\",\"attn(&lt;s&gt;,  driven)= 0.00\",\"attn(&lt;s&gt;,  largely)= 0.00\",\"attn(&lt;s&gt;,  by)= 0.00\",\"attn(&lt;s&gt;,  concerns)= 0.00\",\"attn(&lt;s&gt;,  about)= 0.00\",\"attn(&lt;s&gt;,  further)= 0.00\",\"attn(&lt;s&gt;,  tight)= 0.00\",\"attn(&lt;s&gt;, ening)= 0.00\",\"attn(&lt;s&gt;, .)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(The, &lt;s&gt;)= 0.00\",\"attn(The, The)= 0.01\",\"attn(The,  Fed)= 0.00\",\"attn(The,  apparent)= 0.00\",\"attn(The, ly)= 0.00\",\"attn(The,  could)= 0.02\",\"attn(The,  not)= 0.01\",\"attn(The,  st)= 0.00\",\"attn(The, om)= 0.00\",\"attn(The, ach)= 0.00\",\"attn(The,  the)= 0.00\",\"attn(The,  sell)= 0.00\",\"attn(The, -)= 0.00\",\"attn(The, off)= 0.00\",\"attn(The,  in)= 0.00\",\"attn(The,  global)= 0.00\",\"attn(The,  financial)= 0.00\",\"attn(The,  markets)= 0.00\",\"attn(The,  in)= 0.00\",\"attn(The,  January)= 0.00\",\"attn(The,  and)= 0.20\",\"attn(The,  F)= 0.00\",\"attn(The, eb)= 0.00\",\"attn(The, ru)= 0.00\",\"attn(The, ary)= 0.00\",\"attn(The, ,)= 0.62\",\"attn(The,  which)= 0.00\",\"attn(The,  was)= 0.00\",\"attn(The,  driven)= 0.00\",\"attn(The,  largely)= 0.00\",\"attn(The,  by)= 0.00\",\"attn(The,  concerns)= 0.00\",\"attn(The,  about)= 0.00\",\"attn(The,  further)= 0.00\",\"attn(The,  tight)= 0.00\",\"attn(The, ening)= 0.00\",\"attn(The, .)= 0.12\",\"attn(The, &lt;\\u002fs&gt;)= 0.02\"],[\"attn( Fed, &lt;s&gt;)= 0.00\",\"attn( Fed, The)= 0.00\",\"attn( Fed,  Fed)= 0.00\",\"attn( Fed,  apparent)= 0.00\",\"attn( Fed, ly)= 0.00\",\"attn( Fed,  could)= 0.01\",\"attn( Fed,  not)= 0.01\",\"attn( Fed,  st)= 0.00\",\"attn( Fed, om)= 0.00\",\"attn( Fed, ach)= 0.01\",\"attn( Fed,  the)= 0.01\",\"attn( Fed,  sell)= 0.00\",\"attn( Fed, -)= 0.00\",\"attn( Fed, off)= 0.01\",\"attn( Fed,  in)= 0.00\",\"attn( Fed,  global)= 0.00\",\"attn( Fed,  financial)= 0.02\",\"attn( Fed,  markets)= 0.02\",\"attn( Fed,  in)= 0.00\",\"attn( Fed,  January)= 0.00\",\"attn( Fed,  and)= 0.07\",\"attn( Fed,  F)= 0.00\",\"attn( Fed, eb)= 0.00\",\"attn( Fed, ru)= 0.01\",\"attn( Fed, ary)= 0.01\",\"attn( Fed, ,)= 0.06\",\"attn( Fed,  which)= 0.01\",\"attn( Fed,  was)= 0.01\",\"attn( Fed,  driven)= 0.03\",\"attn( Fed,  largely)= 0.02\",\"attn( Fed,  by)= 0.07\",\"attn( Fed,  concerns)= 0.15\",\"attn( Fed,  about)= 0.11\",\"attn( Fed,  further)= 0.05\",\"attn( Fed,  tight)= 0.09\",\"attn( Fed, ening)= 0.04\",\"attn( Fed, .)= 0.05\",\"attn( Fed, &lt;\\u002fs&gt;)= 0.10\"],[\"attn( apparent, &lt;s&gt;)= 0.00\",\"attn( apparent, The)= 0.00\",\"attn( apparent,  Fed)= 0.00\",\"attn( apparent,  apparent)= 0.00\",\"attn( apparent, ly)= 0.00\",\"attn( apparent,  could)= 0.00\",\"attn( apparent,  not)= 0.00\",\"attn( apparent,  st)= 0.00\",\"attn( apparent, om)= 0.00\",\"attn( apparent, ach)= 0.00\",\"attn( apparent,  the)= 0.00\",\"attn( apparent,  sell)= 0.00\",\"attn( apparent, -)= 0.00\",\"attn( apparent, off)= 0.00\",\"attn( apparent,  in)= 0.00\",\"attn( apparent,  global)= 0.00\",\"attn( apparent,  financial)= 0.00\",\"attn( apparent,  markets)= 0.00\",\"attn( apparent,  in)= 0.00\",\"attn( apparent,  January)= 0.00\",\"attn( apparent,  and)= 0.32\",\"attn( apparent,  F)= 0.00\",\"attn( apparent, eb)= 0.00\",\"attn( apparent, ru)= 0.00\",\"attn( apparent, ary)= 0.00\",\"attn( apparent, ,)= 0.50\",\"attn( apparent,  which)= 0.00\",\"attn( apparent,  was)= 0.00\",\"attn( apparent,  driven)= 0.00\",\"attn( apparent,  largely)= 0.00\",\"attn( apparent,  by)= 0.01\",\"attn( apparent,  concerns)= 0.00\",\"attn( apparent,  about)= 0.01\",\"attn( apparent,  further)= 0.01\",\"attn( apparent,  tight)= 0.01\",\"attn( apparent, ening)= 0.00\",\"attn( apparent, .)= 0.09\",\"attn( apparent, &lt;\\u002fs&gt;)= 0.05\"],[\"attn(ly, &lt;s&gt;)= 0.00\",\"attn(ly, The)= 0.00\",\"attn(ly,  Fed)= 0.00\",\"attn(ly,  apparent)= 0.00\",\"attn(ly, ly)= 0.00\",\"attn(ly,  could)= 0.00\",\"attn(ly,  not)= 0.00\",\"attn(ly,  st)= 0.00\",\"attn(ly, om)= 0.00\",\"attn(ly, ach)= 0.00\",\"attn(ly,  the)= 0.00\",\"attn(ly,  sell)= 0.00\",\"attn(ly, -)= 0.00\",\"attn(ly, off)= 0.00\",\"attn(ly,  in)= 0.00\",\"attn(ly,  global)= 0.00\",\"attn(ly,  financial)= 0.00\",\"attn(ly,  markets)= 0.00\",\"attn(ly,  in)= 0.00\",\"attn(ly,  January)= 0.00\",\"attn(ly,  and)= 0.24\",\"attn(ly,  F)= 0.00\",\"attn(ly, eb)= 0.00\",\"attn(ly, ru)= 0.00\",\"attn(ly, ary)= 0.00\",\"attn(ly, ,)= 0.56\",\"attn(ly,  which)= 0.00\",\"attn(ly,  was)= 0.00\",\"attn(ly,  driven)= 0.00\",\"attn(ly,  largely)= 0.00\",\"attn(ly,  by)= 0.01\",\"attn(ly,  concerns)= 0.01\",\"attn(ly,  about)= 0.01\",\"attn(ly,  further)= 0.01\",\"attn(ly,  tight)= 0.01\",\"attn(ly, ening)= 0.00\",\"attn(ly, .)= 0.09\",\"attn(ly, &lt;\\u002fs&gt;)= 0.07\"],[\"attn( could, &lt;s&gt;)= 0.00\",\"attn( could, The)= 0.00\",\"attn( could,  Fed)= 0.00\",\"attn( could,  apparent)= 0.00\",\"attn( could, ly)= 0.00\",\"attn( could,  could)= 0.00\",\"attn( could,  not)= 0.00\",\"attn( could,  st)= 0.00\",\"attn( could, om)= 0.00\",\"attn( could, ach)= 0.00\",\"attn( could,  the)= 0.00\",\"attn( could,  sell)= 0.00\",\"attn( could, -)= 0.00\",\"attn( could, off)= 0.00\",\"attn( could,  in)= 0.00\",\"attn( could,  global)= 0.00\",\"attn( could,  financial)= 0.00\",\"attn( could,  markets)= 0.00\",\"attn( could,  in)= 0.00\",\"attn( could,  January)= 0.00\",\"attn( could,  and)= 0.09\",\"attn( could,  F)= 0.00\",\"attn( could, eb)= 0.00\",\"attn( could, ru)= 0.00\",\"attn( could, ary)= 0.00\",\"attn( could, ,)= 0.79\",\"attn( could,  which)= 0.00\",\"attn( could,  was)= 0.00\",\"attn( could,  driven)= 0.00\",\"attn( could,  largely)= 0.00\",\"attn( could,  by)= 0.00\",\"attn( could,  concerns)= 0.00\",\"attn( could,  about)= 0.00\",\"attn( could,  further)= 0.00\",\"attn( could,  tight)= 0.00\",\"attn( could, ening)= 0.00\",\"attn( could, .)= 0.09\",\"attn( could, &lt;\\u002fs&gt;)= 0.02\"],[\"attn( not, &lt;s&gt;)= 0.00\",\"attn( not, The)= 0.00\",\"attn( not,  Fed)= 0.00\",\"attn( not,  apparent)= 0.00\",\"attn( not, ly)= 0.00\",\"attn( not,  could)= 0.00\",\"attn( not,  not)= 0.00\",\"attn( not,  st)= 0.00\",\"attn( not, om)= 0.00\",\"attn( not, ach)= 0.00\",\"attn( not,  the)= 0.00\",\"attn( not,  sell)= 0.00\",\"attn( not, -)= 0.00\",\"attn( not, off)= 0.00\",\"attn( not,  in)= 0.00\",\"attn( not,  global)= 0.00\",\"attn( not,  financial)= 0.00\",\"attn( not,  markets)= 0.00\",\"attn( not,  in)= 0.00\",\"attn( not,  January)= 0.00\",\"attn( not,  and)= 0.11\",\"attn( not,  F)= 0.00\",\"attn( not, eb)= 0.00\",\"attn( not, ru)= 0.00\",\"attn( not, ary)= 0.00\",\"attn( not, ,)= 0.72\",\"attn( not,  which)= 0.00\",\"attn( not,  was)= 0.00\",\"attn( not,  driven)= 0.00\",\"attn( not,  largely)= 0.00\",\"attn( not,  by)= 0.00\",\"attn( not,  concerns)= 0.00\",\"attn( not,  about)= 0.00\",\"attn( not,  further)= 0.00\",\"attn( not,  tight)= 0.00\",\"attn( not, ening)= 0.00\",\"attn( not, .)= 0.12\",\"attn( not, &lt;\\u002fs&gt;)= 0.03\"],[\"attn( st, &lt;s&gt;)= 0.00\",\"attn( st, The)= 0.00\",\"attn( st,  Fed)= 0.00\",\"attn( st,  apparent)= 0.00\",\"attn( st, ly)= 0.00\",\"attn( st,  could)= 0.00\",\"attn( st,  not)= 0.00\",\"attn( st,  st)= 0.00\",\"attn( st, om)= 0.00\",\"attn( st, ach)= 0.00\",\"attn( st,  the)= 0.00\",\"attn( st,  sell)= 0.00\",\"attn( st, -)= 0.00\",\"attn( st, off)= 0.00\",\"attn( st,  in)= 0.00\",\"attn( st,  global)= 0.00\",\"attn( st,  financial)= 0.00\",\"attn( st,  markets)= 0.00\",\"attn( st,  in)= 0.00\",\"attn( st,  January)= 0.00\",\"attn( st,  and)= 0.09\",\"attn( st,  F)= 0.00\",\"attn( st, eb)= 0.00\",\"attn( st, ru)= 0.00\",\"attn( st, ary)= 0.00\",\"attn( st, ,)= 0.17\",\"attn( st,  which)= 0.00\",\"attn( st,  was)= 0.00\",\"attn( st,  driven)= 0.01\",\"attn( st,  largely)= 0.00\",\"attn( st,  by)= 0.02\",\"attn( st,  concerns)= 0.39\",\"attn( st,  about)= 0.11\",\"attn( st,  further)= 0.03\",\"attn( st,  tight)= 0.01\",\"attn( st, ening)= 0.01\",\"attn( st, .)= 0.03\",\"attn( st, &lt;\\u002fs&gt;)= 0.13\"],[\"attn(om, &lt;s&gt;)= 0.00\",\"attn(om, The)= 0.00\",\"attn(om,  Fed)= 0.00\",\"attn(om,  apparent)= 0.00\",\"attn(om, ly)= 0.00\",\"attn(om,  could)= 0.00\",\"attn(om,  not)= 0.00\",\"attn(om,  st)= 0.00\",\"attn(om, om)= 0.00\",\"attn(om, ach)= 0.00\",\"attn(om,  the)= 0.00\",\"attn(om,  sell)= 0.00\",\"attn(om, -)= 0.00\",\"attn(om, off)= 0.00\",\"attn(om,  in)= 0.00\",\"attn(om,  global)= 0.00\",\"attn(om,  financial)= 0.00\",\"attn(om,  markets)= 0.00\",\"attn(om,  in)= 0.00\",\"attn(om,  January)= 0.00\",\"attn(om,  and)= 0.09\",\"attn(om,  F)= 0.00\",\"attn(om, eb)= 0.00\",\"attn(om, ru)= 0.00\",\"attn(om, ary)= 0.00\",\"attn(om, ,)= 0.19\",\"attn(om,  which)= 0.00\",\"attn(om,  was)= 0.00\",\"attn(om,  driven)= 0.01\",\"attn(om,  largely)= 0.00\",\"attn(om,  by)= 0.02\",\"attn(om,  concerns)= 0.35\",\"attn(om,  about)= 0.11\",\"attn(om,  further)= 0.03\",\"attn(om,  tight)= 0.02\",\"attn(om, ening)= 0.01\",\"attn(om, .)= 0.03\",\"attn(om, &lt;\\u002fs&gt;)= 0.13\"],[\"attn(ach, &lt;s&gt;)= 0.00\",\"attn(ach, The)= 0.00\",\"attn(ach,  Fed)= 0.00\",\"attn(ach,  apparent)= 0.00\",\"attn(ach, ly)= 0.00\",\"attn(ach,  could)= 0.00\",\"attn(ach,  not)= 0.00\",\"attn(ach,  st)= 0.00\",\"attn(ach, om)= 0.00\",\"attn(ach, ach)= 0.00\",\"attn(ach,  the)= 0.00\",\"attn(ach,  sell)= 0.00\",\"attn(ach, -)= 0.00\",\"attn(ach, off)= 0.00\",\"attn(ach,  in)= 0.00\",\"attn(ach,  global)= 0.00\",\"attn(ach,  financial)= 0.00\",\"attn(ach,  markets)= 0.00\",\"attn(ach,  in)= 0.00\",\"attn(ach,  January)= 0.00\",\"attn(ach,  and)= 0.02\",\"attn(ach,  F)= 0.00\",\"attn(ach, eb)= 0.00\",\"attn(ach, ru)= 0.00\",\"attn(ach, ary)= 0.00\",\"attn(ach, ,)= 0.04\",\"attn(ach,  which)= 0.00\",\"attn(ach,  was)= 0.00\",\"attn(ach,  driven)= 0.00\",\"attn(ach,  largely)= 0.00\",\"attn(ach,  by)= 0.02\",\"attn(ach,  concerns)= 0.71\",\"attn(ach,  about)= 0.10\",\"attn(ach,  further)= 0.02\",\"attn(ach,  tight)= 0.01\",\"attn(ach, ening)= 0.01\",\"attn(ach, .)= 0.01\",\"attn(ach, &lt;\\u002fs&gt;)= 0.06\"],[\"attn( the, &lt;s&gt;)= 0.00\",\"attn( the, The)= 0.00\",\"attn( the,  Fed)= 0.00\",\"attn( the,  apparent)= 0.00\",\"attn( the, ly)= 0.00\",\"attn( the,  could)= 0.00\",\"attn( the,  not)= 0.00\",\"attn( the,  st)= 0.00\",\"attn( the, om)= 0.00\",\"attn( the, ach)= 0.00\",\"attn( the,  the)= 0.00\",\"attn( the,  sell)= 0.00\",\"attn( the, -)= 0.00\",\"attn( the, off)= 0.00\",\"attn( the,  in)= 0.00\",\"attn( the,  global)= 0.00\",\"attn( the,  financial)= 0.00\",\"attn( the,  markets)= 0.00\",\"attn( the,  in)= 0.00\",\"attn( the,  January)= 0.00\",\"attn( the,  and)= 0.00\",\"attn( the,  F)= 0.00\",\"attn( the, eb)= 0.00\",\"attn( the, ru)= 0.00\",\"attn( the, ary)= 0.00\",\"attn( the, ,)= 0.01\",\"attn( the,  which)= 0.00\",\"attn( the,  was)= 0.00\",\"attn( the,  driven)= 0.00\",\"attn( the,  largely)= 0.00\",\"attn( the,  by)= 0.01\",\"attn( the,  concerns)= 0.88\",\"attn( the,  about)= 0.06\",\"attn( the,  further)= 0.01\",\"attn( the,  tight)= 0.00\",\"attn( the, ening)= 0.00\",\"attn( the, .)= 0.00\",\"attn( the, &lt;\\u002fs&gt;)= 0.02\"],[\"attn( sell, &lt;s&gt;)= 0.00\",\"attn( sell, The)= 0.00\",\"attn( sell,  Fed)= 0.00\",\"attn( sell,  apparent)= 0.00\",\"attn( sell, ly)= 0.00\",\"attn( sell,  could)= 0.00\",\"attn( sell,  not)= 0.00\",\"attn( sell,  st)= 0.00\",\"attn( sell, om)= 0.00\",\"attn( sell, ach)= 0.00\",\"attn( sell,  the)= 0.00\",\"attn( sell,  sell)= 0.00\",\"attn( sell, -)= 0.00\",\"attn( sell, off)= 0.00\",\"attn( sell,  in)= 0.00\",\"attn( sell,  global)= 0.00\",\"attn( sell,  financial)= 0.00\",\"attn( sell,  markets)= 0.00\",\"attn( sell,  in)= 0.00\",\"attn( sell,  January)= 0.00\",\"attn( sell,  and)= 0.01\",\"attn( sell,  F)= 0.00\",\"attn( sell, eb)= 0.00\",\"attn( sell, ru)= 0.00\",\"attn( sell, ary)= 0.00\",\"attn( sell, ,)= 0.01\",\"attn( sell,  which)= 0.00\",\"attn( sell,  was)= 0.00\",\"attn( sell,  driven)= 0.00\",\"attn( sell,  largely)= 0.00\",\"attn( sell,  by)= 0.01\",\"attn( sell,  concerns)= 0.85\",\"attn( sell,  about)= 0.06\",\"attn( sell,  further)= 0.01\",\"attn( sell,  tight)= 0.00\",\"attn( sell, ening)= 0.01\",\"attn( sell, .)= 0.00\",\"attn( sell, &lt;\\u002fs&gt;)= 0.03\"],[\"attn(-, &lt;s&gt;)= 0.00\",\"attn(-, The)= 0.00\",\"attn(-,  Fed)= 0.00\",\"attn(-,  apparent)= 0.00\",\"attn(-, ly)= 0.00\",\"attn(-,  could)= 0.00\",\"attn(-,  not)= 0.00\",\"attn(-,  st)= 0.00\",\"attn(-, om)= 0.00\",\"attn(-, ach)= 0.00\",\"attn(-,  the)= 0.00\",\"attn(-,  sell)= 0.00\",\"attn(-, -)= 0.00\",\"attn(-, off)= 0.00\",\"attn(-,  in)= 0.00\",\"attn(-,  global)= 0.00\",\"attn(-,  financial)= 0.00\",\"attn(-,  markets)= 0.00\",\"attn(-,  in)= 0.00\",\"attn(-,  January)= 0.00\",\"attn(-,  and)= 0.00\",\"attn(-,  F)= 0.00\",\"attn(-, eb)= 0.00\",\"attn(-, ru)= 0.00\",\"attn(-, ary)= 0.00\",\"attn(-, ,)= 0.00\",\"attn(-,  which)= 0.00\",\"attn(-,  was)= 0.00\",\"attn(-,  driven)= 0.00\",\"attn(-,  largely)= 0.00\",\"attn(-,  by)= 0.00\",\"attn(-,  concerns)= 0.97\",\"attn(-,  about)= 0.02\",\"attn(-,  further)= 0.00\",\"attn(-,  tight)= 0.00\",\"attn(-, ening)= 0.00\",\"attn(-, .)= 0.00\",\"attn(-, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(off, &lt;s&gt;)= 0.00\",\"attn(off, The)= 0.00\",\"attn(off,  Fed)= 0.00\",\"attn(off,  apparent)= 0.00\",\"attn(off, ly)= 0.00\",\"attn(off,  could)= 0.00\",\"attn(off,  not)= 0.00\",\"attn(off,  st)= 0.00\",\"attn(off, om)= 0.00\",\"attn(off, ach)= 0.00\",\"attn(off,  the)= 0.00\",\"attn(off,  sell)= 0.00\",\"attn(off, -)= 0.00\",\"attn(off, off)= 0.00\",\"attn(off,  in)= 0.00\",\"attn(off,  global)= 0.00\",\"attn(off,  financial)= 0.00\",\"attn(off,  markets)= 0.00\",\"attn(off,  in)= 0.00\",\"attn(off,  January)= 0.00\",\"attn(off,  and)= 0.01\",\"attn(off,  F)= 0.00\",\"attn(off, eb)= 0.00\",\"attn(off, ru)= 0.00\",\"attn(off, ary)= 0.00\",\"attn(off, ,)= 0.01\",\"attn(off,  which)= 0.00\",\"attn(off,  was)= 0.00\",\"attn(off,  driven)= 0.00\",\"attn(off,  largely)= 0.01\",\"attn(off,  by)= 0.01\",\"attn(off,  concerns)= 0.84\",\"attn(off,  about)= 0.07\",\"attn(off,  further)= 0.02\",\"attn(off,  tight)= 0.00\",\"attn(off, ening)= 0.01\",\"attn(off, .)= 0.00\",\"attn(off, &lt;\\u002fs&gt;)= 0.02\"],[\"attn( in, &lt;s&gt;)= 0.00\",\"attn( in, The)= 0.00\",\"attn( in,  Fed)= 0.00\",\"attn( in,  apparent)= 0.00\",\"attn( in, ly)= 0.00\",\"attn( in,  could)= 0.00\",\"attn( in,  not)= 0.00\",\"attn( in,  st)= 0.00\",\"attn( in, om)= 0.00\",\"attn( in, ach)= 0.00\",\"attn( in,  the)= 0.00\",\"attn( in,  sell)= 0.00\",\"attn( in, -)= 0.00\",\"attn( in, off)= 0.00\",\"attn( in,  in)= 0.00\",\"attn( in,  global)= 0.00\",\"attn( in,  financial)= 0.00\",\"attn( in,  markets)= 0.00\",\"attn( in,  in)= 0.00\",\"attn( in,  January)= 0.00\",\"attn( in,  and)= 0.00\",\"attn( in,  F)= 0.00\",\"attn( in, eb)= 0.00\",\"attn( in, ru)= 0.00\",\"attn( in, ary)= 0.00\",\"attn( in, ,)= 0.00\",\"attn( in,  which)= 0.00\",\"attn( in,  was)= 0.00\",\"attn( in,  driven)= 0.00\",\"attn( in,  largely)= 0.00\",\"attn( in,  by)= 0.00\",\"attn( in,  concerns)= 0.99\",\"attn( in,  about)= 0.01\",\"attn( in,  further)= 0.00\",\"attn( in,  tight)= 0.00\",\"attn( in, ening)= 0.00\",\"attn( in, .)= 0.00\",\"attn( in, &lt;\\u002fs&gt;)= 0.00\"],[\"attn( global, &lt;s&gt;)= 0.00\",\"attn( global, The)= 0.00\",\"attn( global,  Fed)= 0.00\",\"attn( global,  apparent)= 0.00\",\"attn( global, ly)= 0.00\",\"attn( global,  could)= 0.00\",\"attn( global,  not)= 0.00\",\"attn( global,  st)= 0.00\",\"attn( global, om)= 0.00\",\"attn( global, ach)= 0.00\",\"attn( global,  the)= 0.00\",\"attn( global,  sell)= 0.00\",\"attn( global, -)= 0.00\",\"attn( global, off)= 0.00\",\"attn( global,  in)= 0.00\",\"attn( global,  global)= 0.00\",\"attn( global,  financial)= 0.00\",\"attn( global,  markets)= 0.00\",\"attn( global,  in)= 0.00\",\"attn( global,  January)= 0.00\",\"attn( global,  and)= 0.00\",\"attn( global,  F)= 0.00\",\"attn( global, eb)= 0.00\",\"attn( global, ru)= 0.00\",\"attn( global, ary)= 0.00\",\"attn( global, ,)= 0.00\",\"attn( global,  which)= 0.00\",\"attn( global,  was)= 0.00\",\"attn( global,  driven)= 0.00\",\"attn( global,  largely)= 0.00\",\"attn( global,  by)= 0.00\",\"attn( global,  concerns)= 0.99\",\"attn( global,  about)= 0.01\",\"attn( global,  further)= 0.00\",\"attn( global,  tight)= 0.00\",\"attn( global, ening)= 0.00\",\"attn( global, .)= 0.00\",\"attn( global, &lt;\\u002fs&gt;)= 0.00\"],[\"attn( financial, &lt;s&gt;)= 0.00\",\"attn( financial, The)= 0.00\",\"attn( financial,  Fed)= 0.00\",\"attn( financial,  apparent)= 0.00\",\"attn( financial, ly)= 0.00\",\"attn( financial,  could)= 0.00\",\"attn( financial,  not)= 0.00\",\"attn( financial,  st)= 0.00\",\"attn( financial, om)= 0.00\",\"attn( financial, ach)= 0.00\",\"attn( financial,  the)= 0.00\",\"attn( financial,  sell)= 0.00\",\"attn( financial, -)= 0.00\",\"attn( financial, off)= 0.00\",\"attn( financial,  in)= 0.00\",\"attn( financial,  global)= 0.00\",\"attn( financial,  financial)= 0.00\",\"attn( financial,  markets)= 0.00\",\"attn( financial,  in)= 0.00\",\"attn( financial,  January)= 0.00\",\"attn( financial,  and)= 0.02\",\"attn( financial,  F)= 0.00\",\"attn( financial, eb)= 0.00\",\"attn( financial, ru)= 0.00\",\"attn( financial, ary)= 0.00\",\"attn( financial, ,)= 0.22\",\"attn( financial,  which)= 0.00\",\"attn( financial,  was)= 0.00\",\"attn( financial,  driven)= 0.00\",\"attn( financial,  largely)= 0.00\",\"attn( financial,  by)= 0.01\",\"attn( financial,  concerns)= 0.49\",\"attn( financial,  about)= 0.09\",\"attn( financial,  further)= 0.00\",\"attn( financial,  tight)= 0.00\",\"attn( financial, ening)= 0.00\",\"attn( financial, .)= 0.02\",\"attn( financial, &lt;\\u002fs&gt;)= 0.16\"],[\"attn( markets, &lt;s&gt;)= 0.00\",\"attn( markets, The)= 0.00\",\"attn( markets,  Fed)= 0.00\",\"attn( markets,  apparent)= 0.00\",\"attn( markets, ly)= 0.00\",\"attn( markets,  could)= 0.00\",\"attn( markets,  not)= 0.00\",\"attn( markets,  st)= 0.00\",\"attn( markets, om)= 0.00\",\"attn( markets, ach)= 0.00\",\"attn( markets,  the)= 0.00\",\"attn( markets,  sell)= 0.00\",\"attn( markets, -)= 0.00\",\"attn( markets, off)= 0.00\",\"attn( markets,  in)= 0.00\",\"attn( markets,  global)= 0.00\",\"attn( markets,  financial)= 0.00\",\"attn( markets,  markets)= 0.00\",\"attn( markets,  in)= 0.00\",\"attn( markets,  January)= 0.00\",\"attn( markets,  and)= 0.02\",\"attn( markets,  F)= 0.00\",\"attn( markets, eb)= 0.00\",\"attn( markets, ru)= 0.00\",\"attn( markets, ary)= 0.00\",\"attn( markets, ,)= 0.27\",\"attn( markets,  which)= 0.00\",\"attn( markets,  was)= 0.00\",\"attn( markets,  driven)= 0.00\",\"attn( markets,  largely)= 0.00\",\"attn( markets,  by)= 0.01\",\"attn( markets,  concerns)= 0.43\",\"attn( markets,  about)= 0.09\",\"attn( markets,  further)= 0.00\",\"attn( markets,  tight)= 0.00\",\"attn( markets, ening)= 0.00\",\"attn( markets, .)= 0.02\",\"attn( markets, &lt;\\u002fs&gt;)= 0.16\"],[\"attn( in, &lt;s&gt;)= 0.00\",\"attn( in, The)= 0.00\",\"attn( in,  Fed)= 0.00\",\"attn( in,  apparent)= 0.00\",\"attn( in, ly)= 0.00\",\"attn( in,  could)= 0.00\",\"attn( in,  not)= 0.00\",\"attn( in,  st)= 0.00\",\"attn( in, om)= 0.00\",\"attn( in, ach)= 0.00\",\"attn( in,  the)= 0.00\",\"attn( in,  sell)= 0.00\",\"attn( in, -)= 0.00\",\"attn( in, off)= 0.00\",\"attn( in,  in)= 0.00\",\"attn( in,  global)= 0.00\",\"attn( in,  financial)= 0.00\",\"attn( in,  markets)= 0.00\",\"attn( in,  in)= 0.00\",\"attn( in,  January)= 0.00\",\"attn( in,  and)= 0.00\",\"attn( in,  F)= 0.00\",\"attn( in, eb)= 0.00\",\"attn( in, ru)= 0.00\",\"attn( in, ary)= 0.00\",\"attn( in, ,)= 0.00\",\"attn( in,  which)= 0.00\",\"attn( in,  was)= 0.00\",\"attn( in,  driven)= 0.00\",\"attn( in,  largely)= 0.00\",\"attn( in,  by)= 0.00\",\"attn( in,  concerns)= 0.99\",\"attn( in,  about)= 0.01\",\"attn( in,  further)= 0.00\",\"attn( in,  tight)= 0.00\",\"attn( in, ening)= 0.00\",\"attn( in, .)= 0.00\",\"attn( in, &lt;\\u002fs&gt;)= 0.00\"],[\"attn( January, &lt;s&gt;)= 0.00\",\"attn( January, The)= 0.00\",\"attn( January,  Fed)= 0.00\",\"attn( January,  apparent)= 0.00\",\"attn( January, ly)= 0.00\",\"attn( January,  could)= 0.00\",\"attn( January,  not)= 0.00\",\"attn( January,  st)= 0.00\",\"attn( January, om)= 0.00\",\"attn( January, ach)= 0.00\",\"attn( January,  the)= 0.00\",\"attn( January,  sell)= 0.00\",\"attn( January, -)= 0.00\",\"attn( January, off)= 0.00\",\"attn( January,  in)= 0.00\",\"attn( January,  global)= 0.00\",\"attn( January,  financial)= 0.00\",\"attn( January,  markets)= 0.00\",\"attn( January,  in)= 0.00\",\"attn( January,  January)= 0.00\",\"attn( January,  and)= 0.00\",\"attn( January,  F)= 0.00\",\"attn( January, eb)= 0.00\",\"attn( January, ru)= 0.00\",\"attn( January, ary)= 0.00\",\"attn( January, ,)= 0.00\",\"attn( January,  which)= 0.00\",\"attn( January,  was)= 0.00\",\"attn( January,  driven)= 0.00\",\"attn( January,  largely)= 0.00\",\"attn( January,  by)= 0.00\",\"attn( January,  concerns)= 0.98\",\"attn( January,  about)= 0.01\",\"attn( January,  further)= 0.00\",\"attn( January,  tight)= 0.00\",\"attn( January, ening)= 0.00\",\"attn( January, .)= 0.00\",\"attn( January, &lt;\\u002fs&gt;)= 0.00\"],[\"attn( and, &lt;s&gt;)= 0.00\",\"attn( and, The)= 0.00\",\"attn( and,  Fed)= 0.00\",\"attn( and,  apparent)= 0.00\",\"attn( and, ly)= 0.00\",\"attn( and,  could)= 0.00\",\"attn( and,  not)= 0.00\",\"attn( and,  st)= 0.00\",\"attn( and, om)= 0.00\",\"attn( and, ach)= 0.00\",\"attn( and,  the)= 0.00\",\"attn( and,  sell)= 0.00\",\"attn( and, -)= 0.00\",\"attn( and, off)= 0.00\",\"attn( and,  in)= 0.00\",\"attn( and,  global)= 0.00\",\"attn( and,  financial)= 0.00\",\"attn( and,  markets)= 0.00\",\"attn( and,  in)= 0.00\",\"attn( and,  January)= 0.00\",\"attn( and,  and)= 0.00\",\"attn( and,  F)= 0.00\",\"attn( and, eb)= 0.00\",\"attn( and, ru)= 0.00\",\"attn( and, ary)= 0.00\",\"attn( and, ,)= 0.00\",\"attn( and,  which)= 0.00\",\"attn( and,  was)= 0.00\",\"attn( and,  driven)= 0.00\",\"attn( and,  largely)= 0.00\",\"attn( and,  by)= 0.00\",\"attn( and,  concerns)= 0.96\",\"attn( and,  about)= 0.03\",\"attn( and,  further)= 0.00\",\"attn( and,  tight)= 0.00\",\"attn( and, ening)= 0.00\",\"attn( and, .)= 0.00\",\"attn( and, &lt;\\u002fs&gt;)= 0.01\"],[\"attn( F, &lt;s&gt;)= 0.00\",\"attn( F, The)= 0.00\",\"attn( F,  Fed)= 0.00\",\"attn( F,  apparent)= 0.00\",\"attn( F, ly)= 0.00\",\"attn( F,  could)= 0.00\",\"attn( F,  not)= 0.00\",\"attn( F,  st)= 0.00\",\"attn( F, om)= 0.00\",\"attn( F, ach)= 0.00\",\"attn( F,  the)= 0.00\",\"attn( F,  sell)= 0.00\",\"attn( F, -)= 0.00\",\"attn( F, off)= 0.00\",\"attn( F,  in)= 0.00\",\"attn( F,  global)= 0.00\",\"attn( F,  financial)= 0.00\",\"attn( F,  markets)= 0.00\",\"attn( F,  in)= 0.00\",\"attn( F,  January)= 0.00\",\"attn( F,  and)= 0.00\",\"attn( F,  F)= 0.00\",\"attn( F, eb)= 0.00\",\"attn( F, ru)= 0.00\",\"attn( F, ary)= 0.00\",\"attn( F, ,)= 0.00\",\"attn( F,  which)= 0.00\",\"attn( F,  was)= 0.00\",\"attn( F,  driven)= 0.00\",\"attn( F,  largely)= 0.00\",\"attn( F,  by)= 0.00\",\"attn( F,  concerns)= 0.99\",\"attn( F,  about)= 0.01\",\"attn( F,  further)= 0.00\",\"attn( F,  tight)= 0.00\",\"attn( F, ening)= 0.00\",\"attn( F, .)= 0.00\",\"attn( F, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(eb, &lt;s&gt;)= 0.00\",\"attn(eb, The)= 0.00\",\"attn(eb,  Fed)= 0.00\",\"attn(eb,  apparent)= 0.00\",\"attn(eb, ly)= 0.00\",\"attn(eb,  could)= 0.00\",\"attn(eb,  not)= 0.00\",\"attn(eb,  st)= 0.00\",\"attn(eb, om)= 0.00\",\"attn(eb, ach)= 0.00\",\"attn(eb,  the)= 0.00\",\"attn(eb,  sell)= 0.00\",\"attn(eb, -)= 0.00\",\"attn(eb, off)= 0.00\",\"attn(eb,  in)= 0.00\",\"attn(eb,  global)= 0.00\",\"attn(eb,  financial)= 0.00\",\"attn(eb,  markets)= 0.00\",\"attn(eb,  in)= 0.00\",\"attn(eb,  January)= 0.00\",\"attn(eb,  and)= 0.00\",\"attn(eb,  F)= 0.00\",\"attn(eb, eb)= 0.00\",\"attn(eb, ru)= 0.00\",\"attn(eb, ary)= 0.00\",\"attn(eb, ,)= 0.00\",\"attn(eb,  which)= 0.00\",\"attn(eb,  was)= 0.00\",\"attn(eb,  driven)= 0.00\",\"attn(eb,  largely)= 0.00\",\"attn(eb,  by)= 0.00\",\"attn(eb,  concerns)= 0.99\",\"attn(eb,  about)= 0.01\",\"attn(eb,  further)= 0.00\",\"attn(eb,  tight)= 0.00\",\"attn(eb, ening)= 0.00\",\"attn(eb, .)= 0.00\",\"attn(eb, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(ru, &lt;s&gt;)= 0.00\",\"attn(ru, The)= 0.00\",\"attn(ru,  Fed)= 0.00\",\"attn(ru,  apparent)= 0.00\",\"attn(ru, ly)= 0.00\",\"attn(ru,  could)= 0.00\",\"attn(ru,  not)= 0.00\",\"attn(ru,  st)= 0.00\",\"attn(ru, om)= 0.00\",\"attn(ru, ach)= 0.00\",\"attn(ru,  the)= 0.00\",\"attn(ru,  sell)= 0.00\",\"attn(ru, -)= 0.00\",\"attn(ru, off)= 0.00\",\"attn(ru,  in)= 0.00\",\"attn(ru,  global)= 0.00\",\"attn(ru,  financial)= 0.00\",\"attn(ru,  markets)= 0.00\",\"attn(ru,  in)= 0.00\",\"attn(ru,  January)= 0.00\",\"attn(ru,  and)= 0.00\",\"attn(ru,  F)= 0.00\",\"attn(ru, eb)= 0.00\",\"attn(ru, ru)= 0.00\",\"attn(ru, ary)= 0.00\",\"attn(ru, ,)= 0.00\",\"attn(ru,  which)= 0.00\",\"attn(ru,  was)= 0.00\",\"attn(ru,  driven)= 0.00\",\"attn(ru,  largely)= 0.00\",\"attn(ru,  by)= 0.00\",\"attn(ru,  concerns)= 0.95\",\"attn(ru,  about)= 0.03\",\"attn(ru,  further)= 0.00\",\"attn(ru,  tight)= 0.00\",\"attn(ru, ening)= 0.00\",\"attn(ru, .)= 0.00\",\"attn(ru, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(ary, &lt;s&gt;)= 0.00\",\"attn(ary, The)= 0.00\",\"attn(ary,  Fed)= 0.00\",\"attn(ary,  apparent)= 0.00\",\"attn(ary, ly)= 0.00\",\"attn(ary,  could)= 0.00\",\"attn(ary,  not)= 0.00\",\"attn(ary,  st)= 0.00\",\"attn(ary, om)= 0.00\",\"attn(ary, ach)= 0.00\",\"attn(ary,  the)= 0.00\",\"attn(ary,  sell)= 0.00\",\"attn(ary, -)= 0.00\",\"attn(ary, off)= 0.00\",\"attn(ary,  in)= 0.00\",\"attn(ary,  global)= 0.00\",\"attn(ary,  financial)= 0.00\",\"attn(ary,  markets)= 0.00\",\"attn(ary,  in)= 0.00\",\"attn(ary,  January)= 0.00\",\"attn(ary,  and)= 0.00\",\"attn(ary,  F)= 0.00\",\"attn(ary, eb)= 0.00\",\"attn(ary, ru)= 0.00\",\"attn(ary, ary)= 0.00\",\"attn(ary, ,)= 0.00\",\"attn(ary,  which)= 0.00\",\"attn(ary,  was)= 0.00\",\"attn(ary,  driven)= 0.00\",\"attn(ary,  largely)= 0.00\",\"attn(ary,  by)= 0.00\",\"attn(ary,  concerns)= 0.98\",\"attn(ary,  about)= 0.01\",\"attn(ary,  further)= 0.00\",\"attn(ary,  tight)= 0.00\",\"attn(ary, ening)= 0.00\",\"attn(ary, .)= 0.00\",\"attn(ary, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(,, &lt;s&gt;)= 0.00\",\"attn(,, The)= 0.00\",\"attn(,,  Fed)= 0.00\",\"attn(,,  apparent)= 0.00\",\"attn(,, ly)= 0.00\",\"attn(,,  could)= 0.00\",\"attn(,,  not)= 0.00\",\"attn(,,  st)= 0.00\",\"attn(,, om)= 0.00\",\"attn(,, ach)= 0.00\",\"attn(,,  the)= 0.00\",\"attn(,,  sell)= 0.00\",\"attn(,, -)= 0.00\",\"attn(,, off)= 0.00\",\"attn(,,  in)= 0.00\",\"attn(,,  global)= 0.00\",\"attn(,,  financial)= 0.00\",\"attn(,,  markets)= 0.00\",\"attn(,,  in)= 0.00\",\"attn(,,  January)= 0.00\",\"attn(,,  and)= 0.00\",\"attn(,,  F)= 0.00\",\"attn(,, eb)= 0.00\",\"attn(,, ru)= 0.00\",\"attn(,, ary)= 0.00\",\"attn(,, ,)= 0.00\",\"attn(,,  which)= 0.00\",\"attn(,,  was)= 0.00\",\"attn(,,  driven)= 0.00\",\"attn(,,  largely)= 0.00\",\"attn(,,  by)= 0.00\",\"attn(,,  concerns)= 0.94\",\"attn(,,  about)= 0.04\",\"attn(,,  further)= 0.00\",\"attn(,,  tight)= 0.00\",\"attn(,, ening)= 0.00\",\"attn(,, .)= 0.00\",\"attn(,, &lt;\\u002fs&gt;)= 0.01\"],[\"attn( which, &lt;s&gt;)= 0.00\",\"attn( which, The)= 0.00\",\"attn( which,  Fed)= 0.00\",\"attn( which,  apparent)= 0.00\",\"attn( which, ly)= 0.00\",\"attn( which,  could)= 0.00\",\"attn( which,  not)= 0.00\",\"attn( which,  st)= 0.00\",\"attn( which, om)= 0.00\",\"attn( which, ach)= 0.00\",\"attn( which,  the)= 0.00\",\"attn( which,  sell)= 0.00\",\"attn( which, -)= 0.00\",\"attn( which, off)= 0.00\",\"attn( which,  in)= 0.00\",\"attn( which,  global)= 0.00\",\"attn( which,  financial)= 0.00\",\"attn( which,  markets)= 0.00\",\"attn( which,  in)= 0.00\",\"attn( which,  January)= 0.00\",\"attn( which,  and)= 0.00\",\"attn( which,  F)= 0.00\",\"attn( which, eb)= 0.00\",\"attn( which, ru)= 0.00\",\"attn( which, ary)= 0.00\",\"attn( which, ,)= 0.00\",\"attn( which,  which)= 0.00\",\"attn( which,  was)= 0.00\",\"attn( which,  driven)= 0.00\",\"attn( which,  largely)= 0.00\",\"attn( which,  by)= 0.01\",\"attn( which,  concerns)= 0.94\",\"attn( which,  about)= 0.03\",\"attn( which,  further)= 0.01\",\"attn( which,  tight)= 0.00\",\"attn( which, ening)= 0.00\",\"attn( which, .)= 0.00\",\"attn( which, &lt;\\u002fs&gt;)= 0.01\"],[\"attn( was, &lt;s&gt;)= 0.00\",\"attn( was, The)= 0.00\",\"attn( was,  Fed)= 0.00\",\"attn( was,  apparent)= 0.00\",\"attn( was, ly)= 0.00\",\"attn( was,  could)= 0.00\",\"attn( was,  not)= 0.00\",\"attn( was,  st)= 0.00\",\"attn( was, om)= 0.00\",\"attn( was, ach)= 0.00\",\"attn( was,  the)= 0.00\",\"attn( was,  sell)= 0.00\",\"attn( was, -)= 0.00\",\"attn( was, off)= 0.00\",\"attn( was,  in)= 0.00\",\"attn( was,  global)= 0.00\",\"attn( was,  financial)= 0.00\",\"attn( was,  markets)= 0.00\",\"attn( was,  in)= 0.00\",\"attn( was,  January)= 0.00\",\"attn( was,  and)= 0.00\",\"attn( was,  F)= 0.00\",\"attn( was, eb)= 0.00\",\"attn( was, ru)= 0.00\",\"attn( was, ary)= 0.00\",\"attn( was, ,)= 0.00\",\"attn( was,  which)= 0.00\",\"attn( was,  was)= 0.00\",\"attn( was,  driven)= 0.00\",\"attn( was,  largely)= 0.00\",\"attn( was,  by)= 0.01\",\"attn( was,  concerns)= 0.90\",\"attn( was,  about)= 0.05\",\"attn( was,  further)= 0.01\",\"attn( was,  tight)= 0.00\",\"attn( was, ening)= 0.00\",\"attn( was, .)= 0.00\",\"attn( was, &lt;\\u002fs&gt;)= 0.01\"],[\"attn( driven, &lt;s&gt;)= 0.00\",\"attn( driven, The)= 0.00\",\"attn( driven,  Fed)= 0.00\",\"attn( driven,  apparent)= 0.00\",\"attn( driven, ly)= 0.00\",\"attn( driven,  could)= 0.00\",\"attn( driven,  not)= 0.00\",\"attn( driven,  st)= 0.00\",\"attn( driven, om)= 0.00\",\"attn( driven, ach)= 0.00\",\"attn( driven,  the)= 0.00\",\"attn( driven,  sell)= 0.00\",\"attn( driven, -)= 0.00\",\"attn( driven, off)= 0.00\",\"attn( driven,  in)= 0.00\",\"attn( driven,  global)= 0.00\",\"attn( driven,  financial)= 0.00\",\"attn( driven,  markets)= 0.00\",\"attn( driven,  in)= 0.00\",\"attn( driven,  January)= 0.00\",\"attn( driven,  and)= 0.04\",\"attn( driven,  F)= 0.00\",\"attn( driven, eb)= 0.00\",\"attn( driven, ru)= 0.00\",\"attn( driven, ary)= 0.00\",\"attn( driven, ,)= 0.08\",\"attn( driven,  which)= 0.00\",\"attn( driven,  was)= 0.00\",\"attn( driven,  driven)= 0.00\",\"attn( driven,  largely)= 0.00\",\"attn( driven,  by)= 0.02\",\"attn( driven,  concerns)= 0.61\",\"attn( driven,  about)= 0.12\",\"attn( driven,  further)= 0.01\",\"attn( driven,  tight)= 0.01\",\"attn( driven, ening)= 0.01\",\"attn( driven, .)= 0.01\",\"attn( driven, &lt;\\u002fs&gt;)= 0.09\"],[\"attn( largely, &lt;s&gt;)= 0.00\",\"attn( largely, The)= 0.00\",\"attn( largely,  Fed)= 0.00\",\"attn( largely,  apparent)= 0.00\",\"attn( largely, ly)= 0.00\",\"attn( largely,  could)= 0.00\",\"attn( largely,  not)= 0.00\",\"attn( largely,  st)= 0.00\",\"attn( largely, om)= 0.00\",\"attn( largely, ach)= 0.00\",\"attn( largely,  the)= 0.00\",\"attn( largely,  sell)= 0.00\",\"attn( largely, -)= 0.00\",\"attn( largely, off)= 0.00\",\"attn( largely,  in)= 0.00\",\"attn( largely,  global)= 0.00\",\"attn( largely,  financial)= 0.00\",\"attn( largely,  markets)= 0.00\",\"attn( largely,  in)= 0.00\",\"attn( largely,  January)= 0.00\",\"attn( largely,  and)= 0.01\",\"attn( largely,  F)= 0.00\",\"attn( largely, eb)= 0.00\",\"attn( largely, ru)= 0.00\",\"attn( largely, ary)= 0.00\",\"attn( largely, ,)= 0.01\",\"attn( largely,  which)= 0.00\",\"attn( largely,  was)= 0.00\",\"attn( largely,  driven)= 0.00\",\"attn( largely,  largely)= 0.00\",\"attn( largely,  by)= 0.01\",\"attn( largely,  concerns)= 0.82\",\"attn( largely,  about)= 0.08\",\"attn( largely,  further)= 0.01\",\"attn( largely,  tight)= 0.00\",\"attn( largely, ening)= 0.00\",\"attn( largely, .)= 0.00\",\"attn( largely, &lt;\\u002fs&gt;)= 0.03\"],[\"attn( by, &lt;s&gt;)= 0.00\",\"attn( by, The)= 0.00\",\"attn( by,  Fed)= 0.00\",\"attn( by,  apparent)= 0.00\",\"attn( by, ly)= 0.00\",\"attn( by,  could)= 0.00\",\"attn( by,  not)= 0.00\",\"attn( by,  st)= 0.00\",\"attn( by, om)= 0.00\",\"attn( by, ach)= 0.00\",\"attn( by,  the)= 0.00\",\"attn( by,  sell)= 0.00\",\"attn( by, -)= 0.00\",\"attn( by, off)= 0.00\",\"attn( by,  in)= 0.00\",\"attn( by,  global)= 0.00\",\"attn( by,  financial)= 0.00\",\"attn( by,  markets)= 0.00\",\"attn( by,  in)= 0.00\",\"attn( by,  January)= 0.00\",\"attn( by,  and)= 0.03\",\"attn( by,  F)= 0.00\",\"attn( by, eb)= 0.00\",\"attn( by, ru)= 0.00\",\"attn( by, ary)= 0.00\",\"attn( by, ,)= 0.04\",\"attn( by,  which)= 0.00\",\"attn( by,  was)= 0.00\",\"attn( by,  driven)= 0.00\",\"attn( by,  largely)= 0.00\",\"attn( by,  by)= 0.02\",\"attn( by,  concerns)= 0.67\",\"attn( by,  about)= 0.12\",\"attn( by,  further)= 0.02\",\"attn( by,  tight)= 0.01\",\"attn( by, ening)= 0.01\",\"attn( by, .)= 0.01\",\"attn( by, &lt;\\u002fs&gt;)= 0.07\"],[\"attn( concerns, &lt;s&gt;)= 0.00\",\"attn( concerns, The)= 0.00\",\"attn( concerns,  Fed)= 0.00\",\"attn( concerns,  apparent)= 0.00\",\"attn( concerns, ly)= 0.00\",\"attn( concerns,  could)= 0.00\",\"attn( concerns,  not)= 0.00\",\"attn( concerns,  st)= 0.00\",\"attn( concerns, om)= 0.00\",\"attn( concerns, ach)= 0.00\",\"attn( concerns,  the)= 0.00\",\"attn( concerns,  sell)= 0.00\",\"attn( concerns, -)= 0.00\",\"attn( concerns, off)= 0.00\",\"attn( concerns,  in)= 0.00\",\"attn( concerns,  global)= 0.00\",\"attn( concerns,  financial)= 0.00\",\"attn( concerns,  markets)= 0.00\",\"attn( concerns,  in)= 0.00\",\"attn( concerns,  January)= 0.00\",\"attn( concerns,  and)= 0.01\",\"attn( concerns,  F)= 0.00\",\"attn( concerns, eb)= 0.00\",\"attn( concerns, ru)= 0.00\",\"attn( concerns, ary)= 0.00\",\"attn( concerns, ,)= 0.03\",\"attn( concerns,  which)= 0.00\",\"attn( concerns,  was)= 0.00\",\"attn( concerns,  driven)= 0.00\",\"attn( concerns,  largely)= 0.00\",\"attn( concerns,  by)= 0.02\",\"attn( concerns,  concerns)= 0.73\",\"attn( concerns,  about)= 0.11\",\"attn( concerns,  further)= 0.01\",\"attn( concerns,  tight)= 0.01\",\"attn( concerns, ening)= 0.01\",\"attn( concerns, .)= 0.01\",\"attn( concerns, &lt;\\u002fs&gt;)= 0.06\"],[\"attn( about, &lt;s&gt;)= 0.00\",\"attn( about, The)= 0.00\",\"attn( about,  Fed)= 0.00\",\"attn( about,  apparent)= 0.00\",\"attn( about, ly)= 0.00\",\"attn( about,  could)= 0.00\",\"attn( about,  not)= 0.00\",\"attn( about,  st)= 0.00\",\"attn( about, om)= 0.00\",\"attn( about, ach)= 0.00\",\"attn( about,  the)= 0.00\",\"attn( about,  sell)= 0.00\",\"attn( about, -)= 0.00\",\"attn( about, off)= 0.00\",\"attn( about,  in)= 0.00\",\"attn( about,  global)= 0.00\",\"attn( about,  financial)= 0.00\",\"attn( about,  markets)= 0.00\",\"attn( about,  in)= 0.00\",\"attn( about,  January)= 0.00\",\"attn( about,  and)= 0.03\",\"attn( about,  F)= 0.00\",\"attn( about, eb)= 0.00\",\"attn( about, ru)= 0.00\",\"attn( about, ary)= 0.00\",\"attn( about, ,)= 0.06\",\"attn( about,  which)= 0.00\",\"attn( about,  was)= 0.00\",\"attn( about,  driven)= 0.00\",\"attn( about,  largely)= 0.00\",\"attn( about,  by)= 0.02\",\"attn( about,  concerns)= 0.63\",\"attn( about,  about)= 0.12\",\"attn( about,  further)= 0.01\",\"attn( about,  tight)= 0.01\",\"attn( about, ening)= 0.01\",\"attn( about, .)= 0.01\",\"attn( about, &lt;\\u002fs&gt;)= 0.09\"],[\"attn( further, &lt;s&gt;)= 0.00\",\"attn( further, The)= 0.00\",\"attn( further,  Fed)= 0.00\",\"attn( further,  apparent)= 0.00\",\"attn( further, ly)= 0.00\",\"attn( further,  could)= 0.00\",\"attn( further,  not)= 0.00\",\"attn( further,  st)= 0.00\",\"attn( further, om)= 0.00\",\"attn( further, ach)= 0.00\",\"attn( further,  the)= 0.00\",\"attn( further,  sell)= 0.00\",\"attn( further, -)= 0.00\",\"attn( further, off)= 0.00\",\"attn( further,  in)= 0.00\",\"attn( further,  global)= 0.00\",\"attn( further,  financial)= 0.00\",\"attn( further,  markets)= 0.00\",\"attn( further,  in)= 0.00\",\"attn( further,  January)= 0.00\",\"attn( further,  and)= 0.03\",\"attn( further,  F)= 0.00\",\"attn( further, eb)= 0.00\",\"attn( further, ru)= 0.00\",\"attn( further, ary)= 0.00\",\"attn( further, ,)= 0.13\",\"attn( further,  which)= 0.00\",\"attn( further,  was)= 0.00\",\"attn( further,  driven)= 0.00\",\"attn( further,  largely)= 0.00\",\"attn( further,  by)= 0.02\",\"attn( further,  concerns)= 0.54\",\"attn( further,  about)= 0.12\",\"attn( further,  further)= 0.01\",\"attn( further,  tight)= 0.01\",\"attn( further, ening)= 0.00\",\"attn( further, .)= 0.02\",\"attn( further, &lt;\\u002fs&gt;)= 0.12\"],[\"attn( tight, &lt;s&gt;)= 0.00\",\"attn( tight, The)= 0.00\",\"attn( tight,  Fed)= 0.00\",\"attn( tight,  apparent)= 0.00\",\"attn( tight, ly)= 0.00\",\"attn( tight,  could)= 0.00\",\"attn( tight,  not)= 0.00\",\"attn( tight,  st)= 0.00\",\"attn( tight, om)= 0.00\",\"attn( tight, ach)= 0.00\",\"attn( tight,  the)= 0.00\",\"attn( tight,  sell)= 0.00\",\"attn( tight, -)= 0.00\",\"attn( tight, off)= 0.00\",\"attn( tight,  in)= 0.00\",\"attn( tight,  global)= 0.00\",\"attn( tight,  financial)= 0.00\",\"attn( tight,  markets)= 0.00\",\"attn( tight,  in)= 0.00\",\"attn( tight,  January)= 0.00\",\"attn( tight,  and)= 0.02\",\"attn( tight,  F)= 0.00\",\"attn( tight, eb)= 0.00\",\"attn( tight, ru)= 0.00\",\"attn( tight, ary)= 0.00\",\"attn( tight, ,)= 0.10\",\"attn( tight,  which)= 0.00\",\"attn( tight,  was)= 0.00\",\"attn( tight,  driven)= 0.00\",\"attn( tight,  largely)= 0.00\",\"attn( tight,  by)= 0.02\",\"attn( tight,  concerns)= 0.60\",\"attn( tight,  about)= 0.12\",\"attn( tight,  further)= 0.01\",\"attn( tight,  tight)= 0.01\",\"attn( tight, ening)= 0.00\",\"attn( tight, .)= 0.01\",\"attn( tight, &lt;\\u002fs&gt;)= 0.11\"],[\"attn(ening, &lt;s&gt;)= 0.00\",\"attn(ening, The)= 0.00\",\"attn(ening,  Fed)= 0.00\",\"attn(ening,  apparent)= 0.00\",\"attn(ening, ly)= 0.00\",\"attn(ening,  could)= 0.00\",\"attn(ening,  not)= 0.00\",\"attn(ening,  st)= 0.00\",\"attn(ening, om)= 0.00\",\"attn(ening, ach)= 0.00\",\"attn(ening,  the)= 0.00\",\"attn(ening,  sell)= 0.00\",\"attn(ening, -)= 0.00\",\"attn(ening, off)= 0.00\",\"attn(ening,  in)= 0.00\",\"attn(ening,  global)= 0.00\",\"attn(ening,  financial)= 0.00\",\"attn(ening,  markets)= 0.00\",\"attn(ening,  in)= 0.00\",\"attn(ening,  January)= 0.00\",\"attn(ening,  and)= 0.04\",\"attn(ening,  F)= 0.00\",\"attn(ening, eb)= 0.00\",\"attn(ening, ru)= 0.00\",\"attn(ening, ary)= 0.00\",\"attn(ening, ,)= 0.19\",\"attn(ening,  which)= 0.00\",\"attn(ening,  was)= 0.00\",\"attn(ening,  driven)= 0.00\",\"attn(ening,  largely)= 0.00\",\"attn(ening,  by)= 0.02\",\"attn(ening,  concerns)= 0.44\",\"attn(ening,  about)= 0.12\",\"attn(ening,  further)= 0.01\",\"attn(ening,  tight)= 0.01\",\"attn(ening, ening)= 0.00\",\"attn(ening, .)= 0.02\",\"attn(ening, &lt;\\u002fs&gt;)= 0.14\"],[\"attn(., &lt;s&gt;)= 0.00\",\"attn(., The)= 0.00\",\"attn(.,  Fed)= 0.00\",\"attn(.,  apparent)= 0.00\",\"attn(., ly)= 0.00\",\"attn(.,  could)= 0.00\",\"attn(.,  not)= 0.00\",\"attn(.,  st)= 0.00\",\"attn(., om)= 0.00\",\"attn(., ach)= 0.00\",\"attn(.,  the)= 0.00\",\"attn(.,  sell)= 0.00\",\"attn(., -)= 0.00\",\"attn(., off)= 0.00\",\"attn(.,  in)= 0.00\",\"attn(.,  global)= 0.00\",\"attn(.,  financial)= 0.00\",\"attn(.,  markets)= 0.00\",\"attn(.,  in)= 0.00\",\"attn(.,  January)= 0.00\",\"attn(.,  and)= 0.02\",\"attn(.,  F)= 0.00\",\"attn(., eb)= 0.00\",\"attn(., ru)= 0.00\",\"attn(., ary)= 0.00\",\"attn(., ,)= 0.04\",\"attn(.,  which)= 0.00\",\"attn(.,  was)= 0.00\",\"attn(.,  driven)= 0.00\",\"attn(.,  largely)= 0.00\",\"attn(.,  by)= 0.02\",\"attn(.,  concerns)= 0.73\",\"attn(.,  about)= 0.10\",\"attn(.,  further)= 0.01\",\"attn(.,  tight)= 0.00\",\"attn(., ening)= 0.00\",\"attn(., .)= 0.01\",\"attn(., &lt;\\u002fs&gt;)= 0.07\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.02\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.07\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.00\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.02\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.64\",\"attn(&lt;\\u002fs&gt;,  about)= 0.12\",\"attn(&lt;\\u002fs&gt;,  further)= 0.01\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.01\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.01\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.09\"]],\"x\":[\"\\u003cspan style='font-size: 10px;color:grey'\\u003e000\\u003c\\u002fspan\\u003e  &lt;s&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e001\\u003c\\u002fspan\\u003e  The\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e002\\u003c\\u002fspan\\u003e   Fed\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e003\\u003c\\u002fspan\\u003e   apparent\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e004\\u003c\\u002fspan\\u003e  ly\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e005\\u003c\\u002fspan\\u003e   could\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e006\\u003c\\u002fspan\\u003e   not\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e007\\u003c\\u002fspan\\u003e   st\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e008\\u003c\\u002fspan\\u003e  om\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e009\\u003c\\u002fspan\\u003e  ach\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e010\\u003c\\u002fspan\\u003e   the\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e011\\u003c\\u002fspan\\u003e   sell\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e012\\u003c\\u002fspan\\u003e  -\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e013\\u003c\\u002fspan\\u003e  off\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e014\\u003c\\u002fspan\\u003e   in\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e015\\u003c\\u002fspan\\u003e   global\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e016\\u003c\\u002fspan\\u003e   financial\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e017\\u003c\\u002fspan\\u003e   markets\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e018\\u003c\\u002fspan\\u003e   in\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e019\\u003c\\u002fspan\\u003e   January\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e020\\u003c\\u002fspan\\u003e   and\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e021\\u003c\\u002fspan\\u003e   F\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e022\\u003c\\u002fspan\\u003e  eb\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e023\\u003c\\u002fspan\\u003e  ru\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e024\\u003c\\u002fspan\\u003e  ary\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e025\\u003c\\u002fspan\\u003e  ,\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e026\\u003c\\u002fspan\\u003e   which\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e027\\u003c\\u002fspan\\u003e   was\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e028\\u003c\\u002fspan\\u003e   driven\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e029\\u003c\\u002fspan\\u003e   largely\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e030\\u003c\\u002fspan\\u003e   by\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e031\\u003c\\u002fspan\\u003e   concerns\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e032\\u003c\\u002fspan\\u003e   about\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e033\\u003c\\u002fspan\\u003e   further\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e034\\u003c\\u002fspan\\u003e   tight\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e035\\u003c\\u002fspan\\u003e  ening\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e036\\u003c\\u002fspan\\u003e  .\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e037\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\"],\"xgap\":1,\"y\":[\"\\u003cspan style='font-size: 10px;color:grey'\\u003e000\\u003c\\u002fspan\\u003e  &lt;s&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e001\\u003c\\u002fspan\\u003e  The\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e002\\u003c\\u002fspan\\u003e   Fed\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e003\\u003c\\u002fspan\\u003e   apparent\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e004\\u003c\\u002fspan\\u003e  ly\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e005\\u003c\\u002fspan\\u003e   could\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e006\\u003c\\u002fspan\\u003e   not\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e007\\u003c\\u002fspan\\u003e   st\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e008\\u003c\\u002fspan\\u003e  om\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e009\\u003c\\u002fspan\\u003e  ach\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e010\\u003c\\u002fspan\\u003e   the\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e011\\u003c\\u002fspan\\u003e   sell\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e012\\u003c\\u002fspan\\u003e  -\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e013\\u003c\\u002fspan\\u003e  off\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e014\\u003c\\u002fspan\\u003e   in\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e015\\u003c\\u002fspan\\u003e   global\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e016\\u003c\\u002fspan\\u003e   financial\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e017\\u003c\\u002fspan\\u003e   markets\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e018\\u003c\\u002fspan\\u003e   in\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e019\\u003c\\u002fspan\\u003e   January\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e020\\u003c\\u002fspan\\u003e   and\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e021\\u003c\\u002fspan\\u003e   F\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e022\\u003c\\u002fspan\\u003e  eb\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e023\\u003c\\u002fspan\\u003e  ru\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e024\\u003c\\u002fspan\\u003e  ary\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e025\\u003c\\u002fspan\\u003e  ,\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e026\\u003c\\u002fspan\\u003e   which\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e027\\u003c\\u002fspan\\u003e   was\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e028\\u003c\\u002fspan\\u003e   driven\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e029\\u003c\\u002fspan\\u003e   largely\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e030\\u003c\\u002fspan\\u003e   by\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e031\\u003c\\u002fspan\\u003e   concerns\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e032\\u003c\\u002fspan\\u003e   about\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e033\\u003c\\u002fspan\\u003e   further\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e034\\u003c\\u002fspan\\u003e   tight\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e035\\u003c\\u002fspan\\u003e  ening\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e036\\u003c\\u002fspan\\u003e  .\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e037\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\"],\"ygap\":1,\"z\":[[0.05593738,0.8511681,0.017270073,0.022889081,0.009208193,0.0153736,0.008079235,0.00009397961,0.00004671508,0.000053962598,0.000007615082,0.000015450285,0.0000032596197,9.0868724e-7,0.000001677665,0.0000011447906,0.0000759672,0.0001962016,0.0000017522457,0.006537026,0.0028523505,0.0002643426,0.0012296961,0.000013378529,0.0000060722564,0.004979144,0.0000022790734,0.00000635318,0.00008267288,0.000008473553,0.00006719296,0.000006866898,0.000062521576,0.00007602119,0.00035217506,0.000065056745,0.0024961417,0.00046795764],[0.00001465119,0.0066203056,0.0000016478909,0.0031727892,0.0011184083,0.022091737,0.010966869,0.000022732822,0.000009524451,0.000007287448,0.000007546895,0.0000026899404,0.000018634511,9.249325e-7,0.0000036513961,0.0000035159603,0.00009973665,0.00028714843,0.0000040772125,0.00003466612,0.19711536,0.0000057942243,0.000012304367,0.000041327254,0.0000039042593,0.61926013,0.00001889512,0.000021051226,0.00085800793,0.000094880015,0.0008096343,0.00008330274,0.000971639,0.000923917,0.002900676,0.0005813478,0.116025016,0.015784254],[0.0015592944,0.00093652867,0.0010667287,0.00071031874,0.00130483,0.008574128,0.014207012,0.0041403417,0.004630853,0.011199546,0.007968834,0.0041809445,0.004487662,0.0066952747,0.0013329684,0.0012083885,0.018767104,0.017639838,0.0011213967,0.0005812918,0.073791295,0.002526193,0.00054889335,0.0067407726,0.0053125066,0.058715437,0.0071998816,0.011316836,0.034966882,0.019734666,0.06689418,0.15242067,0.10833989,0.05471954,0.085649826,0.04362273,0.051780168,0.103406295],[4.0657677e-9,0.0000017317268,5.301424e-10,0.000026130285,0.00001931261,0.002719116,0.002345629,0.00001335083,0.000008420062,0.000007794714,0.000038350543,0.0000037654013,0.00022508716,0.00001559732,0.000022674667,0.000027008593,0.00021957957,0.00038840168,0.000021481193,7.6427774e-8,0.32235566,3.4709993e-7,8.7861935e-8,0.00016087436,0.000011813683,0.49567094,0.00030997326,0.00018131518,0.0034362995,0.0014556391,0.0051794914,0.0033672142,0.008753409,0.0053272317,0.005660602,0.0032400563,0.093647346,0.04513828],[8.9330375e-12,2.0992232e-9,1.104158e-12,1.09726415e-7,1.1392541e-7,0.00007231599,0.00008210379,4.1127655e-7,3.0955326e-7,4.0285892e-7,0.0000056202166,1.9947203e-7,0.000064061576,0.0000042630704,0.0000037584846,0.000007924121,0.0000538054,0.00007235669,0.0000041188005,5.118685e-10,0.23810269,9.650737e-9,9.743395e-10,0.00004726218,0.0000025119273,0.5602363,0.0001936034,0.000068240224,0.0027357899,0.0009518599,0.005797264,0.008044921,0.014139232,0.00586144,0.006058534,0.0027345556,0.086665764,0.067988165],[1.902607e-9,6.869668e-7,2.404656e-10,0.000002698059,8.7594566e-7,0.0008384499,0.0006247018,1.2464696e-7,7.126786e-8,7.6774604e-8,3.6469189e-7,2.680519e-8,0.0000010885768,1.12217634e-7,1.6339781e-7,1.365779e-7,0.000003842857,0.000009046563,2.9300574e-7,4.7538595e-8,0.09137705,3.0166927e-8,2.5373124e-8,0.000009257104,3.046191e-7,0.78658235,0.000007753256,0.0000061317032,0.0005208507,0.000044003165,0.0009743137,0.00020406536,0.0016694609,0.0006479941,0.0017441447,0.00026062227,0.094217576,0.02025129],[2.3457765e-9,5.217706e-7,4.285278e-10,0.0000037915245,0.0000013857417,0.0009219048,0.0007301587,3.6740144e-7,2.3349828e-7,2.4304862e-7,0.0000013655387,1.18870005e-7,0.0000056712925,6.8684284e-7,8.5426325e-7,9.943936e-7,0.000015265365,0.000031956304,0.0000015768659,9.418298e-8,0.108155206,8.5393545e-8,6.112133e-8,0.000030347459,0.0000012524315,0.7172883,0.00003415364,0.000021117477,0.0013374753,0.00015878139,0.0024257554,0.0006997508,0.0040869485,0.0018399452,0.0039962097,0.0007909812,0.12325025,0.034166172],[1.5510462e-16,3.6825024e-15,4.0736822e-17,7.7054405e-12,2.1915827e-11,1.6627604e-7,3.8702171e-7,9.224841e-9,1.2719492e-8,3.1218423e-8,0.0000033582487,2.6999269e-8,0.00016706261,0.000022372627,0.000004122377,0.000037417394,0.00006380434,0.000038291866,0.0000053472677,1.3028844e-13,0.0882222,1.01715754e-10,1.0039822e-12,0.000042999363,0.000002442337,0.17336737,0.0012795907,0.00014139396,0.0060285986,0.004500226,0.023198,0.3857152,0.10671344,0.030994665,0.0132855335,0.010854097,0.028934598,0.12637727],[6.990784e-16,1.3569805e-14,1.9031279e-16,1.9494276e-11,5.2007947e-11,2.798553e-7,6.1681624e-7,1.5905146e-8,2.1405203e-8,5.201075e-8,0.0000044691096,4.4334005e-8,0.0001840025,0.000026999673,0.0000051612647,0.000042546744,0.000080384736,0.000050261668,0.000006856005,4.3485308e-13,0.09320433,2.3416669e-10,2.9424657e-12,0.00005600104,0.0000034679524,0.1897025,0.0013847847,0.00017086041,0.0068385336,0.004631254,0.02495399,0.34785175,0.10681445,0.03258334,0.015291675,0.011614625,0.033081435,0.13141535],[2.17661e-18,1.00753e-17,7.7130994e-19,5.613464e-14,2.4107786e-13,4.081988e-9,1.2841269e-8,6.444025e-10,1.1739656e-9,4.205656e-9,8.5478104e-7,4.1862247e-9,0.00006499403,0.0000141857345,0.0000012194809,0.000021337148,0.00002630021,0.000010726495,0.0000017816321,3.0926475e-15,0.020405293,9.024959e-12,3.8174406e-14,0.000013835256,9.257595e-7,0.042672105,0.00084228005,0.00006165483,0.0031296648,0.0024051922,0.015674165,0.709084,0.095602356,0.022905165,0.008349068,0.0067182556,0.0070958114,0.06489887],[5.632693e-20,2.210833e-19,2.1245145e-20,3.810161e-15,2.4555538e-14,8.5841906e-10,3.6214485e-9,2.9118633e-10,6.4733996e-10,2.6816454e-9,7.1719876e-7,2.4235614e-9,0.00004936009,0.000017468483,7.494448e-7,0.0000113236365,0.000011327848,0.0000038091684,9.106241e-7,9.934958e-17,0.0048593213,1.2708001e-12,1.9469978e-15,0.000007131696,4.950297e-7,0.005131957,0.00066914165,0.000047533642,0.0012760473,0.002025404,0.007971396,0.88330704,0.05691125,0.010685395,0.002332987,0.0035348707,0.0011513559,0.019992897],[3.4385348e-18,1.3555489e-17,1.2378855e-18,8.559946e-14,5.2826434e-13,6.212863e-9,2.3647862e-8,2.7937843e-9,5.623914e-9,2.0963876e-8,0.0000031283219,1.683846e-8,0.00013416473,0.000046374225,0.0000027341764,0.00002668361,0.00003174492,0.000011797204,0.0000028938541,2.2578214e-15,0.009017974,1.5078279e-11,3.4821216e-14,0.000019768737,0.0000018116183,0.008608705,0.0012096921,0.00012231598,0.0020647103,0.0035999678,0.011008351,0.8494928,0.06495989,0.013655605,0.0032858453,0.005078569,0.0018144983,0.02579996],[1.9685204e-25,5.796938e-25,3.8401e-26,1.3010717e-19,2.2734668e-18,7.839969e-13,6.3160657e-12,7.518457e-13,2.2113195e-12,1.2428802e-11,2.3836938e-8,9.752167e-12,0.0000033400509,0.0000011232713,2.4470545e-8,3.779419e-7,1.2085556e-7,2.2725072e-8,2.3755694e-8,8.776591e-22,0.00035951985,4.2681567e-16,6.566703e-20,3.1037933e-7,1.222372e-8,0.0005243509,0.00012164621,0.0000046871405,0.00011680854,0.0004064828,0.0014372307,0.9716906,0.019034196,0.0011693253,0.00014552426,0.0003235637,0.00008079741,0.004579775],[1.5675593e-16,5.441035e-16,6.7648386e-17,1.5817836e-12,8.23515e-12,7.9326234e-8,2.8373321e-7,2.2187747e-8,4.3100556e-8,1.512042e-7,0.000011657733,1.00572834e-7,0.00021664347,0.00013112476,0.0000072740067,0.00004152123,0.0000685165,0.000028599541,0.000007493051,4.8652946e-14,0.009251568,1.6284547e-10,5.660596e-13,0.000053489402,0.000005853843,0.007166327,0.0018406407,0.00030218676,0.0027850394,0.0054893554,0.013886553,0.8382866,0.06967753,0.015096239,0.0035757546,0.006739272,0.0018597214,0.02347043],[6.153323e-25,7.3370267e-25,2.6728392e-25,2.956914e-19,7.430906e-18,6.356892e-13,5.849225e-12,7.2498266e-12,2.6664275e-11,1.4864113e-10,1.6869765e-7,1.652604e-10,0.000021673464,0.000014581713,1.878322e-7,0.0000033840683,6.1258595e-7,9.6406346e-8,1.4283471e-7,2.449309e-21,0.00004774689,2.3168176e-15,2.3221837e-19,5.811164e-7,5.6938088e-8,0.00001771435,0.0002902611,0.00001133729,0.00006743235,0.0007186196,0.0006939613,0.988489,0.0078208065,0.0008208866,0.00005215223,0.00031833132,0.0000057500856,0.0006044716],[1.4928163e-25,1.8551346e-25,4.0909522e-26,7.017721e-20,2.3453598e-18,2.5677862e-13,2.7054075e-12,2.980476e-12,1.0324211e-11,5.3990375e-11,1.1450684e-7,5.0076002e-11,0.000011929936,0.0000063997304,1.2235263e-7,0.0000012104771,1.1727373e-7,1.6532876e-8,8.0724675e-8,4.2769665e-22,0.00003870279,7.270947e-16,5.61447e-20,4.740007e-7,3.743035e-8,0.000029512461,0.00024864703,0.00001038747,0.000049308823,0.00062179996,0.00059983204,0.989361,0.007565832,0.0004301549,0.00002934273,0.00016553861,0.000007363852,0.00082205905],[8.512932e-20,3.4388418e-19,7.696541e-21,6.7074543e-16,4.0389906e-15,6.4267397e-10,3.0164313e-9,1.30354815e-11,2.0507653e-11,9.8094394e-11,4.4400597e-8,3.305324e-11,8.984445e-7,2.4267658e-7,1.9009205e-8,7.4417024e-8,1.675936e-7,5.9941e-8,2.485883e-8,2.0666697e-17,0.017277125,1.4236686e-13,3.2477967e-16,0.0000017366064,4.5400586e-8,0.21701448,0.000079388,0.000010425245,0.00091630593,0.0003760605,0.009514276,0.48641697,0.089901924,0.0038359414,0.002679334,0.00086525717,0.015724014,0.1553852],[1.1696711e-19,6.165736e-19,9.670902e-21,1.0929123e-15,6.0839505e-15,1.0982819e-9,4.9569135e-9,1.5973734e-11,2.4289582e-11,1.13557205e-10,4.6216318e-8,3.5488255e-11,8.578194e-7,2.2437987e-7,1.7733184e-8,6.235036e-8,1.7746017e-7,6.709944e-8,2.2890434e-8,2.5521596e-17,0.022734214,1.5554779e-13,3.6994876e-16,0.0000017423545,4.2374012e-8,0.2658316,0.000072629715,0.000010333476,0.0009219218,0.00036554056,0.009429735,0.43162882,0.08626305,0.0038083226,0.0026371027,0.0008552802,0.01734225,0.15809594],[5.0946168e-23,3.2924707e-23,3.4313543e-23,5.730691e-18,1.4673416e-16,5.3953855e-12,5.2935455e-11,1.15401126e-10,4.5113896e-10,2.6780655e-9,0.0000012121301,2.4013442e-9,0.000053109667,0.00007976447,7.578606e-7,0.000006795055,0.0000018620208,3.062758e-7,4.9145723e-7,7.559269e-20,0.000031138898,4.7948346e-14,5.519252e-18,0.0000017742061,2.9295137e-7,0.0000060445695,0.0005007078,0.00003655312,0.000071726055,0.00118827,0.000704153,0.9895828,0.006313362,0.00071319565,0.000040185892,0.00035500625,0.0000026032005,0.00030796687],[1.8141288e-17,6.379884e-19,2.6088304e-17,3.0468019e-15,6.768582e-14,9.32598e-11,9.66569e-10,1.1128459e-8,4.5949065e-8,3.46787e-7,0.000022089445,2.3730105e-7,0.00011964924,0.0007481951,0.0000053173553,0.000016594542,0.000011848958,0.0000020391817,0.0000033372473,1.1965085e-15,0.00002161832,7.339198e-11,3.39253e-14,0.000014492332,0.000008688416,0.0000047599415,0.0010189776,0.00023299361,0.0001816537,0.0018999645,0.0016100634,0.98259294,0.009294551,0.0010430744,0.00014705211,0.00058595376,0.0000042783067,0.00040915995],[1.9242068e-26,9.8853054e-26,2.8018288e-27,2.7361306e-20,3.7034768e-19,5.8123965e-13,4.2235443e-12,9.6723167e-14,2.4735525e-13,1.4547236e-12,4.1152677e-9,1.1100671e-12,8.3452323e-7,2.3932301e-7,5.2847735e-9,1.2553933e-7,4.5489372e-8,9.093866e-9,6.465611e-9,1.2326438e-22,0.00071307184,5.433178e-17,8.660079e-21,1.2101034e-7,2.7244078e-9,0.0017592437,0.00005408252,0.0000016177609,0.00011924628,0.00022472406,0.0016887079,0.9574749,0.02663663,0.0014627377,0.00021525439,0.00031407265,0.00019659188,0.0091377795],[4.155844e-22,2.056012e-23,4.689397e-22,9.862735e-19,2.676893e-17,4.6718586e-13,5.600451e-12,2.5140398e-11,1.15597525e-10,1.0430532e-9,3.825623e-7,9.858754e-10,0.000010800972,0.000035949823,2.0267956e-7,0.000002314842,8.448301e-7,1.1354513e-7,1.7353238e-7,2.8683038e-19,0.000009654268,9.3991275e-14,1.6404456e-17,9.3997704e-7,2.4735627e-7,0.0000044184444,0.00022447885,0.000017963626,0.000061160405,0.00044725963,0.00073330814,0.99021065,0.00697311,0.00061490986,0.000072511844,0.00022755943,0.0000024832736,0.0003486066],[1.5812745e-18,7.1198046e-20,2.076319e-18,5.767213e-16,1.3987771e-14,3.7988692e-11,4.1651668e-10,3.4909522e-9,1.4692972e-8,1.1595647e-7,0.000010314297,7.8064495e-8,0.00006894015,0.00039621655,0.0000025138622,0.000008872066,0.000006120047,0.0000010180448,0.0000016000824,1.6368136e-16,0.00001708551,1.6127759e-11,5.4861168e-15,0.000008029872,0.00000393129,0.000004127161,0.00070269353,0.00014091206,0.00013456031,0.0014398876,0.0013065691,0.9855784,0.008384006,0.0008520807,0.00010924537,0.00045278357,0.0000034225745,0.00036639566],[1.2698258e-18,1.374293e-18,9.269217e-19,1.4561708e-14,1.2797494e-13,3.5192964e-9,2.1400085e-8,3.602857e-9,1.01698925e-8,5.58568e-8,0.000005312381,3.181101e-8,0.000061984974,0.00011846823,0.0000016853521,0.000008034218,0.00001467106,0.0000044333638,0.0000015534249,5.6895595e-16,0.00070971076,1.2182897e-11,1.04862865e-14,0.000013898549,0.0000018665112,0.00026875228,0.00076253916,0.0001384321,0.00057584076,0.0024195295,0.0045092455,0.9537528,0.026973238,0.003912324,0.0005690267,0.0018115598,0.00009516939,0.0032697294],[2.6883473e-21,8.946423e-22,1.8002776e-21,2.8025663e-17,4.623527e-16,2.199049e-11,1.907964e-10,9.615132e-11,3.3914085e-10,2.5521314e-9,6.3486607e-7,1.6310508e-9,0.000014257031,0.000028304967,2.4448272e-7,0.0000020472785,0.0000020327964,4.0372404e-7,2.1332623e-7,1.7934465e-18,0.0001115055,2.3061682e-13,6.608584e-17,0.000001899377,2.8141613e-7,0.000047417274,0.00026462975,0.000028718152,0.00015100943,0.0007514511,0.0015552694,0.9801682,0.013557858,0.0014087345,0.00017244172,0.00054917176,0.000016141043,0.0011670667],[2.8893126e-23,9.631473e-23,5.1470807e-24,3.268201e-18,3.425883e-17,3.4659664e-11,2.663148e-10,2.533206e-12,6.4850503e-12,4.8226204e-11,2.6229278e-8,1.6508562e-11,6.916194e-7,6.16645e-7,7.4560775e-9,4.598906e-8,1.0302618e-7,2.6706585e-8,8.317174e-9,2.5943969e-20,0.0011254686,3.0913255e-15,8.2225537e-19,3.9340674e-7,1.1965129e-8,0.0018737725,0.000049354854,0.0000048158954,0.00019309814,0.00029719403,0.003059668,0.94099015,0.037330877,0.0015749763,0.00036190022,0.0004208474,0.00032554328,0.012390463],[3.469866e-18,7.48793e-18,1.8043225e-18,6.106974e-14,4.935526e-13,1.1897369e-8,6.2044414e-8,7.2041684e-9,1.7702803e-8,8.0726004e-8,0.000008054798,4.487178e-8,0.00010308578,0.00012805006,0.000003012184,0.000012701692,0.000019508021,0.0000064183673,0.0000025916574,1.2692642e-15,0.0016483378,2.0445689e-11,2.2758239e-14,0.00002199202,0.0000026580353,0.0007343686,0.0010864509,0.00019902203,0.0008613456,0.0035055685,0.0059029697,0.93663603,0.034599807,0.0052460055,0.00076639623,0.0025622253,0.00022054621,0.005722642],[2.436067e-17,4.5047604e-17,1.4805621e-17,1.831521e-13,1.0850559e-12,2.6026509e-8,1.2091691e-7,7.453805e-9,1.7507901e-8,8.67356e-8,0.0000059518666,4.5997588e-8,0.000066390174,0.00008807104,0.000001990206,0.000009687809,0.000028862225,0.000010990381,0.0000021317287,8.893452e-15,0.0032704405,5.3984858e-11,1.0563741e-13,0.000024253211,0.0000027923732,0.0019108357,0.0008603945,0.00017442374,0.0014198717,0.003039161,0.009475435,0.9009513,0.052207224,0.0088486355,0.0019514582,0.0038327833,0.00059453025,0.011222094],[5.1675917e-15,1.8813891e-14,1.4227573e-15,7.713019e-12,2.6856151e-11,8.184024e-7,0.0000029880669,1.7137124e-8,2.8525411e-8,1.2928203e-7,0.000005319185,3.503416e-8,0.00002273532,0.000020491929,0.0000010222814,0.0000019862568,0.00001869165,0.0000098447,0.0000011908298,4.0600333e-13,0.038395874,3.830092e-10,2.3521536e-12,0.000043274267,0.0000030240938,0.07617719,0.00053106906,0.00020325083,0.0035966104,0.0024789802,0.02364184,0.60742927,0.12075744,0.013468223,0.0070919907,0.005194592,0.012142649,0.08875948],[4.3646033e-17,2.0368814e-16,1.6855441e-17,5.7910344e-13,2.7949197e-12,9.29723e-8,3.7152333e-7,7.956882e-9,1.5418978e-8,6.416749e-8,0.000005312195,2.9734979e-8,0.00006145742,0.00004663855,0.0000019352703,0.000007199212,0.000022885772,0.000010053623,0.0000020958416,1.5517798e-14,0.012263261,5.8595157e-11,1.6299879e-13,0.0000324909,0.0000024924316,0.012592374,0.0009152331,0.00019536156,0.0022637078,0.0035649207,0.014380639,0.8219678,0.07868816,0.0115671,0.0031225968,0.0048115025,0.0025617972,0.030912444],[7.401682e-15,1.944746e-14,3.0892725e-15,9.496098e-12,3.1515613e-11,8.341205e-7,0.0000029595328,2.3073056e-8,4.07969e-8,1.887432e-7,0.0000071891664,6.1893275e-8,0.000034488912,0.00003773973,0.0000017191026,0.0000042104866,0.000033543947,0.00001732,0.000002158608,8.761052e-13,0.026712205,7.421945e-10,4.957381e-12,0.000057864803,0.000004817036,0.044810355,0.00071230705,0.00025192607,0.00397393,0.002992046,0.024627171,0.6673633,0.11909291,0.01597595,0.0078403,0.006390541,0.008997748,0.07005412],[3.6466563e-16,8.672846e-16,1.526201e-16,9.213423e-13,3.4874911e-12,1.3464488e-7,4.9676305e-7,4.666288e-9,8.65645e-9,3.882113e-8,0.000002814169,1.6859133e-8,0.000024404722,0.000022899978,0.0000010528356,0.0000039960846,0.000017190201,0.000007866705,0.0000014611306,9.363973e-14,0.014102156,1.3680664e-10,7.236197e-13,0.000032910626,0.0000024026829,0.03154153,0.0006329769,0.00014988934,0.0030599085,0.0023995794,0.019859934,0.7254455,0.10917779,0.014218101,0.0062181493,0.005243533,0.0066736336,0.061159607],[1.8578721e-15,5.246552e-15,6.6668084e-16,3.02315e-12,1.0066131e-11,3.8299336e-7,0.0000013784388,8.056073e-9,1.3950532e-8,6.427706e-8,0.0000034794791,2.1782123e-8,0.000019912817,0.000018859822,9.45443e-7,0.0000025045188,0.00001666489,0.0000083845725,0.0000012704844,2.8651216e-13,0.025951989,2.703695e-10,1.7761202e-12,0.000039580525,0.0000027055992,0.06425728,0.000550453,0.00016995188,0.003560195,0.0022972098,0.023295669,0.63343436,0.12244392,0.014404921,0.007559622,0.005306668,0.011405342,0.085246325],[2.3112506e-16,9.582024e-16,4.342695e-17,5.2634785e-13,2.0102912e-12,1.5701525e-7,6.11915e-7,1.7445064e-9,2.7839038e-9,1.3431052e-8,0.0000010589362,3.3659997e-9,0.000005639116,0.0000040906048,2.122952e-7,4.1774132e-7,0.0000035548503,0.0000017626456,2.6882964e-7,2.3649799e-14,0.034087956,3.5467004e-11,1.6839203e-13,0.000015882824,7.3090536e-7,0.1299103,0.00024077902,0.000077456214,0.0024011228,0.001261243,0.019103128,0.54328716,0.11738703,0.008952465,0.0054314574,0.0028901873,0.015903523,0.11903177],[4.0178823e-16,7.4318004e-16,8.9876046e-17,2.9524175e-13,1.2515739e-12,8.603162e-8,3.7568648e-7,1.4647985e-9,2.5411366e-9,1.4827559e-8,0.0000010480106,3.3302674e-9,0.000004333072,0.00000410687,1.765037e-7,3.255468e-7,0.0000031627842,0.0000014120169,2.1881937e-7,3.029755e-14,0.024796775,4.8477517e-11,2.1221909e-13,0.000014446549,8.314034e-7,0.09740892,0.00020973322,0.000074887306,0.0021290493,0.0010439762,0.018221574,0.60288644,0.11700201,0.007921264,0.005385013,0.002525075,0.0124226445,0.10794201],[1.0849353e-15,4.828941e-15,2.0597084e-16,1.812988e-12,6.1405633e-12,3.0208145e-7,0.0000010700866,3.2013656e-9,4.826617e-9,2.1205238e-8,0.0000014579111,5.649962e-9,0.000007620201,0.0000047583244,3.2904373e-7,6.3093336e-7,0.0000049696705,0.0000026079558,4.1950858e-7,9.635168e-14,0.04454126,8.8191045e-11,6.024778e-13,0.00002192849,0.0000010829679,0.19116963,0.00028545823,0.00009521596,0.0028913082,0.001389431,0.020415902,0.44265524,0.115869105,0.009914246,0.006567944,0.0032824862,0.022539156,0.13833638],[2.1225446e-17,7.743211e-17,5.2954577e-18,1.1086094e-13,4.997154e-13,4.750664e-8,2.1388335e-7,1.1865049e-9,2.2133706e-9,1.19937935e-8,0.0000011126255,3.3537408e-9,0.000007946788,0.0000065712393,2.3860937e-7,6.2283834e-7,0.0000040456366,0.0000017504221,2.794789e-7,4.152845e-15,0.019827282,1.3926855e-11,3.7093904e-14,0.000012220668,6.2091806e-7,0.04398782,0.00027491903,0.000071899216,0.0017980702,0.0013751931,0.015485507,0.7272996,0.101579145,0.00822713,0.0037389183,0.00274162,0.0063212086,0.06723609],[2.3157778e-16,7.4118453e-16,7.093802e-17,6.2173487e-13,2.2687355e-12,1.2944675e-7,5.0644314e-7,2.6804523e-9,4.712881e-9,2.2916119e-8,0.0000017173008,7.378556e-9,0.000011551618,0.000009575183,4.5980343e-7,0.0000012672318,0.000007584128,0.0000035922662,6.059129e-7,4.5039872e-14,0.024392296,6.636315e-11,3.2306961e-13,0.000022650123,0.0000012653021,0.06925127,0.0003853836,0.00010467319,0.0027299724,0.0017034501,0.020167341,0.64115554,0.11790693,0.011475585,0.006106308,0.003926327,0.011031375,0.08960259]],\"type\":\"heatmap\"}],                        {\"height\":1000,\"title\":{\"text\":\"Encoder self-attn, Layer 3, Head 2\",\"x\":0.5},\"width\":1000,\"xaxis\":{\"automargin\":true,\"showgrid\":false,\"tickangle\":-45,\"ticklen\":5,\"ticks\":\"outside\",\"title\":{\"font\":{\"color\":\"crimson\",\"family\":\"Courier\",\"size\":18},\"text\":\"Key\"}},\"yaxis\":{\"automargin\":true,\"autorange\":\"reversed\",\"showgrid\":false,\"ticklen\":5,\"ticks\":\"outside\",\"title\":{\"font\":{\"color\":\"crimson\",\"family\":\"Courier\",\"size\":18},\"text\":\"Query\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('53bfb659-76c7-46d8-ba5e-e48d94dcba1f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "vis_attn(\n",
        "    matrix,\n",
        "    xlabels,\n",
        "    ylabels,\n",
        "    title=title\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "883f5f9c",
      "metadata": {
        "id": "883f5f9c"
      },
      "outputs": [],
      "source": [
        "# # The above block should produce a similar but not the same (due to randomness) figure as below\n",
        "# Image(filename='images/encoder_self_attn.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a93c281",
      "metadata": {
        "id": "3a93c281",
        "outputId": "5dc5356e-ce8f-4824-82b5-87db2034c263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 38, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "attn_score.shape        # [batch_size, num_heads, seq_len, seq_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "300ba27b",
      "metadata": {
        "id": "300ba27b"
      },
      "outputs": [],
      "source": [
        "# num_layers = 6\n",
        "# num_heads = attn_score.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f8f0126",
      "metadata": {
        "id": "4f8f0126"
      },
      "outputs": [],
      "source": [
        "# for layer in [0, 5]:\n",
        "#     for head in [0, 3, 7]:\n",
        "\n",
        "#         # Encoder self-attention score\n",
        "#         attn_score = model.encoder.layers[layer].self_attn.attn_score    # [batch_size, num_heads, seq_len, seq_len]\n",
        "#         attn_score = attn_score.cpu().numpy()\n",
        "\n",
        "#         matrix = attn_score[0][head]\n",
        "\n",
        "#         title = f'Encoder self-attn, Layer {layer}, Head {head}'\n",
        "\n",
        "#         xlabels = [tokenizer.decode(x) for x in batch['src'][0]]\n",
        "#         ylabels = xlabels\n",
        "\n",
        "#         vis_attn(\n",
        "#             matrix,\n",
        "#             xlabels,\n",
        "#             ylabels,\n",
        "#             title=title\n",
        "#         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7975bc3b",
      "metadata": {
        "id": "7975bc3b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "22f62ea1",
      "metadata": {
        "id": "22f62ea1"
      },
      "source": [
        "## Decoder Visualization [greedy decoding]\n",
        "* Self-attention\n",
        "* Cross-attention"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbfd6377",
      "metadata": {
        "id": "dbfd6377"
      },
      "source": [
        "### Decoder self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28af7ca5",
      "metadata": {
        "id": "28af7ca5"
      },
      "outputs": [],
      "source": [
        "# layer and head to visualize\n",
        "layer = 1\n",
        "head = 0\n",
        "\n",
        "# Decoder self-attention score\n",
        "attn_score = model.decoder.layers[layer].self_attn.attn_score    # [batch_size, num_heads, seq_len, seq_len]\n",
        "attn_score = attn_score.cpu().numpy()\n",
        "\n",
        "matrix = attn_score[0][head]\n",
        "\n",
        "title = f'Decoder self-attn, Layer {layer}, Head {head}'\n",
        "\n",
        "# 然而，greedy_decode 并未用到 decoder input，即 batch['tgt']，\n",
        "# 而是直接以 bos_token_id （在这里为0）开始，一步一步（autoregressive）生成每一个目标文本token。\n",
        "# 因此，在此 decoder 的 self-attention 应该展示为 greedy decode 产生的文本（又作为decoder的输入）之间的 self-attention，\n",
        "# 并非 batch['tgt'] 的 self-attention\n",
        "\n",
        "# Under `greedy_decode`\n",
        "# 1. should not use batch['tgt'] to show the decoder self-attention\n",
        "# xlabels = [tokenizer.decode(x) for x in batch['tgt'][0]]\n",
        "# ylabels = xlabels\n",
        "\n",
        "# 2. should use model outputs to show the decoder self-attention\n",
        "xlabels = [tokenizer.decode(x) for x in output_ids[0][:-1]]    # -1: exclude last token which is not involved in the attention calculation\n",
        "ylabels = xlabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c892cce5",
      "metadata": {
        "id": "c892cce5",
        "outputId": "028e80b1-9432-4c06-c394-9477aa620301",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b209009f",
      "metadata": {
        "id": "b209009f",
        "outputId": "4f00d949-f00c-46f4-e91d-075878d861d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "output_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1be7022d",
      "metadata": {
        "id": "1be7022d",
        "outputId": "f1d3fa0c-7590-46e9-b566-d4ac529d2551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>美联储还不是在2008年金融危机中，欧洲银行和银行和银行都无法实现这一政策，而危机上就需要解决。</s></s></s></s></s>。</s></s></s></s>。</s></s></s></s>。</s></s></s></s></s>']"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "results = tokenizer.batch_decode(output_ids)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d6a01e6",
      "metadata": {
        "id": "3d6a01e6",
        "outputId": "2b814e2a-05d1-49ab-b506-350d7e494f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4be6ef13-69bb-4a31-904e-ff5a2621cf93\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4be6ef13-69bb-4a31-904e-ff5a2621cf93\")) {                    Plotly.newPlot(                        \"4be6ef13-69bb-4a31-904e-ff5a2621cf93\",                        [{\"colorbar\":{\"thickness\":15,\"ticklen\":3},\"colorscale\":[[0.0,\"rgb(255,247,251)\"],[0.125,\"rgb(236,231,242)\"],[0.25,\"rgb(208,209,230)\"],[0.375,\"rgb(166,189,219)\"],[0.5,\"rgb(116,169,207)\"],[0.625,\"rgb(54,144,192)\"],[0.75,\"rgb(5,112,176)\"],[0.875,\"rgb(4,90,141)\"],[1.0,\"rgb(2,56,88)\"]],\"hoverinfo\":\"text\",\"hovertext\":[[\"attn(&lt;s&gt;, &lt;s&gt;)= 1.00\",\"attn(&lt;s&gt;, 美联储)= 0.00\",\"attn(&lt;s&gt;, 还)= 0.00\",\"attn(&lt;s&gt;, 不是)= 0.00\",\"attn(&lt;s&gt;, 在)= 0.00\",\"attn(&lt;s&gt;, 2008)= 0.00\",\"attn(&lt;s&gt;, 年)= 0.00\",\"attn(&lt;s&gt;, 金融危机)= 0.00\",\"attn(&lt;s&gt;, 中)= 0.00\",\"attn(&lt;s&gt;, ，)= 0.00\",\"attn(&lt;s&gt;, 欧洲)= 0.00\",\"attn(&lt;s&gt;, 银行)= 0.00\",\"attn(&lt;s&gt;, 和)= 0.00\",\"attn(&lt;s&gt;, 银行)= 0.00\",\"attn(&lt;s&gt;, 和)= 0.00\",\"attn(&lt;s&gt;, 银行)= 0.00\",\"attn(&lt;s&gt;, 都)= 0.00\",\"attn(&lt;s&gt;, 无法)= 0.00\",\"attn(&lt;s&gt;, 实现)= 0.00\",\"attn(&lt;s&gt;, 这一)= 0.00\",\"attn(&lt;s&gt;, 政策)= 0.00\",\"attn(&lt;s&gt;, ，)= 0.00\",\"attn(&lt;s&gt;, 而)= 0.00\",\"attn(&lt;s&gt;, 危机)= 0.00\",\"attn(&lt;s&gt;, 上)= 0.00\",\"attn(&lt;s&gt;, 就)= 0.00\",\"attn(&lt;s&gt;, 需要)= 0.00\",\"attn(&lt;s&gt;, 解决)= 0.00\",\"attn(&lt;s&gt;, 。)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, 。)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, 。)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, 。)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(美联储, &lt;s&gt;)= 1.00\",\"attn(美联储, 美联储)= 0.00\",\"attn(美联储, 还)= 0.00\",\"attn(美联储, 不是)= 0.00\",\"attn(美联储, 在)= 0.00\",\"attn(美联储, 2008)= 0.00\",\"attn(美联储, 年)= 0.00\",\"attn(美联储, 金融危机)= 0.00\",\"attn(美联储, 中)= 0.00\",\"attn(美联储, ，)= 0.00\",\"attn(美联储, 欧洲)= 0.00\",\"attn(美联储, 银行)= 0.00\",\"attn(美联储, 和)= 0.00\",\"attn(美联储, 银行)= 0.00\",\"attn(美联储, 和)= 0.00\",\"attn(美联储, 银行)= 0.00\",\"attn(美联储, 都)= 0.00\",\"attn(美联储, 无法)= 0.00\",\"attn(美联储, 实现)= 0.00\",\"attn(美联储, 这一)= 0.00\",\"attn(美联储, 政策)= 0.00\",\"attn(美联储, ，)= 0.00\",\"attn(美联储, 而)= 0.00\",\"attn(美联储, 危机)= 0.00\",\"attn(美联储, 上)= 0.00\",\"attn(美联储, 就)= 0.00\",\"attn(美联储, 需要)= 0.00\",\"attn(美联储, 解决)= 0.00\",\"attn(美联储, 。)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, 。)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, 。)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, 。)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(还, &lt;s&gt;)= 0.00\",\"attn(还, 美联储)= 0.00\",\"attn(还, 还)= 1.00\",\"attn(还, 不是)= 0.00\",\"attn(还, 在)= 0.00\",\"attn(还, 2008)= 0.00\",\"attn(还, 年)= 0.00\",\"attn(还, 金融危机)= 0.00\",\"attn(还, 中)= 0.00\",\"attn(还, ，)= 0.00\",\"attn(还, 欧洲)= 0.00\",\"attn(还, 银行)= 0.00\",\"attn(还, 和)= 0.00\",\"attn(还, 银行)= 0.00\",\"attn(还, 和)= 0.00\",\"attn(还, 银行)= 0.00\",\"attn(还, 都)= 0.00\",\"attn(还, 无法)= 0.00\",\"attn(还, 实现)= 0.00\",\"attn(还, 这一)= 0.00\",\"attn(还, 政策)= 0.00\",\"attn(还, ，)= 0.00\",\"attn(还, 而)= 0.00\",\"attn(还, 危机)= 0.00\",\"attn(还, 上)= 0.00\",\"attn(还, 就)= 0.00\",\"attn(还, 需要)= 0.00\",\"attn(还, 解决)= 0.00\",\"attn(还, 。)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, 。)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, 。)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, 。)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(不是, &lt;s&gt;)= 0.00\",\"attn(不是, 美联储)= 0.56\",\"attn(不是, 还)= 0.42\",\"attn(不是, 不是)= 0.02\",\"attn(不是, 在)= 0.00\",\"attn(不是, 2008)= 0.00\",\"attn(不是, 年)= 0.00\",\"attn(不是, 金融危机)= 0.00\",\"attn(不是, 中)= 0.00\",\"attn(不是, ，)= 0.00\",\"attn(不是, 欧洲)= 0.00\",\"attn(不是, 银行)= 0.00\",\"attn(不是, 和)= 0.00\",\"attn(不是, 银行)= 0.00\",\"attn(不是, 和)= 0.00\",\"attn(不是, 银行)= 0.00\",\"attn(不是, 都)= 0.00\",\"attn(不是, 无法)= 0.00\",\"attn(不是, 实现)= 0.00\",\"attn(不是, 这一)= 0.00\",\"attn(不是, 政策)= 0.00\",\"attn(不是, ，)= 0.00\",\"attn(不是, 而)= 0.00\",\"attn(不是, 危机)= 0.00\",\"attn(不是, 上)= 0.00\",\"attn(不是, 就)= 0.00\",\"attn(不是, 需要)= 0.00\",\"attn(不是, 解决)= 0.00\",\"attn(不是, 。)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, 。)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, 。)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, 。)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(在, &lt;s&gt;)= 0.19\",\"attn(在, 美联储)= 0.81\",\"attn(在, 还)= 0.00\",\"attn(在, 不是)= 0.00\",\"attn(在, 在)= 0.00\",\"attn(在, 2008)= 0.00\",\"attn(在, 年)= 0.00\",\"attn(在, 金融危机)= 0.00\",\"attn(在, 中)= 0.00\",\"attn(在, ，)= 0.00\",\"attn(在, 欧洲)= 0.00\",\"attn(在, 银行)= 0.00\",\"attn(在, 和)= 0.00\",\"attn(在, 银行)= 0.00\",\"attn(在, 和)= 0.00\",\"attn(在, 银行)= 0.00\",\"attn(在, 都)= 0.00\",\"attn(在, 无法)= 0.00\",\"attn(在, 实现)= 0.00\",\"attn(在, 这一)= 0.00\",\"attn(在, 政策)= 0.00\",\"attn(在, ，)= 0.00\",\"attn(在, 而)= 0.00\",\"attn(在, 危机)= 0.00\",\"attn(在, 上)= 0.00\",\"attn(在, 就)= 0.00\",\"attn(在, 需要)= 0.00\",\"attn(在, 解决)= 0.00\",\"attn(在, 。)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, 。)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, 。)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, 。)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(2008, &lt;s&gt;)= 0.00\",\"attn(2008, 美联储)= 0.00\",\"attn(2008, 还)= 0.00\",\"attn(2008, 不是)= 0.00\",\"attn(2008, 在)= 0.00\",\"attn(2008, 2008)= 1.00\",\"attn(2008, 年)= 0.00\",\"attn(2008, 金融危机)= 0.00\",\"attn(2008, 中)= 0.00\",\"attn(2008, ，)= 0.00\",\"attn(2008, 欧洲)= 0.00\",\"attn(2008, 银行)= 0.00\",\"attn(2008, 和)= 0.00\",\"attn(2008, 银行)= 0.00\",\"attn(2008, 和)= 0.00\",\"attn(2008, 银行)= 0.00\",\"attn(2008, 都)= 0.00\",\"attn(2008, 无法)= 0.00\",\"attn(2008, 实现)= 0.00\",\"attn(2008, 这一)= 0.00\",\"attn(2008, 政策)= 0.00\",\"attn(2008, ，)= 0.00\",\"attn(2008, 而)= 0.00\",\"attn(2008, 危机)= 0.00\",\"attn(2008, 上)= 0.00\",\"attn(2008, 就)= 0.00\",\"attn(2008, 需要)= 0.00\",\"attn(2008, 解决)= 0.00\",\"attn(2008, 。)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, 。)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, 。)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, 。)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(年, &lt;s&gt;)= 0.00\",\"attn(年, 美联储)= 0.00\",\"attn(年, 还)= 0.00\",\"attn(年, 不是)= 0.00\",\"attn(年, 在)= 0.00\",\"attn(年, 2008)= 1.00\",\"attn(年, 年)= 0.00\",\"attn(年, 金融危机)= 0.00\",\"attn(年, 中)= 0.00\",\"attn(年, ，)= 0.00\",\"attn(年, 欧洲)= 0.00\",\"attn(年, 银行)= 0.00\",\"attn(年, 和)= 0.00\",\"attn(年, 银行)= 0.00\",\"attn(年, 和)= 0.00\",\"attn(年, 银行)= 0.00\",\"attn(年, 都)= 0.00\",\"attn(年, 无法)= 0.00\",\"attn(年, 实现)= 0.00\",\"attn(年, 这一)= 0.00\",\"attn(年, 政策)= 0.00\",\"attn(年, ，)= 0.00\",\"attn(年, 而)= 0.00\",\"attn(年, 危机)= 0.00\",\"attn(年, 上)= 0.00\",\"attn(年, 就)= 0.00\",\"attn(年, 需要)= 0.00\",\"attn(年, 解决)= 0.00\",\"attn(年, 。)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, 。)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, 。)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, 。)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(金融危机, &lt;s&gt;)= 0.00\",\"attn(金融危机, 美联储)= 0.00\",\"attn(金融危机, 还)= 0.00\",\"attn(金融危机, 不是)= 0.00\",\"attn(金融危机, 在)= 1.00\",\"attn(金融危机, 2008)= 0.00\",\"attn(金融危机, 年)= 0.00\",\"attn(金融危机, 金融危机)= 0.00\",\"attn(金融危机, 中)= 0.00\",\"attn(金融危机, ，)= 0.00\",\"attn(金融危机, 欧洲)= 0.00\",\"attn(金融危机, 银行)= 0.00\",\"attn(金融危机, 和)= 0.00\",\"attn(金融危机, 银行)= 0.00\",\"attn(金融危机, 和)= 0.00\",\"attn(金融危机, 银行)= 0.00\",\"attn(金融危机, 都)= 0.00\",\"attn(金融危机, 无法)= 0.00\",\"attn(金融危机, 实现)= 0.00\",\"attn(金融危机, 这一)= 0.00\",\"attn(金融危机, 政策)= 0.00\",\"attn(金融危机, ，)= 0.00\",\"attn(金融危机, 而)= 0.00\",\"attn(金融危机, 危机)= 0.00\",\"attn(金融危机, 上)= 0.00\",\"attn(金融危机, 就)= 0.00\",\"attn(金融危机, 需要)= 0.00\",\"attn(金融危机, 解决)= 0.00\",\"attn(金融危机, 。)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, 。)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, 。)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, 。)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(中, &lt;s&gt;)= 0.00\",\"attn(中, 美联储)= 0.00\",\"attn(中, 还)= 0.00\",\"attn(中, 不是)= 0.00\",\"attn(中, 在)= 1.00\",\"attn(中, 2008)= 0.00\",\"attn(中, 年)= 0.00\",\"attn(中, 金融危机)= 0.00\",\"attn(中, 中)= 0.00\",\"attn(中, ，)= 0.00\",\"attn(中, 欧洲)= 0.00\",\"attn(中, 银行)= 0.00\",\"attn(中, 和)= 0.00\",\"attn(中, 银行)= 0.00\",\"attn(中, 和)= 0.00\",\"attn(中, 银行)= 0.00\",\"attn(中, 都)= 0.00\",\"attn(中, 无法)= 0.00\",\"attn(中, 实现)= 0.00\",\"attn(中, 这一)= 0.00\",\"attn(中, 政策)= 0.00\",\"attn(中, ，)= 0.00\",\"attn(中, 而)= 0.00\",\"attn(中, 危机)= 0.00\",\"attn(中, 上)= 0.00\",\"attn(中, 就)= 0.00\",\"attn(中, 需要)= 0.00\",\"attn(中, 解决)= 0.00\",\"attn(中, 。)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, 。)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, 。)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, 。)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(，, &lt;s&gt;)= 0.00\",\"attn(，, 美联储)= 0.00\",\"attn(，, 还)= 0.00\",\"attn(，, 不是)= 0.00\",\"attn(，, 在)= 0.00\",\"attn(，, 2008)= 0.00\",\"attn(，, 年)= 0.00\",\"attn(，, 金融危机)= 0.00\",\"attn(，, 中)= 1.00\",\"attn(，, ，)= 0.00\",\"attn(，, 欧洲)= 0.00\",\"attn(，, 银行)= 0.00\",\"attn(，, 和)= 0.00\",\"attn(，, 银行)= 0.00\",\"attn(，, 和)= 0.00\",\"attn(，, 银行)= 0.00\",\"attn(，, 都)= 0.00\",\"attn(，, 无法)= 0.00\",\"attn(，, 实现)= 0.00\",\"attn(，, 这一)= 0.00\",\"attn(，, 政策)= 0.00\",\"attn(，, ，)= 0.00\",\"attn(，, 而)= 0.00\",\"attn(，, 危机)= 0.00\",\"attn(，, 上)= 0.00\",\"attn(，, 就)= 0.00\",\"attn(，, 需要)= 0.00\",\"attn(，, 解决)= 0.00\",\"attn(，, 。)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, 。)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, 。)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, 。)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(欧洲, &lt;s&gt;)= 0.00\",\"attn(欧洲, 美联储)= 0.00\",\"attn(欧洲, 还)= 0.00\",\"attn(欧洲, 不是)= 0.00\",\"attn(欧洲, 在)= 1.00\",\"attn(欧洲, 2008)= 0.00\",\"attn(欧洲, 年)= 0.00\",\"attn(欧洲, 金融危机)= 0.00\",\"attn(欧洲, 中)= 0.00\",\"attn(欧洲, ，)= 0.00\",\"attn(欧洲, 欧洲)= 0.00\",\"attn(欧洲, 银行)= 0.00\",\"attn(欧洲, 和)= 0.00\",\"attn(欧洲, 银行)= 0.00\",\"attn(欧洲, 和)= 0.00\",\"attn(欧洲, 银行)= 0.00\",\"attn(欧洲, 都)= 0.00\",\"attn(欧洲, 无法)= 0.00\",\"attn(欧洲, 实现)= 0.00\",\"attn(欧洲, 这一)= 0.00\",\"attn(欧洲, 政策)= 0.00\",\"attn(欧洲, ，)= 0.00\",\"attn(欧洲, 而)= 0.00\",\"attn(欧洲, 危机)= 0.00\",\"attn(欧洲, 上)= 0.00\",\"attn(欧洲, 就)= 0.00\",\"attn(欧洲, 需要)= 0.00\",\"attn(欧洲, 解决)= 0.00\",\"attn(欧洲, 。)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, 。)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, 。)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, 。)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(银行, &lt;s&gt;)= 0.00\",\"attn(银行, 美联储)= 0.00\",\"attn(银行, 还)= 0.00\",\"attn(银行, 不是)= 0.00\",\"attn(银行, 在)= 1.00\",\"attn(银行, 2008)= 0.00\",\"attn(银行, 年)= 0.00\",\"attn(银行, 金融危机)= 0.00\",\"attn(银行, 中)= 0.00\",\"attn(银行, ，)= 0.00\",\"attn(银行, 欧洲)= 0.00\",\"attn(银行, 银行)= 0.00\",\"attn(银行, 和)= 0.00\",\"attn(银行, 银行)= 0.00\",\"attn(银行, 和)= 0.00\",\"attn(银行, 银行)= 0.00\",\"attn(银行, 都)= 0.00\",\"attn(银行, 无法)= 0.00\",\"attn(银行, 实现)= 0.00\",\"attn(银行, 这一)= 0.00\",\"attn(银行, 政策)= 0.00\",\"attn(银行, ，)= 0.00\",\"attn(银行, 而)= 0.00\",\"attn(银行, 危机)= 0.00\",\"attn(银行, 上)= 0.00\",\"attn(银行, 就)= 0.00\",\"attn(银行, 需要)= 0.00\",\"attn(银行, 解决)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(和, &lt;s&gt;)= 0.00\",\"attn(和, 美联储)= 0.00\",\"attn(和, 还)= 0.00\",\"attn(和, 不是)= 0.00\",\"attn(和, 在)= 0.00\",\"attn(和, 2008)= 0.00\",\"attn(和, 年)= 0.00\",\"attn(和, 金融危机)= 0.00\",\"attn(和, 中)= 0.99\",\"attn(和, ，)= 0.00\",\"attn(和, 欧洲)= 0.00\",\"attn(和, 银行)= 0.00\",\"attn(和, 和)= 0.00\",\"attn(和, 银行)= 0.00\",\"attn(和, 和)= 0.00\",\"attn(和, 银行)= 0.00\",\"attn(和, 都)= 0.00\",\"attn(和, 无法)= 0.00\",\"attn(和, 实现)= 0.00\",\"attn(和, 这一)= 0.00\",\"attn(和, 政策)= 0.00\",\"attn(和, ，)= 0.00\",\"attn(和, 而)= 0.00\",\"attn(和, 危机)= 0.00\",\"attn(和, 上)= 0.00\",\"attn(和, 就)= 0.00\",\"attn(和, 需要)= 0.00\",\"attn(和, 解决)= 0.00\",\"attn(和, 。)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, 。)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, 。)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, 。)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(银行, &lt;s&gt;)= 0.00\",\"attn(银行, 美联储)= 0.00\",\"attn(银行, 还)= 0.00\",\"attn(银行, 不是)= 0.00\",\"attn(银行, 在)= 1.00\",\"attn(银行, 2008)= 0.00\",\"attn(银行, 年)= 0.00\",\"attn(银行, 金融危机)= 0.00\",\"attn(银行, 中)= 0.00\",\"attn(银行, ，)= 0.00\",\"attn(银行, 欧洲)= 0.00\",\"attn(银行, 银行)= 0.00\",\"attn(银行, 和)= 0.00\",\"attn(银行, 银行)= 0.00\",\"attn(银行, 和)= 0.00\",\"attn(银行, 银行)= 0.00\",\"attn(银行, 都)= 0.00\",\"attn(银行, 无法)= 0.00\",\"attn(银行, 实现)= 0.00\",\"attn(银行, 这一)= 0.00\",\"attn(银行, 政策)= 0.00\",\"attn(银行, ，)= 0.00\",\"attn(银行, 而)= 0.00\",\"attn(银行, 危机)= 0.00\",\"attn(银行, 上)= 0.00\",\"attn(银行, 就)= 0.00\",\"attn(银行, 需要)= 0.00\",\"attn(银行, 解决)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(和, &lt;s&gt;)= 0.00\",\"attn(和, 美联储)= 0.00\",\"attn(和, 还)= 0.00\",\"attn(和, 不是)= 0.00\",\"attn(和, 在)= 0.00\",\"attn(和, 2008)= 0.01\",\"attn(和, 年)= 0.00\",\"attn(和, 金融危机)= 0.00\",\"attn(和, 中)= 0.99\",\"attn(和, ，)= 0.00\",\"attn(和, 欧洲)= 0.00\",\"attn(和, 银行)= 0.00\",\"attn(和, 和)= 0.00\",\"attn(和, 银行)= 0.00\",\"attn(和, 和)= 0.00\",\"attn(和, 银行)= 0.00\",\"attn(和, 都)= 0.00\",\"attn(和, 无法)= 0.00\",\"attn(和, 实现)= 0.00\",\"attn(和, 这一)= 0.00\",\"attn(和, 政策)= 0.00\",\"attn(和, ，)= 0.00\",\"attn(和, 而)= 0.00\",\"attn(和, 危机)= 0.00\",\"attn(和, 上)= 0.00\",\"attn(和, 就)= 0.00\",\"attn(和, 需要)= 0.00\",\"attn(和, 解决)= 0.00\",\"attn(和, 。)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, 。)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, 。)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, 。)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(银行, &lt;s&gt;)= 0.00\",\"attn(银行, 美联储)= 0.00\",\"attn(银行, 还)= 0.00\",\"attn(银行, 不是)= 0.00\",\"attn(银行, 在)= 1.00\",\"attn(银行, 2008)= 0.00\",\"attn(银行, 年)= 0.00\",\"attn(银行, 金融危机)= 0.00\",\"attn(银行, 中)= 0.00\",\"attn(银行, ，)= 0.00\",\"attn(银行, 欧洲)= 0.00\",\"attn(银行, 银行)= 0.00\",\"attn(银行, 和)= 0.00\",\"attn(银行, 银行)= 0.00\",\"attn(银行, 和)= 0.00\",\"attn(银行, 银行)= 0.00\",\"attn(银行, 都)= 0.00\",\"attn(银行, 无法)= 0.00\",\"attn(银行, 实现)= 0.00\",\"attn(银行, 这一)= 0.00\",\"attn(银行, 政策)= 0.00\",\"attn(银行, ，)= 0.00\",\"attn(银行, 而)= 0.00\",\"attn(银行, 危机)= 0.00\",\"attn(银行, 上)= 0.00\",\"attn(银行, 就)= 0.00\",\"attn(银行, 需要)= 0.00\",\"attn(银行, 解决)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, 。)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(都, &lt;s&gt;)= 0.00\",\"attn(都, 美联储)= 0.00\",\"attn(都, 还)= 0.00\",\"attn(都, 不是)= 0.00\",\"attn(都, 在)= 0.82\",\"attn(都, 2008)= 0.00\",\"attn(都, 年)= 0.00\",\"attn(都, 金融危机)= 0.00\",\"attn(都, 中)= 0.00\",\"attn(都, ，)= 0.00\",\"attn(都, 欧洲)= 0.00\",\"attn(都, 银行)= 0.00\",\"attn(都, 和)= 0.00\",\"attn(都, 银行)= 0.00\",\"attn(都, 和)= 0.00\",\"attn(都, 银行)= 0.00\",\"attn(都, 都)= 0.17\",\"attn(都, 无法)= 0.00\",\"attn(都, 实现)= 0.00\",\"attn(都, 这一)= 0.00\",\"attn(都, 政策)= 0.00\",\"attn(都, ，)= 0.00\",\"attn(都, 而)= 0.00\",\"attn(都, 危机)= 0.00\",\"attn(都, 上)= 0.00\",\"attn(都, 就)= 0.00\",\"attn(都, 需要)= 0.00\",\"attn(都, 解决)= 0.00\",\"attn(都, 。)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, 。)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, 。)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, 。)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\",\"attn(都, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(无法, &lt;s&gt;)= 0.00\",\"attn(无法, 美联储)= 0.00\",\"attn(无法, 还)= 0.00\",\"attn(无法, 不是)= 0.00\",\"attn(无法, 在)= 0.00\",\"attn(无法, 2008)= 0.00\",\"attn(无法, 年)= 0.00\",\"attn(无法, 金融危机)= 0.00\",\"attn(无法, 中)= 0.00\",\"attn(无法, ，)= 0.00\",\"attn(无法, 欧洲)= 0.00\",\"attn(无法, 银行)= 0.00\",\"attn(无法, 和)= 0.00\",\"attn(无法, 银行)= 0.00\",\"attn(无法, 和)= 0.00\",\"attn(无法, 银行)= 0.00\",\"attn(无法, 都)= 0.36\",\"attn(无法, 无法)= 0.64\",\"attn(无法, 实现)= 0.00\",\"attn(无法, 这一)= 0.00\",\"attn(无法, 政策)= 0.00\",\"attn(无法, ，)= 0.00\",\"attn(无法, 而)= 0.00\",\"attn(无法, 危机)= 0.00\",\"attn(无法, 上)= 0.00\",\"attn(无法, 就)= 0.00\",\"attn(无法, 需要)= 0.00\",\"attn(无法, 解决)= 0.00\",\"attn(无法, 。)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, 。)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, 。)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, 。)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(实现, &lt;s&gt;)= 0.00\",\"attn(实现, 美联储)= 0.00\",\"attn(实现, 还)= 0.00\",\"attn(实现, 不是)= 0.00\",\"attn(实现, 在)= 0.00\",\"attn(实现, 2008)= 0.00\",\"attn(实现, 年)= 0.00\",\"attn(实现, 金融危机)= 0.00\",\"attn(实现, 中)= 0.00\",\"attn(实现, ，)= 0.00\",\"attn(实现, 欧洲)= 0.00\",\"attn(实现, 银行)= 0.00\",\"attn(实现, 和)= 0.00\",\"attn(实现, 银行)= 0.00\",\"attn(实现, 和)= 0.00\",\"attn(实现, 银行)= 0.00\",\"attn(实现, 都)= 0.66\",\"attn(实现, 无法)= 0.34\",\"attn(实现, 实现)= 0.00\",\"attn(实现, 这一)= 0.00\",\"attn(实现, 政策)= 0.00\",\"attn(实现, ，)= 0.00\",\"attn(实现, 而)= 0.00\",\"attn(实现, 危机)= 0.00\",\"attn(实现, 上)= 0.00\",\"attn(实现, 就)= 0.00\",\"attn(实现, 需要)= 0.00\",\"attn(实现, 解决)= 0.00\",\"attn(实现, 。)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, 。)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, 。)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, 。)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(这一, &lt;s&gt;)= 0.00\",\"attn(这一, 美联储)= 0.00\",\"attn(这一, 还)= 0.00\",\"attn(这一, 不是)= 0.00\",\"attn(这一, 在)= 1.00\",\"attn(这一, 2008)= 0.00\",\"attn(这一, 年)= 0.00\",\"attn(这一, 金融危机)= 0.00\",\"attn(这一, 中)= 0.00\",\"attn(这一, ，)= 0.00\",\"attn(这一, 欧洲)= 0.00\",\"attn(这一, 银行)= 0.00\",\"attn(这一, 和)= 0.00\",\"attn(这一, 银行)= 0.00\",\"attn(这一, 和)= 0.00\",\"attn(这一, 银行)= 0.00\",\"attn(这一, 都)= 0.00\",\"attn(这一, 无法)= 0.00\",\"attn(这一, 实现)= 0.00\",\"attn(这一, 这一)= 0.00\",\"attn(这一, 政策)= 0.00\",\"attn(这一, ，)= 0.00\",\"attn(这一, 而)= 0.00\",\"attn(这一, 危机)= 0.00\",\"attn(这一, 上)= 0.00\",\"attn(这一, 就)= 0.00\",\"attn(这一, 需要)= 0.00\",\"attn(这一, 解决)= 0.00\",\"attn(这一, 。)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, 。)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, 。)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, 。)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(政策, &lt;s&gt;)= 0.00\",\"attn(政策, 美联储)= 0.00\",\"attn(政策, 还)= 0.00\",\"attn(政策, 不是)= 0.00\",\"attn(政策, 在)= 0.99\",\"attn(政策, 2008)= 0.00\",\"attn(政策, 年)= 0.00\",\"attn(政策, 金融危机)= 0.00\",\"attn(政策, 中)= 0.00\",\"attn(政策, ，)= 0.00\",\"attn(政策, 欧洲)= 0.00\",\"attn(政策, 银行)= 0.00\",\"attn(政策, 和)= 0.00\",\"attn(政策, 银行)= 0.00\",\"attn(政策, 和)= 0.00\",\"attn(政策, 银行)= 0.00\",\"attn(政策, 都)= 0.01\",\"attn(政策, 无法)= 0.00\",\"attn(政策, 实现)= 0.00\",\"attn(政策, 这一)= 0.00\",\"attn(政策, 政策)= 0.00\",\"attn(政策, ，)= 0.00\",\"attn(政策, 而)= 0.00\",\"attn(政策, 危机)= 0.00\",\"attn(政策, 上)= 0.00\",\"attn(政策, 就)= 0.00\",\"attn(政策, 需要)= 0.00\",\"attn(政策, 解决)= 0.00\",\"attn(政策, 。)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, 。)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, 。)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, 。)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\",\"attn(政策, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(，, &lt;s&gt;)= 0.00\",\"attn(，, 美联储)= 0.00\",\"attn(，, 还)= 0.00\",\"attn(，, 不是)= 0.00\",\"attn(，, 在)= 0.00\",\"attn(，, 2008)= 0.00\",\"attn(，, 年)= 0.00\",\"attn(，, 金融危机)= 0.00\",\"attn(，, 中)= 0.55\",\"attn(，, ，)= 0.00\",\"attn(，, 欧洲)= 0.00\",\"attn(，, 银行)= 0.00\",\"attn(，, 和)= 0.00\",\"attn(，, 银行)= 0.00\",\"attn(，, 和)= 0.00\",\"attn(，, 银行)= 0.00\",\"attn(，, 都)= 0.24\",\"attn(，, 无法)= 0.20\",\"attn(，, 实现)= 0.00\",\"attn(，, 这一)= 0.00\",\"attn(，, 政策)= 0.00\",\"attn(，, ，)= 0.00\",\"attn(，, 而)= 0.00\",\"attn(，, 危机)= 0.00\",\"attn(，, 上)= 0.00\",\"attn(，, 就)= 0.00\",\"attn(，, 需要)= 0.00\",\"attn(，, 解决)= 0.00\",\"attn(，, 。)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, 。)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, 。)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, 。)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(而, &lt;s&gt;)= 0.00\",\"attn(而, 美联储)= 0.00\",\"attn(而, 还)= 0.00\",\"attn(而, 不是)= 0.00\",\"attn(而, 在)= 0.00\",\"attn(而, 2008)= 1.00\",\"attn(而, 年)= 0.00\",\"attn(而, 金融危机)= 0.00\",\"attn(而, 中)= 0.00\",\"attn(而, ，)= 0.00\",\"attn(而, 欧洲)= 0.00\",\"attn(而, 银行)= 0.00\",\"attn(而, 和)= 0.00\",\"attn(而, 银行)= 0.00\",\"attn(而, 和)= 0.00\",\"attn(而, 银行)= 0.00\",\"attn(而, 都)= 0.00\",\"attn(而, 无法)= 0.00\",\"attn(而, 实现)= 0.00\",\"attn(而, 这一)= 0.00\",\"attn(而, 政策)= 0.00\",\"attn(而, ，)= 0.00\",\"attn(而, 而)= 0.00\",\"attn(而, 危机)= 0.00\",\"attn(而, 上)= 0.00\",\"attn(而, 就)= 0.00\",\"attn(而, 需要)= 0.00\",\"attn(而, 解决)= 0.00\",\"attn(而, 。)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, 。)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, 。)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, 。)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(危机, &lt;s&gt;)= 0.00\",\"attn(危机, 美联储)= 0.00\",\"attn(危机, 还)= 0.00\",\"attn(危机, 不是)= 0.00\",\"attn(危机, 在)= 0.00\",\"attn(危机, 2008)= 0.00\",\"attn(危机, 年)= 0.00\",\"attn(危机, 金融危机)= 0.00\",\"attn(危机, 中)= 0.00\",\"attn(危机, ，)= 0.00\",\"attn(危机, 欧洲)= 0.00\",\"attn(危机, 银行)= 0.00\",\"attn(危机, 和)= 0.00\",\"attn(危机, 银行)= 0.00\",\"attn(危机, 和)= 0.00\",\"attn(危机, 银行)= 0.00\",\"attn(危机, 都)= 0.00\",\"attn(危机, 无法)= 0.00\",\"attn(危机, 实现)= 0.00\",\"attn(危机, 这一)= 0.00\",\"attn(危机, 政策)= 0.00\",\"attn(危机, ，)= 0.00\",\"attn(危机, 而)= 1.00\",\"attn(危机, 危机)= 0.00\",\"attn(危机, 上)= 0.00\",\"attn(危机, 就)= 0.00\",\"attn(危机, 需要)= 0.00\",\"attn(危机, 解决)= 0.00\",\"attn(危机, 。)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, 。)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, 。)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, 。)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\",\"attn(危机, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(上, &lt;s&gt;)= 0.00\",\"attn(上, 美联储)= 0.00\",\"attn(上, 还)= 0.00\",\"attn(上, 不是)= 0.00\",\"attn(上, 在)= 0.00\",\"attn(上, 2008)= 0.20\",\"attn(上, 年)= 0.00\",\"attn(上, 金融危机)= 0.00\",\"attn(上, 中)= 0.00\",\"attn(上, ，)= 0.00\",\"attn(上, 欧洲)= 0.00\",\"attn(上, 银行)= 0.00\",\"attn(上, 和)= 0.00\",\"attn(上, 银行)= 0.00\",\"attn(上, 和)= 0.00\",\"attn(上, 银行)= 0.00\",\"attn(上, 都)= 0.00\",\"attn(上, 无法)= 0.00\",\"attn(上, 实现)= 0.00\",\"attn(上, 这一)= 0.00\",\"attn(上, 政策)= 0.00\",\"attn(上, ，)= 0.00\",\"attn(上, 而)= 0.00\",\"attn(上, 危机)= 0.00\",\"attn(上, 上)= 0.80\",\"attn(上, 就)= 0.00\",\"attn(上, 需要)= 0.00\",\"attn(上, 解决)= 0.00\",\"attn(上, 。)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, 。)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, 。)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, 。)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\",\"attn(上, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(就, &lt;s&gt;)= 0.00\",\"attn(就, 美联储)= 0.00\",\"attn(就, 还)= 0.00\",\"attn(就, 不是)= 0.00\",\"attn(就, 在)= 0.00\",\"attn(就, 2008)= 0.04\",\"attn(就, 年)= 0.00\",\"attn(就, 金融危机)= 0.00\",\"attn(就, 中)= 0.00\",\"attn(就, ，)= 0.00\",\"attn(就, 欧洲)= 0.00\",\"attn(就, 银行)= 0.00\",\"attn(就, 和)= 0.00\",\"attn(就, 银行)= 0.00\",\"attn(就, 和)= 0.00\",\"attn(就, 银行)= 0.00\",\"attn(就, 都)= 0.00\",\"attn(就, 无法)= 0.00\",\"attn(就, 实现)= 0.00\",\"attn(就, 这一)= 0.00\",\"attn(就, 政策)= 0.00\",\"attn(就, ，)= 0.00\",\"attn(就, 而)= 0.00\",\"attn(就, 危机)= 0.00\",\"attn(就, 上)= 0.96\",\"attn(就, 就)= 0.00\",\"attn(就, 需要)= 0.00\",\"attn(就, 解决)= 0.00\",\"attn(就, 。)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, 。)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, 。)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, 。)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\",\"attn(就, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(需要, &lt;s&gt;)= 0.00\",\"attn(需要, 美联储)= 0.00\",\"attn(需要, 还)= 0.00\",\"attn(需要, 不是)= 0.00\",\"attn(需要, 在)= 0.00\",\"attn(需要, 2008)= 0.00\",\"attn(需要, 年)= 0.00\",\"attn(需要, 金融危机)= 0.00\",\"attn(需要, 中)= 0.00\",\"attn(需要, ，)= 0.00\",\"attn(需要, 欧洲)= 0.00\",\"attn(需要, 银行)= 0.00\",\"attn(需要, 和)= 0.00\",\"attn(需要, 银行)= 0.00\",\"attn(需要, 和)= 0.00\",\"attn(需要, 银行)= 0.00\",\"attn(需要, 都)= 0.25\",\"attn(需要, 无法)= 0.06\",\"attn(需要, 实现)= 0.00\",\"attn(需要, 这一)= 0.00\",\"attn(需要, 政策)= 0.17\",\"attn(需要, ，)= 0.00\",\"attn(需要, 而)= 0.00\",\"attn(需要, 危机)= 0.00\",\"attn(需要, 上)= 0.03\",\"attn(需要, 就)= 0.49\",\"attn(需要, 需要)= 0.01\",\"attn(需要, 解决)= 0.00\",\"attn(需要, 。)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, 。)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, 。)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, 。)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\",\"attn(需要, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(解决, &lt;s&gt;)= 0.00\",\"attn(解决, 美联储)= 0.00\",\"attn(解决, 还)= 0.00\",\"attn(解决, 不是)= 0.00\",\"attn(解决, 在)= 0.00\",\"attn(解决, 2008)= 0.00\",\"attn(解决, 年)= 0.00\",\"attn(解决, 金融危机)= 0.00\",\"attn(解决, 中)= 0.00\",\"attn(解决, ，)= 0.00\",\"attn(解决, 欧洲)= 0.00\",\"attn(解决, 银行)= 0.00\",\"attn(解决, 和)= 0.00\",\"attn(解决, 银行)= 0.00\",\"attn(解决, 和)= 0.00\",\"attn(解决, 银行)= 0.00\",\"attn(解决, 都)= 0.00\",\"attn(解决, 无法)= 0.00\",\"attn(解决, 实现)= 0.00\",\"attn(解决, 这一)= 0.00\",\"attn(解决, 政策)= 1.00\",\"attn(解决, ，)= 0.00\",\"attn(解决, 而)= 0.00\",\"attn(解决, 危机)= 0.00\",\"attn(解决, 上)= 0.00\",\"attn(解决, 就)= 0.00\",\"attn(解决, 需要)= 0.00\",\"attn(解决, 解决)= 0.00\",\"attn(解决, 。)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, 。)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, 。)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, 。)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\",\"attn(解决, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(。, &lt;s&gt;)= 0.00\",\"attn(。, 美联储)= 0.00\",\"attn(。, 还)= 0.00\",\"attn(。, 不是)= 0.00\",\"attn(。, 在)= 0.00\",\"attn(。, 2008)= 0.00\",\"attn(。, 年)= 0.00\",\"attn(。, 金融危机)= 0.00\",\"attn(。, 中)= 0.00\",\"attn(。, ，)= 0.00\",\"attn(。, 欧洲)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 和)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 和)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 都)= 0.00\",\"attn(。, 无法)= 0.00\",\"attn(。, 实现)= 0.00\",\"attn(。, 这一)= 0.00\",\"attn(。, 政策)= 0.00\",\"attn(。, ，)= 0.00\",\"attn(。, 而)= 0.77\",\"attn(。, 危机)= 0.00\",\"attn(。, 上)= 0.04\",\"attn(。, 就)= 0.20\",\"attn(。, 需要)= 0.00\",\"attn(。, 解决)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.90\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.10\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.93\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.07\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.94\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.06\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.93\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.07\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.90\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.10\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(。, &lt;s&gt;)= 0.00\",\"attn(。, 美联储)= 0.00\",\"attn(。, 还)= 0.00\",\"attn(。, 不是)= 0.00\",\"attn(。, 在)= 0.00\",\"attn(。, 2008)= 0.00\",\"attn(。, 年)= 0.00\",\"attn(。, 金融危机)= 0.00\",\"attn(。, 中)= 0.00\",\"attn(。, ，)= 0.00\",\"attn(。, 欧洲)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 和)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 和)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 都)= 0.00\",\"attn(。, 无法)= 0.00\",\"attn(。, 实现)= 0.00\",\"attn(。, 这一)= 0.00\",\"attn(。, 政策)= 0.00\",\"attn(。, ，)= 0.00\",\"attn(。, 而)= 0.75\",\"attn(。, 危机)= 0.00\",\"attn(。, 上)= 0.15\",\"attn(。, 就)= 0.10\",\"attn(。, 需要)= 0.00\",\"attn(。, 解决)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.93\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.07\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.94\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.06\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.94\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.06\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.92\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.08\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(。, &lt;s&gt;)= 0.00\",\"attn(。, 美联储)= 0.00\",\"attn(。, 还)= 0.00\",\"attn(。, 不是)= 0.00\",\"attn(。, 在)= 0.00\",\"attn(。, 2008)= 0.00\",\"attn(。, 年)= 0.00\",\"attn(。, 金融危机)= 0.00\",\"attn(。, 中)= 0.00\",\"attn(。, ，)= 0.00\",\"attn(。, 欧洲)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 和)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 和)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 都)= 0.00\",\"attn(。, 无法)= 0.00\",\"attn(。, 实现)= 0.00\",\"attn(。, 这一)= 0.00\",\"attn(。, 政策)= 0.00\",\"attn(。, ，)= 0.00\",\"attn(。, 而)= 0.82\",\"attn(。, 危机)= 0.00\",\"attn(。, 上)= 0.08\",\"attn(。, 就)= 0.10\",\"attn(。, 需要)= 0.00\",\"attn(。, 解决)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.93\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.07\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.91\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.09\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.87\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.13\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.86\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.14\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(。, &lt;s&gt;)= 0.00\",\"attn(。, 美联储)= 0.00\",\"attn(。, 还)= 0.00\",\"attn(。, 不是)= 0.00\",\"attn(。, 在)= 0.00\",\"attn(。, 2008)= 0.00\",\"attn(。, 年)= 0.00\",\"attn(。, 金融危机)= 0.00\",\"attn(。, 中)= 0.00\",\"attn(。, ，)= 0.00\",\"attn(。, 欧洲)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 和)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 和)= 0.00\",\"attn(。, 银行)= 0.00\",\"attn(。, 都)= 0.00\",\"attn(。, 无法)= 0.00\",\"attn(。, 实现)= 0.00\",\"attn(。, 这一)= 0.00\",\"attn(。, 政策)= 0.00\",\"attn(。, ，)= 0.00\",\"attn(。, 而)= 0.87\",\"attn(。, 危机)= 0.00\",\"attn(。, 上)= 0.04\",\"attn(。, 就)= 0.09\",\"attn(。, 需要)= 0.00\",\"attn(。, 解决)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, 。)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\",\"attn(。, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.96\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.04\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.96\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.04\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.93\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.07\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 美联储)= 0.00\",\"attn(&lt;\\u002fs&gt;, 还)= 0.00\",\"attn(&lt;\\u002fs&gt;, 不是)= 0.00\",\"attn(&lt;\\u002fs&gt;, 在)= 0.00\",\"attn(&lt;\\u002fs&gt;, 2008)= 0.00\",\"attn(&lt;\\u002fs&gt;, 年)= 0.00\",\"attn(&lt;\\u002fs&gt;, 金融危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 中)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 欧洲)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 和)= 0.00\",\"attn(&lt;\\u002fs&gt;, 银行)= 0.00\",\"attn(&lt;\\u002fs&gt;, 都)= 0.00\",\"attn(&lt;\\u002fs&gt;, 无法)= 0.00\",\"attn(&lt;\\u002fs&gt;, 实现)= 0.00\",\"attn(&lt;\\u002fs&gt;, 这一)= 0.00\",\"attn(&lt;\\u002fs&gt;, 政策)= 0.00\",\"attn(&lt;\\u002fs&gt;, ，)= 0.00\",\"attn(&lt;\\u002fs&gt;, 而)= 0.88\",\"attn(&lt;\\u002fs&gt;, 危机)= 0.00\",\"attn(&lt;\\u002fs&gt;, 上)= 0.00\",\"attn(&lt;\\u002fs&gt;, 就)= 0.11\",\"attn(&lt;\\u002fs&gt;, 需要)= 0.00\",\"attn(&lt;\\u002fs&gt;, 解决)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, 。)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.00\"]],\"x\":[\"\\u003cspan style='font-size: 10px;color:grey'\\u003e000\\u003c\\u002fspan\\u003e  &lt;s&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e001\\u003c\\u002fspan\\u003e  美联储\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e002\\u003c\\u002fspan\\u003e  还\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e003\\u003c\\u002fspan\\u003e  不是\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e004\\u003c\\u002fspan\\u003e  在\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e005\\u003c\\u002fspan\\u003e  2008\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e006\\u003c\\u002fspan\\u003e  年\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e007\\u003c\\u002fspan\\u003e  金融危机\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e008\\u003c\\u002fspan\\u003e  中\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e009\\u003c\\u002fspan\\u003e  ，\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e010\\u003c\\u002fspan\\u003e  欧洲\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e011\\u003c\\u002fspan\\u003e  银行\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e012\\u003c\\u002fspan\\u003e  和\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e013\\u003c\\u002fspan\\u003e  银行\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e014\\u003c\\u002fspan\\u003e  和\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e015\\u003c\\u002fspan\\u003e  银行\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e016\\u003c\\u002fspan\\u003e  都\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e017\\u003c\\u002fspan\\u003e  无法\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e018\\u003c\\u002fspan\\u003e  实现\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e019\\u003c\\u002fspan\\u003e  这一\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e020\\u003c\\u002fspan\\u003e  政策\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e021\\u003c\\u002fspan\\u003e  ，\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e022\\u003c\\u002fspan\\u003e  而\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e023\\u003c\\u002fspan\\u003e  危机\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e024\\u003c\\u002fspan\\u003e  上\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e025\\u003c\\u002fspan\\u003e  就\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e026\\u003c\\u002fspan\\u003e  需要\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e027\\u003c\\u002fspan\\u003e  解决\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e028\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e029\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e030\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e031\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e032\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e033\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e034\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e035\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e036\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e037\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e038\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e039\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e040\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e041\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e042\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e043\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e044\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e045\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e046\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e047\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e048\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\"],\"xgap\":1,\"y\":[\"\\u003cspan style='font-size: 10px;color:grey'\\u003e000\\u003c\\u002fspan\\u003e  &lt;s&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e001\\u003c\\u002fspan\\u003e  美联储\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e002\\u003c\\u002fspan\\u003e  还\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e003\\u003c\\u002fspan\\u003e  不是\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e004\\u003c\\u002fspan\\u003e  在\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e005\\u003c\\u002fspan\\u003e  2008\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e006\\u003c\\u002fspan\\u003e  年\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e007\\u003c\\u002fspan\\u003e  金融危机\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e008\\u003c\\u002fspan\\u003e  中\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e009\\u003c\\u002fspan\\u003e  ，\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e010\\u003c\\u002fspan\\u003e  欧洲\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e011\\u003c\\u002fspan\\u003e  银行\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e012\\u003c\\u002fspan\\u003e  和\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e013\\u003c\\u002fspan\\u003e  银行\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e014\\u003c\\u002fspan\\u003e  和\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e015\\u003c\\u002fspan\\u003e  银行\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e016\\u003c\\u002fspan\\u003e  都\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e017\\u003c\\u002fspan\\u003e  无法\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e018\\u003c\\u002fspan\\u003e  实现\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e019\\u003c\\u002fspan\\u003e  这一\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e020\\u003c\\u002fspan\\u003e  政策\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e021\\u003c\\u002fspan\\u003e  ，\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e022\\u003c\\u002fspan\\u003e  而\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e023\\u003c\\u002fspan\\u003e  危机\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e024\\u003c\\u002fspan\\u003e  上\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e025\\u003c\\u002fspan\\u003e  就\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e026\\u003c\\u002fspan\\u003e  需要\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e027\\u003c\\u002fspan\\u003e  解决\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e028\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e029\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e030\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e031\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e032\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e033\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e034\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e035\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e036\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e037\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e038\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e039\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e040\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e041\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e042\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e043\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e044\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e045\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e046\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e047\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e048\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\"],\"ygap\":1,\"z\":[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.0,2.687847e-12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.0213901e-14,6.2667856e-20,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0000017132702,0.56232125,0.42213207,0.015544977,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.19293703,0.80706143,6.2783756e-17,3.164496e-13,0.0000015382886,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[9.14264e-20,1.5626068e-27,1.53693e-40,5.6974006e-36,2.7111473e-22,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[3.8238283e-14,3.4001758e-27,7.52917e-24,5.512932e-18,0.00069411646,0.9993042,0.0000017061898,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.9558998e-22,1.7343956e-33,0.000008295722,0.000085655935,0.99990594,6.5137566e-33,6.06697e-27,1.7800736e-36,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[4.2631219e-16,9.4175115e-29,1.1503311e-16,3.9087826e-14,0.9999976,1.615768e-7,1.4510001e-11,1.537119e-38,0.0000023185826,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.4237575e-19,1.7960533e-19,2.1760975e-9,1.787901e-8,0.0003056186,4.054922e-9,1.5589661e-7,1.2047418e-19,0.99969435,3.872629e-17,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.864503e-15,1.820282e-30,4.794937e-18,1.6905905e-11,1.0,1.3716782e-10,5.7215344e-13,6.2087e-40,1.6081586e-8,3.1935263e-14,6.068922e-22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[9.654265e-23,1.3749786e-35,2.2377138e-9,0.000037012287,0.99996305,1.5679452e-29,2.1923645e-25,8.65593e-40,5.295992e-17,1.4760571e-16,5.5305425e-31,2.3600094e-32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.1580015e-12,1.6431426e-15,1.8909616e-14,7.4591966e-10,0.000003444961,0.004961007,0.00075072347,7.1552255e-17,0.9942848,4.763437e-13,7.44911e-8,3.4958263e-15,3.5231757e-12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[3.4228886e-20,1.3761367e-34,2.1361645e-11,4.6529172e-7,0.9999995,6.306261e-26,8.465156e-24,8.1456e-41,1.1438572e-16,2.4042336e-15,6.0783936e-30,9.6204875e-33,1.4413206e-12,2.7317796e-33,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.3819876e-12,3.9166947e-15,3.5179023e-14,9.2317065e-10,0.0000038279313,0.0053792624,0.0008131842,1.7409218e-16,0.9938036,9.13755e-13,1.09654025e-7,8.173032e-15,6.0855192e-12,9.536467e-12,1.0625902e-11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[3.273379e-19,2.2997223e-33,3.1418423e-11,5.069244e-7,0.9999995,7.0026936e-25,4.5437782e-23,1.139676e-39,2.0467209e-16,1.1537185e-14,5.496299e-29,9.351823e-32,4.805928e-12,2.6189935e-32,4.923389e-12,1.08320475e-32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.8566093e-12,1.3966095e-16,0.00004508112,0.00012252823,0.82447714,2.402946e-9,2.7349496e-9,3.1011102e-19,0.00041879827,4.9611243e-10,3.8213895e-13,2.970982e-15,4.4100126e-8,5.4787078e-15,4.527891e-8,4.437859e-15,0.17493634,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[3.5843403e-20,7.6298825e-18,0.00076293835,9.815764e-8,6.013638e-10,3.120245e-25,1.0912253e-19,2.2609928e-14,2.265479e-13,2.161193e-15,1.03958e-18,8.826986e-13,4.980854e-13,1.6553392e-14,4.984884e-13,8.043725e-15,0.36061126,0.63862574,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.9714893e-15,1.6173152e-13,0.00060553226,1.6564697e-7,8.8455783e-7,5.1761978e-17,5.9978216e-13,3.689802e-11,5.1463143e-8,3.1995537e-12,2.493341e-12,1.4425564e-8,2.414679e-9,4.627462e-9,2.886241e-9,4.031497e-9,0.66123843,0.3381549,3.312775e-8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.9240845e-14,4.439311e-27,8.692925e-12,1.1614607e-9,1.0,4.3525123e-14,3.4977802e-15,5.006066e-35,5.8543886e-10,4.010683e-12,8.8677615e-23,1.5223618e-27,1.5508148e-10,3.1864836e-27,1.471913e-10,1.4903787e-27,1.617309e-9,4.2533514e-13,2.921585e-19,3.6177318e-29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[3.6831064e-27,2.45522e-40,3.6660282e-7,1.9763843e-7,0.99238646,1.2966502e-35,1.8827221e-31,1e-45,1.0607848e-20,1.9974504e-19,7.2964395e-38,5.2118312e-36,1.3847825e-14,1.8716804e-38,1.0813265e-14,2.853764e-39,0.0076083895,0.0000046652303,3.3115082e-25,4.1894216e-36,2.4703475e-32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.5341748e-19,3.7730874e-19,4.8973714e-8,8.832208e-8,0.0020251437,1.5150667e-9,6.2447945e-8,2.0574421e-19,0.553486,1.211463e-16,1.0325128e-11,2.4281423e-15,1.5391315e-12,2.4113082e-13,2.5062031e-12,4.0994896e-13,0.2448511,0.1996329,0.00000471824,1.8770943e-17,4.591991e-9,6.859113e-16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[6.2973943e-21,1.9262787e-18,5.165534e-28,3.6602203e-26,3.925013e-20,0.99997866,0.0000032616656,9.470871e-21,0.000018126924,1.2217261e-24,6.350466e-10,9.368253e-20,6.885866e-24,3.2626212e-15,1.20038834e-23,1.984967e-14,2.206968e-23,2.031029e-24,2.916974e-15,4.2988194e-24,2.4213159e-19,8.756771e-24,1.1666664e-21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.4446417e-25,1.0066767e-34,5.7840715e-11,4.646223e-11,0.0000034595255,4.2602193e-32,4.354241e-28,5.022738e-38,1.7771408e-20,1.2555326e-19,5.0334174e-32,1.5120688e-30,6.8725776e-16,3.9738098e-32,6.3791714e-16,1.4251125e-32,5.030237e-7,2.0056108e-9,1.0611053e-22,5.2793473e-31,5.654728e-27,9.90548e-20,0.99999607,8.771732e-32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.6436457e-18,7.8538234e-31,7.3418227e-31,3.9910784e-27,5.7856726e-11,0.1961156,6.0000595e-11,1.12e-43,2.1228699e-9,7.436253e-22,7.112528e-21,4.8051135e-35,1.4879244e-20,5.5660936e-31,1.8460813e-20,1.422773e-30,4.359646e-27,1.1293794e-33,5.6525875e-29,1.26917e-40,2.094e-42,4.578128e-22,2.1791288e-11,1.4632e-41,0.80388445,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[4.5607263e-14,5.264361e-15,1.8474146e-15,2.3744451e-15,1.4069371e-9,0.039406773,0.0000043235973,2.5033507e-18,0.0006516147,2.5241245e-15,7.9120077e-10,1.3698897e-15,2.8229643e-14,2.3534722e-13,3.422994e-14,5.047169e-13,5.4210456e-12,1.2925755e-14,1.2374997e-12,1.2527322e-19,4.7273544e-16,7.3730805e-15,1.0069077e-8,1.9121224e-17,0.95993733,4.467003e-8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[6.874375e-11,1.5602527e-7,0.0004906123,3.0014115e-7,0.000003005449,6.030249e-8,0.0000016664294,0.0000066402627,0.004055457,1.3209326e-9,0.0000063484854,0.00027087866,1.4590248e-7,0.0005711746,1.8011345e-7,0.0007350696,0.24694757,0.060675446,0.00004725514,2.9551944e-7,0.16545254,6.143684e-9,0.0003494647,0.000079537414,0.025121335,0.48760068,0.007584138,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[9.524441e-13,2.5103615e-8,0.0000012303594,4.4310258e-9,6.7681215e-11,8.295164e-15,6.1574516e-11,0.00019624241,2.3623936e-9,2.7903863e-11,5.598995e-8,0.00026223998,9.694725e-10,0.00020731323,1.2225818e-9,0.00028585852,0.00005482833,0.0013555429,0.0000055982955,0.000029227476,0.9957743,1.1434159e-10,8.408413e-10,0.0018211798,9.37309e-10,0.0000028890943,0.0000033952529,4.159669e-8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.1394235e-17,4.100234e-24,8.678279e-12,1.1138306e-11,0.0009272847,6.5200595e-11,1.7063813e-13,1.1933105e-29,8.824645e-9,3.4395589e-16,3.7917155e-19,1.5677085e-23,2.5491436e-13,7.281048e-23,2.1759359e-13,5.6551046e-23,9.553194e-8,1.5313435e-11,3.27788e-18,1.30834e-25,4.09903e-24,3.9888926e-16,0.76645154,4.4245187e-26,0.035293672,0.19732745,8.399794e-9,8.9223166e-24,7.553143e-17,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.7308867e-17,2.3597044e-24,3.2267702e-11,1.7828279e-11,0.0006467133,7.3936414e-13,9.432355e-15,1.4973201e-29,8.873907e-10,1.1633942e-15,5.448405e-20,2.0124664e-23,6.257667e-13,4.204705e-23,5.3849476e-13,2.9277414e-23,1.3517925e-7,2.7906413e-11,1.5502369e-18,2.5456145e-25,9.8477175e-24,1.2830772e-15,0.89512426,7.5564924e-26,0.0015557702,0.102673054,2.3381144e-9,4.213727e-24,2.489941e-16,2.0768457e-14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.566827e-16,2.7897858e-23,8.4585686e-11,3.467247e-11,0.00083863887,1.9220433e-12,2.4595292e-14,2.4469807e-28,9.507508e-10,8.048623e-15,3.1545256e-19,2.133308e-22,3.0105913e-12,3.5546605e-22,2.544847e-12,2.5039755e-22,1.8374172e-7,3.8648966e-11,3.975318e-18,2.9608078e-24,6.074561e-23,8.867108e-15,0.9265388,8.516772e-25,0.0009946591,0.071627654,2.1031061e-9,3.130592e-23,1.5002137e-15,7.705614e-14,7.920158e-14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.7329887e-15,1.0794883e-21,3.433808e-10,9.621938e-11,0.0011882116,1.5770543e-11,1.7011204e-13,1.561365e-26,2.3485072e-9,8.854871e-14,5.4431975e-18,6.5362766e-21,2.0390778e-11,9.3270285e-21,1.6970323e-11,6.7438375e-21,3.6864455e-7,8.18971e-11,2.2481614e-17,9.3471794e-23,1.0752962e-21,9.911841e-14,0.9374959,2.9768783e-23,0.001142886,0.060172644,3.0754297e-9,6.003446e-22,1.5057063e-14,4.4597182e-13,4.3692076e-13,6.1312067e-13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.4017413e-14,2.5875786e-20,1.7803121e-9,2.9797204e-10,0.0013747313,3.9033728e-11,5.7268274e-13,8.485617e-25,3.6580527e-9,6.6692116e-13,5.2592418e-17,1.6748022e-19,1.0486751e-10,1.82125e-19,8.607644e-11,1.3261314e-19,0.000001045729,2.752891e-10,1.1780487e-16,2.8241095e-21,2.475328e-20,7.7221346e-13,0.93242574,1.0331221e-21,0.000781837,0.065416634,4.7588222e-9,7.520237e-21,2.0477862e-13,3.6527695e-12,3.3804897e-12,4.5558145e-12,4.6197182e-12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[4.538193e-14,1.4825497e-19,9.489276e-9,8.152366e-10,0.001119895,1.0792419e-11,4.3558408e-13,1.5246155e-23,2.160056e-9,1.823066e-12,1.2186305e-16,1.6970379e-18,2.6583474e-10,1.1984966e-18,2.1603433e-10,8.504126e-19,0.000003966203,1.4087261e-9,3.4827636e-16,3.8641445e-20,4.2085792e-19,2.2238517e-12,0.8998142,1.6508207e-20,0.00022480375,0.098837085,6.5110024e-9,2.6393025e-20,2.6722994e-12,3.3223847e-11,2.8718422e-11,3.731982e-11,3.7265763e-11,2.3017921e-11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.4109511e-15,1.0760072e-21,3.1963186e-11,3.502818e-11,0.0020963894,1.193238e-8,1.0328628e-11,2.6543114e-27,9.009237e-8,1.2889814e-14,4.4908013e-17,1.4088169e-21,3.9530046e-12,7.0890614e-21,3.2989366e-12,5.824012e-21,1.1957928e-7,1.5966565e-11,3.107082e-17,8.8162424e-24,7.3995677e-23,1.414325e-14,0.7481308,3.1652961e-24,0.14912897,0.10064353,1.3078212e-8,6.9224895e-22,5.1801745e-16,2.1004281e-14,2.5805814e-14,4.0671253e-14,4.3296387e-14,2.625758e-14,8.1275146e-16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[5.386793e-15,5.070611e-21,8.3736357e-10,1.4110123e-10,0.0012561319,5.128138e-11,3.067491e-13,4.2405236e-26,2.364941e-9,1.2916534e-13,1.0237502e-17,1.557693e-20,2.664536e-11,1.7664447e-20,2.1174845e-11,1.2017099e-20,6.0394166e-7,7.753536e-11,1.0875171e-17,1.2884339e-22,7.2862056e-22,1.2634324e-13,0.92978156,4.524157e-23,0.0009919665,0.06796976,1.6433729e-9,4.5466343e-22,1.228324e-14,2.8146303e-13,2.642608e-13,3.578976e-13,3.6157115e-13,2.2183279e-13,1.896343e-14,5.9385216e-14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[3.6259418e-13,1.3183805e-18,7.4663635e-9,7.573486e-10,0.0021684947,9.920851e-10,5.555797e-12,2.6402635e-23,9.620631e-9,4.6445924e-12,7.9181715e-16,3.2199924e-18,5.2714977e-10,2.8908674e-18,4.1291784e-10,2.0561425e-18,0.000001943601,3.339755e-10,2.0148835e-16,2.9656687e-20,7.435639e-20,4.740392e-12,0.94104177,1.1289135e-20,0.0012174181,0.05557033,3.717363e-9,5.0614852e-20,5.0989735e-13,5.294305e-12,4.6633934e-12,5.974181e-12,5.9990164e-12,3.8789558e-12,8.083416e-13,1.6470743e-12,1.9353087e-12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.190588e-10,4.3479827e-15,3.0138148e-7,1.1970105e-8,0.003986755,2.989906e-8,2.3781183e-10,5.0550636e-19,5.9033095e-8,7.833714e-10,3.5006563e-13,9.995702e-15,3.6863486e-8,5.6086422e-15,2.8359416e-8,4.1774123e-15,0.000018084036,5.5439195e-9,1.8791233e-14,1.2403684e-16,1.371021e-16,8.7226204e-10,0.93836427,6.232636e-17,0.0010534915,0.056576956,1.5376605e-8,4.8007445e-17,2.0448135e-10,6.7947e-10,5.398743e-10,6.362706e-10,6.325183e-10,4.402075e-10,3.3798006e-10,3.7383377e-10,3.657553e-10,2.7609343e-10,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.1906181e-8,4.98578e-12,0.000018863539,2.1964797e-7,0.0049366304,7.268783e-8,1.9526785e-9,5.43041e-15,1.0867267e-7,7.105604e-8,3.7295736e-11,1.75684e-11,0.0000015554423,4.604958e-12,0.0000011722074,3.408656e-12,0.0002762982,1.7325118e-7,1.0944413e-12,3.584565e-13,2.7821576e-13,8.680749e-8,0.91510844,2.5865082e-13,0.00024813786,0.07940699,5.192586e-8,1.5466347e-14,1.1720794e-7,1.3195687e-7,9.148678e-8,9.816204e-8,9.5522125e-8,6.995429e-8,2.0268526e-7,1.199832e-7,9.06506e-8,5.4843174e-8,2.2177968e-8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[9.107686e-15,1.5394502e-20,1.5505085e-10,8.921944e-11,0.0024449092,2.016896e-8,2.0203965e-11,5.865635e-26,9.0194845e-8,7.203883e-14,2.0301684e-16,1.8899405e-20,1.7503393e-11,6.612262e-20,1.43175515e-11,5.281316e-20,2.977053e-7,3.9174292e-11,7.1789775e-17,1.1416058e-22,5.786925e-22,7.858662e-14,0.81648517,4.328719e-23,0.07803831,0.10303121,1.2521496e-8,3.3766444e-21,3.6373e-15,9.2870224e-14,1.0643381e-13,1.607932e-13,1.698496e-13,1.05372735e-13,5.8450068e-15,2.3212708e-14,4.0066295e-14,4.993231e-14,1.9448918e-14,3.5228913e-15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.5727545e-13,7.4223206e-19,2.1663721e-8,1.0614526e-9,0.0013543484,3.7188762e-11,4.9750433e-13,2.2137693e-23,9.643257e-10,3.6716524e-12,1.3533633e-16,2.7847896e-18,4.778341e-10,1.3049607e-18,3.6264652e-10,8.3566707e-19,0.000004130627,6.499231e-10,5.8147515e-17,3.0421758e-20,6.3482803e-20,3.6167905e-12,0.93018097,1.0707637e-20,0.00010219,0.06835839,1.3401111e-9,1.1176181e-20,1.1401878e-12,9.348269e-12,7.495601e-12,9.2956216e-12,9.22008e-12,5.8718737e-12,1.893862e-12,2.9647075e-12,2.9417592e-12,2.1590295e-12,7.076724e-13,1.0625954e-12,4.74933e-13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.4133796e-12,7.0537416e-17,4.6759862e-7,7.078732e-9,0.0013150241,2.5006655e-11,1.0203079e-12,1.0611787e-20,8.0076296e-10,6.621798e-11,1.9227978e-15,4.440078e-16,5.801134e-9,1.0302202e-16,4.301993e-9,6.3957095e-17,0.0000322542,7.534738e-9,5.58372e-16,5.7503553e-18,1.0588107e-17,6.796917e-11,0.9111943,2.7729257e-18,0.000019719644,0.087438166,2.0362185e-9,3.1096059e-19,9.7481564e-11,3.7559433e-10,2.6638913e-10,3.057967e-10,2.9723804e-10,1.9490633e-10,1.6714714e-10,1.6449271e-10,1.315348e-10,7.964944e-11,2.6002457e-11,9.6300676e-11,3.059844e-11,1.238434e-11,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[1.7800249e-10,7.025446e-14,0.000026794749,1.1476008e-7,0.0016005033,6.9773014e-11,9.192116e-12,9.263445e-17,1.8818076e-9,4.5661186e-9,1.9634245e-13,6.864734e-13,2.05311e-7,7.84647e-14,1.4927978e-7,4.835481e-14,0.0004935634,2.3194093e-7,3.0855543e-14,1.1280285e-14,1.8470006e-14,5.0380535e-9,0.87111396,8.955085e-15,0.000005924161,0.12675811,7.2940205e-9,8.147906e-17,3.866711e-8,5.6410855e-8,3.5299323e-8,3.6926405e-8,3.511178e-8,2.4234854e-8,6.786211e-8,3.871397e-8,2.4618519e-8,1.2280433e-8,4.180431e-9,4.1636426e-8,9.337313e-9,3.6574859e-9,1.3244943e-9,0.0,0.0,0.0,0.0,0.0,0.0],[6.1863825e-9,1.1678503e-11,0.00031854692,7.6713445e-7,0.00225952,4.927416e-10,9.0571814e-11,5.0436594e-14,5.9978094e-9,1.1209065e-7,8.406513e-12,1.0893169e-10,0.0000027063616,9.052894e-12,0.0000019416361,5.690443e-12,0.0022939118,0.0000016984161,6.3161027e-13,2.0713101e-12,2.442043e-12,1.292075e-7,0.85735095,2.1846871e-12,0.0000049428922,0.13775127,2.0680853e-8,6.4242295e-15,0.0000017025222,0.0000012515646,7.3305057e-7,7.217979e-7,6.768886e-7,4.8803764e-7,0.0000030088884,0.0000011907736,6.7553685e-7,3.082521e-7,1.11170856e-7,0.0000019750657,3.575088e-7,1.4111235e-7,5.1348508e-8,3.180351e-8,0.0,0.0,0.0,0.0,0.0],[2.0394856e-14,4.8596447e-20,3.59481e-10,1.3425089e-10,0.0026119016,1.8288269e-8,1.9072084e-11,1.9594435e-25,6.3677284e-8,1.5994684e-13,3.0533e-16,5.6170876e-20,3.5224487e-11,1.4830702e-19,2.812801e-11,1.1384288e-19,4.5172584e-7,5.28517e-11,6.91595e-17,2.7603127e-22,1.0496092e-21,1.664066e-13,0.8651317,1.0899932e-22,0.039603606,0.092652306,8.617372e-9,4.7603978e-21,7.3111175e-15,1.463796e-13,1.5838883e-13,2.3002314e-13,2.3924328e-13,1.4945413e-13,1.165749e-14,3.8371575e-14,6.168453e-14,7.171065e-14,2.7506326e-14,7.0558327e-15,6.7094424e-15,3.5651524e-15,1.8666093e-15,1.6290176e-15,4.7532986e-15,0.0,0.0,0.0,0.0],[1.2723264e-12,5.4640586e-18,2.7397075e-8,1.4712019e-9,0.0021114578,4.998329e-10,2.3066644e-12,8.37402e-23,1.9832789e-9,1.5383124e-11,6.049552e-16,8.209409e-18,1.2306874e-9,3.8970398e-18,9.0191304e-10,2.4765142e-18,0.0000028406332,3.3881464e-10,7.3524736e-17,6.31098e-20,5.256373e-20,1.3748243e-11,0.96060973,2.1391744e-20,0.00016677624,0.03710917,9.92873e-10,3.974808e-20,9.0889357e-13,5.5111866e-12,4.3134866e-12,5.140676e-12,5.024016e-12,3.2907605e-12,1.4554305e-12,1.8730276e-12,1.8804914e-12,1.4031675e-12,4.819609e-13,8.5884896e-13,3.3142917e-13,1.4768559e-13,6.500623e-14,4.7572003e-14,5.41847e-13,3.2844316e-13,0.0,0.0,0.0],[2.4547456e-11,3.9564988e-16,1.9326284e-7,6.2299796e-9,0.0028048793,2.810735e-9,1.6533531e-11,1.7181942e-20,4.9759903e-9,2.1523283e-10,1.6677996e-14,6.379473e-16,1.1036496e-8,2.4024946e-16,8.020046e-9,1.586729e-16,0.0000100331745,1.7375856e-9,9.021277e-16,5.9712522e-18,3.4958187e-18,2.0889071e-10,0.95508564,2.393053e-18,0.00015608636,0.041943047,2.4082842e-9,1.6729543e-18,2.8862088e-11,9.0808236e-11,6.761179e-11,7.7541105e-11,7.5491745e-11,5.1271487e-11,4.8196995e-11,4.3705022e-11,3.9851983e-11,2.7628838e-11,9.988312e-12,3.0329128e-11,9.511881e-12,4.229938e-12,1.8485823e-12,1.3334612e-12,1.9980328e-11,9.891904e-12,9.888906e-12,0.0,0.0],[1.8455265e-10,1.4607783e-14,0.000001815321,2.9450089e-8,0.002894159,3.216549e-9,4.491452e-11,2.6684474e-18,6.7076877e-9,1.7437711e-9,2.0905902e-13,3.857979e-14,6.945609e-8,9.982851e-15,5.0322488e-8,6.6985386e-15,0.000054944845,1.6200909e-8,9.828718e-15,4.833008e-16,3.1020403e-16,1.8656443e-9,0.93076617,2.501962e-16,0.000075092685,0.0662077,6.2794774e-9,3.8562813e-17,1.2467924e-9,2.2112647e-9,1.5496766e-9,1.7122433e-9,1.6567894e-9,1.1513737e-9,2.1856652e-9,1.445298e-9,1.1574751e-9,7.1962947e-10,2.6620023e-10,1.4288357e-9,3.6862072e-10,1.593695e-10,6.658884e-11,4.657854e-11,9.589969e-10,4.00901e-10,3.5787623e-10,2.3203917e-10,0.0],[5.4587024e-10,1.99397e-13,0.000015896667,1.2263764e-7,0.0024107953,1.0329696e-9,4.6893597e-11,1.5992177e-16,4.7678195e-9,7.4042465e-9,9.167242e-13,1.043105e-12,2.6511742e-7,1.677273e-13,1.9111926e-7,1.1081531e-13,0.0003129523,1.5469091e-7,6.054437e-14,1.754343e-14,1.568138e-14,8.536176e-9,0.8830982,1.1994242e-14,0.000020526018,0.11414039,1.2704053e-8,3.3326998e-16,3.6272713e-8,4.1283236e-8,2.7035505e-8,2.8759557e-8,2.7550755e-8,1.934958e-8,6.606915e-8,3.3512116e-8,2.321086e-8,1.2689523e-8,4.669951e-9,4.35481e-8,9.352188e-9,3.8582417e-9,1.5068626e-9,1.010258e-9,2.9022793e-8,1.0474373e-8,8.286671e-9,4.923447e-9,2.1358175e-9]],\"type\":\"heatmap\"}],                        {\"height\":1000,\"title\":{\"text\":\"Decoder self-attn, Layer 1, Head 0\",\"x\":0.5},\"width\":1000,\"xaxis\":{\"automargin\":true,\"showgrid\":false,\"tickangle\":-45,\"ticklen\":5,\"ticks\":\"outside\",\"title\":{\"font\":{\"color\":\"crimson\",\"family\":\"Courier\",\"size\":18},\"text\":\"Key\"}},\"yaxis\":{\"automargin\":true,\"autorange\":\"reversed\",\"showgrid\":false,\"ticklen\":5,\"ticks\":\"outside\",\"title\":{\"font\":{\"color\":\"crimson\",\"family\":\"Courier\",\"size\":18},\"text\":\"Query\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4be6ef13-69bb-4a31-904e-ff5a2621cf93');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "vis_attn(\n",
        "    matrix,\n",
        "    xlabels,\n",
        "    ylabels,\n",
        "    title=title\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edad972c",
      "metadata": {
        "id": "edad972c"
      },
      "outputs": [],
      "source": [
        "# Image(filename='images/decoder_self_attn1.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c63458a9",
      "metadata": {
        "id": "c63458a9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "142e6ec1",
      "metadata": {
        "id": "142e6ec1"
      },
      "source": [
        "### Decoder cross-attention\n",
        "\n",
        "Decoder side (Chinese) is the query, and encoder side (English) is the key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3288366f",
      "metadata": {
        "id": "3288366f"
      },
      "outputs": [],
      "source": [
        "# layer and head to visualize\n",
        "layer = 2\n",
        "head = 1\n",
        "\n",
        "# Decoder cross-attention score: decoder input query encoder output\n",
        "attn_score = model.decoder.layers[layer].cross_attn.attn_score    # [batch_size, num_heads, seq_len, seq_len]\n",
        "attn_score = attn_score.cpu().numpy()\n",
        "\n",
        "matrix = attn_score[0][head]\n",
        "\n",
        "title = f'Decoder cross-attn, Layer {layer}, Head {head}'\n",
        "\n",
        "query_labels = [tokenizer.decode(x) for x in output_ids[0][:-1]]    # -1: exclude last token which is not involved in the attention calculation\n",
        "key_labels = [tokenizer.decode(x) for x in batch['src'][0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6819194",
      "metadata": {
        "id": "f6819194",
        "outputId": "ae00ae7e-ba92-4008-c9bf-8ca01222982d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfbbbcb",
      "metadata": {
        "id": "abfbbbcb",
        "outputId": "e4c6afe0-5dcd-4035-9eca-9eff39c2d3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ],
      "source": [
        "len(ylabels), len(xlabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c6f70a4",
      "metadata": {
        "id": "8c6f70a4",
        "outputId": "b48e07e1-f0df-4b1e-9af6-9fc444746854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"2b3bb503-88b2-4899-b419-2f401f825684\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2b3bb503-88b2-4899-b419-2f401f825684\")) {                    Plotly.newPlot(                        \"2b3bb503-88b2-4899-b419-2f401f825684\",                        [{\"colorbar\":{\"thickness\":15,\"ticklen\":3},\"colorscale\":[[0.0,\"rgb(255,247,251)\"],[0.125,\"rgb(236,231,242)\"],[0.25,\"rgb(208,209,230)\"],[0.375,\"rgb(166,189,219)\"],[0.5,\"rgb(116,169,207)\"],[0.625,\"rgb(54,144,192)\"],[0.75,\"rgb(5,112,176)\"],[0.875,\"rgb(4,90,141)\"],[1.0,\"rgb(2,56,88)\"]],\"hoverinfo\":\"text\",\"hovertext\":[[\"attn(&lt;s&gt;, &lt;s&gt;)= 0.05\",\"attn(&lt;s&gt;, The)= 0.00\",\"attn(&lt;s&gt;,  Fed)= 0.90\",\"attn(&lt;s&gt;,  apparent)= 0.00\",\"attn(&lt;s&gt;, ly)= 0.00\",\"attn(&lt;s&gt;,  could)= 0.00\",\"attn(&lt;s&gt;,  not)= 0.00\",\"attn(&lt;s&gt;,  st)= 0.00\",\"attn(&lt;s&gt;, om)= 0.00\",\"attn(&lt;s&gt;, ach)= 0.00\",\"attn(&lt;s&gt;,  the)= 0.00\",\"attn(&lt;s&gt;,  sell)= 0.00\",\"attn(&lt;s&gt;, -)= 0.00\",\"attn(&lt;s&gt;, off)= 0.00\",\"attn(&lt;s&gt;,  in)= 0.00\",\"attn(&lt;s&gt;,  global)= 0.05\",\"attn(&lt;s&gt;,  financial)= 0.00\",\"attn(&lt;s&gt;,  markets)= 0.00\",\"attn(&lt;s&gt;,  in)= 0.00\",\"attn(&lt;s&gt;,  January)= 0.00\",\"attn(&lt;s&gt;,  and)= 0.00\",\"attn(&lt;s&gt;,  F)= 0.00\",\"attn(&lt;s&gt;, eb)= 0.00\",\"attn(&lt;s&gt;, ru)= 0.00\",\"attn(&lt;s&gt;, ary)= 0.00\",\"attn(&lt;s&gt;, ,)= 0.00\",\"attn(&lt;s&gt;,  which)= 0.00\",\"attn(&lt;s&gt;,  was)= 0.00\",\"attn(&lt;s&gt;,  driven)= 0.00\",\"attn(&lt;s&gt;,  largely)= 0.00\",\"attn(&lt;s&gt;,  by)= 0.00\",\"attn(&lt;s&gt;,  concerns)= 0.00\",\"attn(&lt;s&gt;,  about)= 0.00\",\"attn(&lt;s&gt;,  further)= 0.00\",\"attn(&lt;s&gt;,  tight)= 0.00\",\"attn(&lt;s&gt;, ening)= 0.00\",\"attn(&lt;s&gt;, .)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(美联储, &lt;s&gt;)= 0.00\",\"attn(美联储, The)= 0.00\",\"attn(美联储,  Fed)= 0.00\",\"attn(美联储,  apparent)= 0.00\",\"attn(美联储, ly)= 0.00\",\"attn(美联储,  could)= 0.01\",\"attn(美联储,  not)= 0.01\",\"attn(美联储,  st)= 0.01\",\"attn(美联储, om)= 0.01\",\"attn(美联储, ach)= 0.01\",\"attn(美联储,  the)= 0.01\",\"attn(美联储,  sell)= 0.03\",\"attn(美联储, -)= 0.20\",\"attn(美联储, off)= 0.01\",\"attn(美联储,  in)= 0.11\",\"attn(美联储,  global)= 0.13\",\"attn(美联储,  financial)= 0.07\",\"attn(美联储,  markets)= 0.08\",\"attn(美联储,  in)= 0.01\",\"attn(美联储,  January)= 0.00\",\"attn(美联储,  and)= 0.29\",\"attn(美联储,  F)= 0.00\",\"attn(美联储, eb)= 0.00\",\"attn(美联储, ru)= 0.00\",\"attn(美联储, ary)= 0.00\",\"attn(美联储, ,)= 0.00\",\"attn(美联储,  which)= 0.00\",\"attn(美联储,  was)= 0.00\",\"attn(美联储,  driven)= 0.00\",\"attn(美联储,  largely)= 0.00\",\"attn(美联储,  by)= 0.00\",\"attn(美联储,  concerns)= 0.00\",\"attn(美联储,  about)= 0.00\",\"attn(美联储,  further)= 0.00\",\"attn(美联储,  tight)= 0.00\",\"attn(美联储, ening)= 0.00\",\"attn(美联储, .)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(还, &lt;s&gt;)= 0.00\",\"attn(还, The)= 0.00\",\"attn(还,  Fed)= 0.00\",\"attn(还,  apparent)= 0.00\",\"attn(还, ly)= 0.00\",\"attn(还,  could)= 0.01\",\"attn(还,  not)= 0.01\",\"attn(还,  st)= 0.01\",\"attn(还, om)= 0.01\",\"attn(还, ach)= 0.02\",\"attn(还,  the)= 0.01\",\"attn(还,  sell)= 0.07\",\"attn(还, -)= 0.16\",\"attn(还, off)= 0.04\",\"attn(还,  in)= 0.23\",\"attn(还,  global)= 0.20\",\"attn(还,  financial)= 0.04\",\"attn(还,  markets)= 0.05\",\"attn(还,  in)= 0.05\",\"attn(还,  January)= 0.00\",\"attn(还,  and)= 0.08\",\"attn(还,  F)= 0.00\",\"attn(还, eb)= 0.00\",\"attn(还, ru)= 0.00\",\"attn(还, ary)= 0.00\",\"attn(还, ,)= 0.00\",\"attn(还,  which)= 0.00\",\"attn(还,  was)= 0.00\",\"attn(还,  driven)= 0.00\",\"attn(还,  largely)= 0.00\",\"attn(还,  by)= 0.00\",\"attn(还,  concerns)= 0.00\",\"attn(还,  about)= 0.00\",\"attn(还,  further)= 0.00\",\"attn(还,  tight)= 0.00\",\"attn(还, ening)= 0.00\",\"attn(还, .)= 0.00\",\"attn(还, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(不是, &lt;s&gt;)= 0.00\",\"attn(不是, The)= 0.00\",\"attn(不是,  Fed)= 0.00\",\"attn(不是,  apparent)= 0.00\",\"attn(不是, ly)= 0.00\",\"attn(不是,  could)= 0.00\",\"attn(不是,  not)= 0.00\",\"attn(不是,  st)= 0.00\",\"attn(不是, om)= 0.00\",\"attn(不是, ach)= 0.00\",\"attn(不是,  the)= 0.00\",\"attn(不是,  sell)= 0.00\",\"attn(不是, -)= 0.00\",\"attn(不是, off)= 0.00\",\"attn(不是,  in)= 0.00\",\"attn(不是,  global)= 0.91\",\"attn(不是,  financial)= 0.06\",\"attn(不是,  markets)= 0.03\",\"attn(不是,  in)= 0.00\",\"attn(不是,  January)= 0.00\",\"attn(不是,  and)= 0.00\",\"attn(不是,  F)= 0.00\",\"attn(不是, eb)= 0.00\",\"attn(不是, ru)= 0.00\",\"attn(不是, ary)= 0.00\",\"attn(不是, ,)= 0.00\",\"attn(不是,  which)= 0.00\",\"attn(不是,  was)= 0.00\",\"attn(不是,  driven)= 0.00\",\"attn(不是,  largely)= 0.00\",\"attn(不是,  by)= 0.00\",\"attn(不是,  concerns)= 0.00\",\"attn(不是,  about)= 0.00\",\"attn(不是,  further)= 0.00\",\"attn(不是,  tight)= 0.00\",\"attn(不是, ening)= 0.00\",\"attn(不是, .)= 0.00\",\"attn(不是, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(在, &lt;s&gt;)= 0.00\",\"attn(在, The)= 0.00\",\"attn(在,  Fed)= 0.00\",\"attn(在,  apparent)= 0.00\",\"attn(在, ly)= 0.00\",\"attn(在,  could)= 0.00\",\"attn(在,  not)= 0.00\",\"attn(在,  st)= 0.00\",\"attn(在, om)= 0.00\",\"attn(在, ach)= 0.00\",\"attn(在,  the)= 0.00\",\"attn(在,  sell)= 0.00\",\"attn(在, -)= 0.00\",\"attn(在, off)= 0.00\",\"attn(在,  in)= 0.01\",\"attn(在,  global)= 0.92\",\"attn(在,  financial)= 0.04\",\"attn(在,  markets)= 0.02\",\"attn(在,  in)= 0.01\",\"attn(在,  January)= 0.00\",\"attn(在,  and)= 0.00\",\"attn(在,  F)= 0.00\",\"attn(在, eb)= 0.00\",\"attn(在, ru)= 0.00\",\"attn(在, ary)= 0.00\",\"attn(在, ,)= 0.00\",\"attn(在,  which)= 0.00\",\"attn(在,  was)= 0.00\",\"attn(在,  driven)= 0.00\",\"attn(在,  largely)= 0.00\",\"attn(在,  by)= 0.00\",\"attn(在,  concerns)= 0.00\",\"attn(在,  about)= 0.00\",\"attn(在,  further)= 0.00\",\"attn(在,  tight)= 0.00\",\"attn(在, ening)= 0.00\",\"attn(在, .)= 0.00\",\"attn(在, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(2008, &lt;s&gt;)= 0.00\",\"attn(2008, The)= 0.00\",\"attn(2008,  Fed)= 0.00\",\"attn(2008,  apparent)= 0.00\",\"attn(2008, ly)= 0.00\",\"attn(2008,  could)= 0.00\",\"attn(2008,  not)= 0.00\",\"attn(2008,  st)= 0.00\",\"attn(2008, om)= 0.00\",\"attn(2008, ach)= 0.00\",\"attn(2008,  the)= 0.00\",\"attn(2008,  sell)= 0.00\",\"attn(2008, -)= 0.07\",\"attn(2008, off)= 0.01\",\"attn(2008,  in)= 0.10\",\"attn(2008,  global)= 0.56\",\"attn(2008,  financial)= 0.06\",\"attn(2008,  markets)= 0.07\",\"attn(2008,  in)= 0.06\",\"attn(2008,  January)= 0.00\",\"attn(2008,  and)= 0.02\",\"attn(2008,  F)= 0.01\",\"attn(2008, eb)= 0.00\",\"attn(2008, ru)= 0.00\",\"attn(2008, ary)= 0.00\",\"attn(2008, ,)= 0.00\",\"attn(2008,  which)= 0.00\",\"attn(2008,  was)= 0.00\",\"attn(2008,  driven)= 0.00\",\"attn(2008,  largely)= 0.00\",\"attn(2008,  by)= 0.00\",\"attn(2008,  concerns)= 0.00\",\"attn(2008,  about)= 0.00\",\"attn(2008,  further)= 0.00\",\"attn(2008,  tight)= 0.00\",\"attn(2008, ening)= 0.00\",\"attn(2008, .)= 0.00\",\"attn(2008, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(年, &lt;s&gt;)= 0.00\",\"attn(年, The)= 0.00\",\"attn(年,  Fed)= 0.00\",\"attn(年,  apparent)= 0.00\",\"attn(年, ly)= 0.00\",\"attn(年,  could)= 0.00\",\"attn(年,  not)= 0.00\",\"attn(年,  st)= 0.00\",\"attn(年, om)= 0.00\",\"attn(年, ach)= 0.00\",\"attn(年,  the)= 0.00\",\"attn(年,  sell)= 0.00\",\"attn(年, -)= 0.02\",\"attn(年, off)= 0.00\",\"attn(年,  in)= 0.01\",\"attn(年,  global)= 0.11\",\"attn(年,  financial)= 0.37\",\"attn(年,  markets)= 0.32\",\"attn(年,  in)= 0.01\",\"attn(年,  January)= 0.00\",\"attn(年,  and)= 0.15\",\"attn(年,  F)= 0.00\",\"attn(年, eb)= 0.00\",\"attn(年, ru)= 0.00\",\"attn(年, ary)= 0.00\",\"attn(年, ,)= 0.00\",\"attn(年,  which)= 0.00\",\"attn(年,  was)= 0.00\",\"attn(年,  driven)= 0.00\",\"attn(年,  largely)= 0.00\",\"attn(年,  by)= 0.00\",\"attn(年,  concerns)= 0.00\",\"attn(年,  about)= 0.00\",\"attn(年,  further)= 0.00\",\"attn(年,  tight)= 0.00\",\"attn(年, ening)= 0.00\",\"attn(年, .)= 0.00\",\"attn(年, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(金融危机, &lt;s&gt;)= 0.00\",\"attn(金融危机, The)= 0.00\",\"attn(金融危机,  Fed)= 0.00\",\"attn(金融危机,  apparent)= 0.00\",\"attn(金融危机, ly)= 0.00\",\"attn(金融危机,  could)= 0.00\",\"attn(金融危机,  not)= 0.00\",\"attn(金融危机,  st)= 0.00\",\"attn(金融危机, om)= 0.00\",\"attn(金融危机, ach)= 0.00\",\"attn(金融危机,  the)= 0.01\",\"attn(金融危机,  sell)= 0.00\",\"attn(金融危机, -)= 0.01\",\"attn(金融危机, off)= 0.00\",\"attn(金融危机,  in)= 0.00\",\"attn(金融危机,  global)= 0.00\",\"attn(金融危机,  financial)= 0.00\",\"attn(金融危机,  markets)= 0.01\",\"attn(金融危机,  in)= 0.00\",\"attn(金融危机,  January)= 0.00\",\"attn(金融危机,  and)= 0.85\",\"attn(金融危机,  F)= 0.00\",\"attn(金融危机, eb)= 0.00\",\"attn(金融危机, ru)= 0.01\",\"attn(金融危机, ary)= 0.00\",\"attn(金融危机, ,)= 0.05\",\"attn(金融危机,  which)= 0.01\",\"attn(金融危机,  was)= 0.01\",\"attn(金融危机,  driven)= 0.00\",\"attn(金融危机,  largely)= 0.01\",\"attn(金融危机,  by)= 0.00\",\"attn(金融危机,  concerns)= 0.00\",\"attn(金融危机,  about)= 0.00\",\"attn(金融危机,  further)= 0.01\",\"attn(金融危机,  tight)= 0.00\",\"attn(金融危机, ening)= 0.00\",\"attn(金融危机, .)= 0.00\",\"attn(金融危机, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(中, &lt;s&gt;)= 0.00\",\"attn(中, The)= 0.00\",\"attn(中,  Fed)= 0.00\",\"attn(中,  apparent)= 0.00\",\"attn(中, ly)= 0.00\",\"attn(中,  could)= 0.00\",\"attn(中,  not)= 0.00\",\"attn(中,  st)= 0.00\",\"attn(中, om)= 0.00\",\"attn(中, ach)= 0.00\",\"attn(中,  the)= 0.00\",\"attn(中,  sell)= 0.00\",\"attn(中, -)= 0.02\",\"attn(中, off)= 0.00\",\"attn(中,  in)= 0.01\",\"attn(中,  global)= 0.04\",\"attn(中,  financial)= 0.42\",\"attn(中,  markets)= 0.41\",\"attn(中,  in)= 0.00\",\"attn(中,  January)= 0.00\",\"attn(中,  and)= 0.09\",\"attn(中,  F)= 0.00\",\"attn(中, eb)= 0.00\",\"attn(中, ru)= 0.00\",\"attn(中, ary)= 0.00\",\"attn(中, ,)= 0.00\",\"attn(中,  which)= 0.00\",\"attn(中,  was)= 0.00\",\"attn(中,  driven)= 0.00\",\"attn(中,  largely)= 0.00\",\"attn(中,  by)= 0.00\",\"attn(中,  concerns)= 0.00\",\"attn(中,  about)= 0.00\",\"attn(中,  further)= 0.00\",\"attn(中,  tight)= 0.00\",\"attn(中, ening)= 0.00\",\"attn(中, .)= 0.00\",\"attn(中, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(，, &lt;s&gt;)= 0.00\",\"attn(，, The)= 0.00\",\"attn(，,  Fed)= 0.00\",\"attn(，,  apparent)= 0.00\",\"attn(，, ly)= 0.00\",\"attn(，,  could)= 0.00\",\"attn(，,  not)= 0.00\",\"attn(，,  st)= 0.00\",\"attn(，, om)= 0.00\",\"attn(，, ach)= 0.00\",\"attn(，,  the)= 0.00\",\"attn(，,  sell)= 0.00\",\"attn(，, -)= 0.00\",\"attn(，, off)= 0.00\",\"attn(，,  in)= 0.01\",\"attn(，,  global)= 0.19\",\"attn(，,  financial)= 0.40\",\"attn(，,  markets)= 0.25\",\"attn(，,  in)= 0.01\",\"attn(，,  January)= 0.00\",\"attn(，,  and)= 0.14\",\"attn(，,  F)= 0.00\",\"attn(，, eb)= 0.00\",\"attn(，, ru)= 0.00\",\"attn(，, ary)= 0.00\",\"attn(，, ,)= 0.00\",\"attn(，,  which)= 0.00\",\"attn(，,  was)= 0.00\",\"attn(，,  driven)= 0.00\",\"attn(，,  largely)= 0.00\",\"attn(，,  by)= 0.00\",\"attn(，,  concerns)= 0.00\",\"attn(，,  about)= 0.00\",\"attn(，,  further)= 0.00\",\"attn(，,  tight)= 0.00\",\"attn(，, ening)= 0.00\",\"attn(，, .)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(欧洲, &lt;s&gt;)= 0.00\",\"attn(欧洲, The)= 0.00\",\"attn(欧洲,  Fed)= 0.00\",\"attn(欧洲,  apparent)= 0.00\",\"attn(欧洲, ly)= 0.00\",\"attn(欧洲,  could)= 0.00\",\"attn(欧洲,  not)= 0.00\",\"attn(欧洲,  st)= 0.00\",\"attn(欧洲, om)= 0.00\",\"attn(欧洲, ach)= 0.00\",\"attn(欧洲,  the)= 0.00\",\"attn(欧洲,  sell)= 0.00\",\"attn(欧洲, -)= 0.00\",\"attn(欧洲, off)= 0.00\",\"attn(欧洲,  in)= 0.00\",\"attn(欧洲,  global)= 0.00\",\"attn(欧洲,  financial)= 0.39\",\"attn(欧洲,  markets)= 0.39\",\"attn(欧洲,  in)= 0.00\",\"attn(欧洲,  January)= 0.00\",\"attn(欧洲,  and)= 0.20\",\"attn(欧洲,  F)= 0.00\",\"attn(欧洲, eb)= 0.00\",\"attn(欧洲, ru)= 0.00\",\"attn(欧洲, ary)= 0.00\",\"attn(欧洲, ,)= 0.00\",\"attn(欧洲,  which)= 0.00\",\"attn(欧洲,  was)= 0.00\",\"attn(欧洲,  driven)= 0.00\",\"attn(欧洲,  largely)= 0.00\",\"attn(欧洲,  by)= 0.00\",\"attn(欧洲,  concerns)= 0.00\",\"attn(欧洲,  about)= 0.00\",\"attn(欧洲,  further)= 0.00\",\"attn(欧洲,  tight)= 0.00\",\"attn(欧洲, ening)= 0.00\",\"attn(欧洲, .)= 0.00\",\"attn(欧洲, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(银行, &lt;s&gt;)= 0.00\",\"attn(银行, The)= 0.00\",\"attn(银行,  Fed)= 0.00\",\"attn(银行,  apparent)= 0.00\",\"attn(银行, ly)= 0.00\",\"attn(银行,  could)= 0.00\",\"attn(银行,  not)= 0.00\",\"attn(银行,  st)= 0.00\",\"attn(银行, om)= 0.00\",\"attn(银行, ach)= 0.00\",\"attn(银行,  the)= 0.00\",\"attn(银行,  sell)= 0.00\",\"attn(银行, -)= 0.00\",\"attn(银行, off)= 0.00\",\"attn(银行,  in)= 0.00\",\"attn(银行,  global)= 0.00\",\"attn(银行,  financial)= 0.03\",\"attn(银行,  markets)= 0.04\",\"attn(银行,  in)= 0.00\",\"attn(银行,  January)= 0.00\",\"attn(银行,  and)= 0.87\",\"attn(银行,  F)= 0.00\",\"attn(银行, eb)= 0.00\",\"attn(银行, ru)= 0.00\",\"attn(银行, ary)= 0.00\",\"attn(银行, ,)= 0.03\",\"attn(银行,  which)= 0.00\",\"attn(银行,  was)= 0.00\",\"attn(银行,  driven)= 0.00\",\"attn(银行,  largely)= 0.00\",\"attn(银行,  by)= 0.00\",\"attn(银行,  concerns)= 0.00\",\"attn(银行,  about)= 0.00\",\"attn(银行,  further)= 0.00\",\"attn(银行,  tight)= 0.00\",\"attn(银行, ening)= 0.00\",\"attn(银行, .)= 0.00\",\"attn(银行, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(和, &lt;s&gt;)= 0.00\",\"attn(和, The)= 0.00\",\"attn(和,  Fed)= 0.00\",\"attn(和,  apparent)= 0.00\",\"attn(和, ly)= 0.00\",\"attn(和,  could)= 0.00\",\"attn(和,  not)= 0.00\",\"attn(和,  st)= 0.00\",\"attn(和, om)= 0.00\",\"attn(和, ach)= 0.00\",\"attn(和,  the)= 0.00\",\"attn(和,  sell)= 0.00\",\"attn(和, -)= 0.00\",\"attn(和, off)= 0.00\",\"attn(和,  in)= 0.00\",\"attn(和,  global)= 0.03\",\"attn(和,  financial)= 0.61\",\"attn(和,  markets)= 0.35\",\"attn(和,  in)= 0.00\",\"attn(和,  January)= 0.00\",\"attn(和,  and)= 0.00\",\"attn(和,  F)= 0.00\",\"attn(和, eb)= 0.00\",\"attn(和, ru)= 0.00\",\"attn(和, ary)= 0.00\",\"attn(和, ,)= 0.00\",\"attn(和,  which)= 0.00\",\"attn(和,  was)= 0.00\",\"attn(和,  driven)= 0.00\",\"attn(和,  largely)= 0.00\",\"attn(和,  by)= 0.00\",\"attn(和,  concerns)= 0.00\",\"attn(和,  about)= 0.00\",\"attn(和,  further)= 0.00\",\"attn(和,  tight)= 0.00\",\"attn(和, ening)= 0.00\",\"attn(和, .)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(银行, &lt;s&gt;)= 0.00\",\"attn(银行, The)= 0.00\",\"attn(银行,  Fed)= 0.00\",\"attn(银行,  apparent)= 0.00\",\"attn(银行, ly)= 0.00\",\"attn(银行,  could)= 0.00\",\"attn(银行,  not)= 0.00\",\"attn(银行,  st)= 0.00\",\"attn(银行, om)= 0.00\",\"attn(银行, ach)= 0.00\",\"attn(银行,  the)= 0.00\",\"attn(银行,  sell)= 0.00\",\"attn(银行, -)= 0.00\",\"attn(银行, off)= 0.00\",\"attn(银行,  in)= 0.00\",\"attn(银行,  global)= 0.00\",\"attn(银行,  financial)= 0.04\",\"attn(银行,  markets)= 0.06\",\"attn(银行,  in)= 0.00\",\"attn(银行,  January)= 0.00\",\"attn(银行,  and)= 0.52\",\"attn(银行,  F)= 0.00\",\"attn(银行, eb)= 0.00\",\"attn(银行, ru)= 0.00\",\"attn(银行, ary)= 0.00\",\"attn(银行, ,)= 0.07\",\"attn(银行,  which)= 0.00\",\"attn(银行,  was)= 0.00\",\"attn(银行,  driven)= 0.02\",\"attn(银行,  largely)= 0.01\",\"attn(银行,  by)= 0.01\",\"attn(银行,  concerns)= 0.03\",\"attn(银行,  about)= 0.02\",\"attn(银行,  further)= 0.06\",\"attn(银行,  tight)= 0.04\",\"attn(银行, ening)= 0.05\",\"attn(银行, .)= 0.02\",\"attn(银行, &lt;\\u002fs&gt;)= 0.02\"],[\"attn(和, &lt;s&gt;)= 0.00\",\"attn(和, The)= 0.00\",\"attn(和,  Fed)= 0.00\",\"attn(和,  apparent)= 0.00\",\"attn(和, ly)= 0.00\",\"attn(和,  could)= 0.00\",\"attn(和,  not)= 0.00\",\"attn(和,  st)= 0.00\",\"attn(和, om)= 0.00\",\"attn(和, ach)= 0.00\",\"attn(和,  the)= 0.00\",\"attn(和,  sell)= 0.00\",\"attn(和, -)= 0.00\",\"attn(和, off)= 0.00\",\"attn(和,  in)= 0.00\",\"attn(和,  global)= 0.02\",\"attn(和,  financial)= 0.62\",\"attn(和,  markets)= 0.35\",\"attn(和,  in)= 0.00\",\"attn(和,  January)= 0.00\",\"attn(和,  and)= 0.00\",\"attn(和,  F)= 0.00\",\"attn(和, eb)= 0.00\",\"attn(和, ru)= 0.00\",\"attn(和, ary)= 0.00\",\"attn(和, ,)= 0.00\",\"attn(和,  which)= 0.00\",\"attn(和,  was)= 0.00\",\"attn(和,  driven)= 0.00\",\"attn(和,  largely)= 0.00\",\"attn(和,  by)= 0.00\",\"attn(和,  concerns)= 0.00\",\"attn(和,  about)= 0.00\",\"attn(和,  further)= 0.00\",\"attn(和,  tight)= 0.00\",\"attn(和, ening)= 0.00\",\"attn(和, .)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(银行, &lt;s&gt;)= 0.00\",\"attn(银行, The)= 0.00\",\"attn(银行,  Fed)= 0.00\",\"attn(银行,  apparent)= 0.00\",\"attn(银行, ly)= 0.00\",\"attn(银行,  could)= 0.00\",\"attn(银行,  not)= 0.00\",\"attn(银行,  st)= 0.00\",\"attn(银行, om)= 0.00\",\"attn(银行, ach)= 0.00\",\"attn(银行,  the)= 0.00\",\"attn(银行,  sell)= 0.00\",\"attn(银行, -)= 0.00\",\"attn(银行, off)= 0.00\",\"attn(银行,  in)= 0.00\",\"attn(银行,  global)= 0.00\",\"attn(银行,  financial)= 0.02\",\"attn(银行,  markets)= 0.03\",\"attn(银行,  in)= 0.00\",\"attn(银行,  January)= 0.00\",\"attn(银行,  and)= 0.30\",\"attn(银行,  F)= 0.00\",\"attn(银行, eb)= 0.00\",\"attn(银行, ru)= 0.00\",\"attn(银行, ary)= 0.00\",\"attn(银行, ,)= 0.09\",\"attn(银行,  which)= 0.00\",\"attn(银行,  was)= 0.00\",\"attn(银行,  driven)= 0.03\",\"attn(银行,  largely)= 0.01\",\"attn(银行,  by)= 0.03\",\"attn(银行,  concerns)= 0.06\",\"attn(银行,  about)= 0.05\",\"attn(银行,  further)= 0.09\",\"attn(银行,  tight)= 0.07\",\"attn(银行, ening)= 0.07\",\"attn(银行, .)= 0.07\",\"attn(银行, &lt;\\u002fs&gt;)= 0.06\"],[\"attn(都, &lt;s&gt;)= 0.00\",\"attn(都, The)= 0.00\",\"attn(都,  Fed)= 0.00\",\"attn(都,  apparent)= 0.00\",\"attn(都, ly)= 0.00\",\"attn(都,  could)= 0.00\",\"attn(都,  not)= 0.00\",\"attn(都,  st)= 0.00\",\"attn(都, om)= 0.00\",\"attn(都, ach)= 0.00\",\"attn(都,  the)= 0.00\",\"attn(都,  sell)= 0.00\",\"attn(都, -)= 0.01\",\"attn(都, off)= 0.01\",\"attn(都,  in)= 0.00\",\"attn(都,  global)= 0.00\",\"attn(都,  financial)= 0.11\",\"attn(都,  markets)= 0.14\",\"attn(都,  in)= 0.01\",\"attn(都,  January)= 0.00\",\"attn(都,  and)= 0.28\",\"attn(都,  F)= 0.00\",\"attn(都, eb)= 0.00\",\"attn(都, ru)= 0.01\",\"attn(都, ary)= 0.01\",\"attn(都, ,)= 0.04\",\"attn(都,  which)= 0.02\",\"attn(都,  was)= 0.01\",\"attn(都,  driven)= 0.03\",\"attn(都,  largely)= 0.02\",\"attn(都,  by)= 0.01\",\"attn(都,  concerns)= 0.05\",\"attn(都,  about)= 0.02\",\"attn(都,  further)= 0.09\",\"attn(都,  tight)= 0.04\",\"attn(都, ening)= 0.06\",\"attn(都, .)= 0.01\",\"attn(都, &lt;\\u002fs&gt;)= 0.01\"],[\"attn(无法, &lt;s&gt;)= 0.00\",\"attn(无法, The)= 0.00\",\"attn(无法,  Fed)= 0.00\",\"attn(无法,  apparent)= 0.00\",\"attn(无法, ly)= 0.00\",\"attn(无法,  could)= 0.00\",\"attn(无法,  not)= 0.00\",\"attn(无法,  st)= 0.00\",\"attn(无法, om)= 0.00\",\"attn(无法, ach)= 0.00\",\"attn(无法,  the)= 0.00\",\"attn(无法,  sell)= 0.00\",\"attn(无法, -)= 0.00\",\"attn(无法, off)= 0.00\",\"attn(无法,  in)= 0.00\",\"attn(无法,  global)= 0.00\",\"attn(无法,  financial)= 0.11\",\"attn(无法,  markets)= 0.11\",\"attn(无法,  in)= 0.00\",\"attn(无法,  January)= 0.00\",\"attn(无法,  and)= 0.16\",\"attn(无法,  F)= 0.00\",\"attn(无法, eb)= 0.00\",\"attn(无法, ru)= 0.00\",\"attn(无法, ary)= 0.00\",\"attn(无法, ,)= 0.01\",\"attn(无法,  which)= 0.01\",\"attn(无法,  was)= 0.00\",\"attn(无法,  driven)= 0.03\",\"attn(无法,  largely)= 0.00\",\"attn(无法,  by)= 0.01\",\"attn(无法,  concerns)= 0.07\",\"attn(无法,  about)= 0.03\",\"attn(无法,  further)= 0.16\",\"attn(无法,  tight)= 0.17\",\"attn(无法, ening)= 0.10\",\"attn(无法, .)= 0.01\",\"attn(无法, &lt;\\u002fs&gt;)= 0.01\"],[\"attn(实现, &lt;s&gt;)= 0.00\",\"attn(实现, The)= 0.00\",\"attn(实现,  Fed)= 0.00\",\"attn(实现,  apparent)= 0.00\",\"attn(实现, ly)= 0.00\",\"attn(实现,  could)= 0.00\",\"attn(实现,  not)= 0.00\",\"attn(实现,  st)= 0.00\",\"attn(实现, om)= 0.00\",\"attn(实现, ach)= 0.00\",\"attn(实现,  the)= 0.00\",\"attn(实现,  sell)= 0.00\",\"attn(实现, -)= 0.00\",\"attn(实现, off)= 0.00\",\"attn(实现,  in)= 0.00\",\"attn(实现,  global)= 0.01\",\"attn(实现,  financial)= 0.39\",\"attn(实现,  markets)= 0.23\",\"attn(实现,  in)= 0.00\",\"attn(实现,  January)= 0.00\",\"attn(实现,  and)= 0.01\",\"attn(实现,  F)= 0.00\",\"attn(实现, eb)= 0.00\",\"attn(实现, ru)= 0.00\",\"attn(实现, ary)= 0.00\",\"attn(实现, ,)= 0.00\",\"attn(实现,  which)= 0.00\",\"attn(实现,  was)= 0.00\",\"attn(实现,  driven)= 0.01\",\"attn(实现,  largely)= 0.00\",\"attn(实现,  by)= 0.00\",\"attn(实现,  concerns)= 0.01\",\"attn(实现,  about)= 0.01\",\"attn(实现,  further)= 0.06\",\"attn(实现,  tight)= 0.20\",\"attn(实现, ening)= 0.05\",\"attn(实现, .)= 0.00\",\"attn(实现, &lt;\\u002fs&gt;)= 0.01\"],[\"attn(这一, &lt;s&gt;)= 0.00\",\"attn(这一, The)= 0.00\",\"attn(这一,  Fed)= 0.00\",\"attn(这一,  apparent)= 0.00\",\"attn(这一, ly)= 0.00\",\"attn(这一,  could)= 0.00\",\"attn(这一,  not)= 0.00\",\"attn(这一,  st)= 0.00\",\"attn(这一, om)= 0.00\",\"attn(这一, ach)= 0.00\",\"attn(这一,  the)= 0.00\",\"attn(这一,  sell)= 0.00\",\"attn(这一, -)= 0.00\",\"attn(这一, off)= 0.00\",\"attn(这一,  in)= 0.00\",\"attn(这一,  global)= 0.00\",\"attn(这一,  financial)= 0.44\",\"attn(这一,  markets)= 0.41\",\"attn(这一,  in)= 0.00\",\"attn(这一,  January)= 0.00\",\"attn(这一,  and)= 0.03\",\"attn(这一,  F)= 0.00\",\"attn(这一, eb)= 0.00\",\"attn(这一, ru)= 0.00\",\"attn(这一, ary)= 0.00\",\"attn(这一, ,)= 0.00\",\"attn(这一,  which)= 0.00\",\"attn(这一,  was)= 0.00\",\"attn(这一,  driven)= 0.00\",\"attn(这一,  largely)= 0.00\",\"attn(这一,  by)= 0.00\",\"attn(这一,  concerns)= 0.01\",\"attn(这一,  about)= 0.00\",\"attn(这一,  further)= 0.03\",\"attn(这一,  tight)= 0.03\",\"attn(这一, ening)= 0.03\",\"attn(这一, .)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(政策, &lt;s&gt;)= 0.00\",\"attn(政策, The)= 0.00\",\"attn(政策,  Fed)= 0.00\",\"attn(政策,  apparent)= 0.00\",\"attn(政策, ly)= 0.00\",\"attn(政策,  could)= 0.00\",\"attn(政策,  not)= 0.00\",\"attn(政策,  st)= 0.00\",\"attn(政策, om)= 0.00\",\"attn(政策, ach)= 0.00\",\"attn(政策,  the)= 0.00\",\"attn(政策,  sell)= 0.00\",\"attn(政策, -)= 0.00\",\"attn(政策, off)= 0.00\",\"attn(政策,  in)= 0.00\",\"attn(政策,  global)= 0.00\",\"attn(政策,  financial)= 0.00\",\"attn(政策,  markets)= 0.00\",\"attn(政策,  in)= 0.00\",\"attn(政策,  January)= 0.00\",\"attn(政策,  and)= 0.04\",\"attn(政策,  F)= 0.00\",\"attn(政策, eb)= 0.00\",\"attn(政策, ru)= 0.00\",\"attn(政策, ary)= 0.00\",\"attn(政策, ,)= 0.03\",\"attn(政策,  which)= 0.00\",\"attn(政策,  was)= 0.00\",\"attn(政策,  driven)= 0.05\",\"attn(政策,  largely)= 0.01\",\"attn(政策,  by)= 0.05\",\"attn(政策,  concerns)= 0.08\",\"attn(政策,  about)= 0.11\",\"attn(政策,  further)= 0.09\",\"attn(政策,  tight)= 0.15\",\"attn(政策, ening)= 0.06\",\"attn(政策, .)= 0.16\",\"attn(政策, &lt;\\u002fs&gt;)= 0.14\"],[\"attn(，, &lt;s&gt;)= 0.00\",\"attn(，, The)= 0.00\",\"attn(，,  Fed)= 0.00\",\"attn(，,  apparent)= 0.00\",\"attn(，, ly)= 0.00\",\"attn(，,  could)= 0.00\",\"attn(，,  not)= 0.00\",\"attn(，,  st)= 0.00\",\"attn(，, om)= 0.00\",\"attn(，, ach)= 0.00\",\"attn(，,  the)= 0.00\",\"attn(，,  sell)= 0.00\",\"attn(，, -)= 0.00\",\"attn(，, off)= 0.00\",\"attn(，,  in)= 0.00\",\"attn(，,  global)= 0.00\",\"attn(，,  financial)= 0.08\",\"attn(，,  markets)= 0.06\",\"attn(，,  in)= 0.00\",\"attn(，,  January)= 0.00\",\"attn(，,  and)= 0.50\",\"attn(，,  F)= 0.00\",\"attn(，, eb)= 0.00\",\"attn(，, ru)= 0.00\",\"attn(，, ary)= 0.00\",\"attn(，, ,)= 0.06\",\"attn(，,  which)= 0.00\",\"attn(，,  was)= 0.00\",\"attn(，,  driven)= 0.01\",\"attn(，,  largely)= 0.00\",\"attn(，,  by)= 0.01\",\"attn(，,  concerns)= 0.03\",\"attn(，,  about)= 0.02\",\"attn(，,  further)= 0.07\",\"attn(，,  tight)= 0.12\",\"attn(，, ening)= 0.03\",\"attn(，, .)= 0.01\",\"attn(，, &lt;\\u002fs&gt;)= 0.01\"],[\"attn(而, &lt;s&gt;)= 0.00\",\"attn(而, The)= 0.00\",\"attn(而,  Fed)= 0.00\",\"attn(而,  apparent)= 0.00\",\"attn(而, ly)= 0.00\",\"attn(而,  could)= 0.00\",\"attn(而,  not)= 0.00\",\"attn(而,  st)= 0.00\",\"attn(而, om)= 0.00\",\"attn(而, ach)= 0.00\",\"attn(而,  the)= 0.00\",\"attn(而,  sell)= 0.00\",\"attn(而, -)= 0.00\",\"attn(而, off)= 0.00\",\"attn(而,  in)= 0.00\",\"attn(而,  global)= 0.09\",\"attn(而,  financial)= 0.51\",\"attn(而,  markets)= 0.27\",\"attn(而,  in)= 0.02\",\"attn(而,  January)= 0.00\",\"attn(而,  and)= 0.01\",\"attn(而,  F)= 0.01\",\"attn(而, eb)= 0.00\",\"attn(而, ru)= 0.00\",\"attn(而, ary)= 0.00\",\"attn(而, ,)= 0.00\",\"attn(而,  which)= 0.00\",\"attn(而,  was)= 0.00\",\"attn(而,  driven)= 0.00\",\"attn(而,  largely)= 0.00\",\"attn(而,  by)= 0.00\",\"attn(而,  concerns)= 0.00\",\"attn(而,  about)= 0.00\",\"attn(而,  further)= 0.02\",\"attn(而,  tight)= 0.04\",\"attn(而, ening)= 0.01\",\"attn(而, .)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(危机, &lt;s&gt;)= 0.00\",\"attn(危机, The)= 0.00\",\"attn(危机,  Fed)= 0.00\",\"attn(危机,  apparent)= 0.00\",\"attn(危机, ly)= 0.00\",\"attn(危机,  could)= 0.00\",\"attn(危机,  not)= 0.00\",\"attn(危机,  st)= 0.00\",\"attn(危机, om)= 0.00\",\"attn(危机, ach)= 0.00\",\"attn(危机,  the)= 0.00\",\"attn(危机,  sell)= 0.00\",\"attn(危机, -)= 0.00\",\"attn(危机, off)= 0.00\",\"attn(危机,  in)= 0.00\",\"attn(危机,  global)= 0.00\",\"attn(危机,  financial)= 0.00\",\"attn(危机,  markets)= 0.00\",\"attn(危机,  in)= 0.00\",\"attn(危机,  January)= 0.00\",\"attn(危机,  and)= 0.00\",\"attn(危机,  F)= 0.00\",\"attn(危机, eb)= 0.00\",\"attn(危机, ru)= 0.00\",\"attn(危机, ary)= 0.00\",\"attn(危机, ,)= 0.03\",\"attn(危机,  which)= 0.00\",\"attn(危机,  was)= 0.00\",\"attn(危机,  driven)= 0.05\",\"attn(危机,  largely)= 0.01\",\"attn(危机,  by)= 0.07\",\"attn(危机,  concerns)= 0.06\",\"attn(危机,  about)= 0.13\",\"attn(危机,  further)= 0.04\",\"attn(危机,  tight)= 0.10\",\"attn(危机, ening)= 0.02\",\"attn(危机, .)= 0.29\",\"attn(危机, &lt;\\u002fs&gt;)= 0.19\"],[\"attn(上, &lt;s&gt;)= 0.00\",\"attn(上, The)= 0.00\",\"attn(上,  Fed)= 0.00\",\"attn(上,  apparent)= 0.00\",\"attn(上, ly)= 0.00\",\"attn(上,  could)= 0.00\",\"attn(上,  not)= 0.00\",\"attn(上,  st)= 0.00\",\"attn(上, om)= 0.00\",\"attn(上, ach)= 0.00\",\"attn(上,  the)= 0.00\",\"attn(上,  sell)= 0.00\",\"attn(上, -)= 0.00\",\"attn(上, off)= 0.00\",\"attn(上,  in)= 0.00\",\"attn(上,  global)= 0.00\",\"attn(上,  financial)= 0.11\",\"attn(上,  markets)= 0.11\",\"attn(上,  in)= 0.00\",\"attn(上,  January)= 0.00\",\"attn(上,  and)= 0.04\",\"attn(上,  F)= 0.00\",\"attn(上, eb)= 0.00\",\"attn(上, ru)= 0.01\",\"attn(上, ary)= 0.01\",\"attn(上, ,)= 0.02\",\"attn(上,  which)= 0.01\",\"attn(上,  was)= 0.00\",\"attn(上,  driven)= 0.03\",\"attn(上,  largely)= 0.01\",\"attn(上,  by)= 0.02\",\"attn(上,  concerns)= 0.05\",\"attn(上,  about)= 0.04\",\"attn(上,  further)= 0.19\",\"attn(上,  tight)= 0.19\",\"attn(上, ening)= 0.11\",\"attn(上, .)= 0.02\",\"attn(上, &lt;\\u002fs&gt;)= 0.02\"],[\"attn(就, &lt;s&gt;)= 0.00\",\"attn(就, The)= 0.00\",\"attn(就,  Fed)= 0.00\",\"attn(就,  apparent)= 0.00\",\"attn(就, ly)= 0.00\",\"attn(就,  could)= 0.00\",\"attn(就,  not)= 0.00\",\"attn(就,  st)= 0.00\",\"attn(就, om)= 0.00\",\"attn(就, ach)= 0.00\",\"attn(就,  the)= 0.00\",\"attn(就,  sell)= 0.00\",\"attn(就, -)= 0.00\",\"attn(就, off)= 0.00\",\"attn(就,  in)= 0.00\",\"attn(就,  global)= 0.00\",\"attn(就,  financial)= 0.01\",\"attn(就,  markets)= 0.01\",\"attn(就,  in)= 0.00\",\"attn(就,  January)= 0.00\",\"attn(就,  and)= 0.01\",\"attn(就,  F)= 0.00\",\"attn(就, eb)= 0.00\",\"attn(就, ru)= 0.01\",\"attn(就, ary)= 0.00\",\"attn(就, ,)= 0.01\",\"attn(就,  which)= 0.01\",\"attn(就,  was)= 0.00\",\"attn(就,  driven)= 0.05\",\"attn(就,  largely)= 0.01\",\"attn(就,  by)= 0.04\",\"attn(就,  concerns)= 0.08\",\"attn(就,  about)= 0.09\",\"attn(就,  further)= 0.15\",\"attn(就,  tight)= 0.32\",\"attn(就, ening)= 0.10\",\"attn(就, .)= 0.04\",\"attn(就, &lt;\\u002fs&gt;)= 0.05\"],[\"attn(需要, &lt;s&gt;)= 0.00\",\"attn(需要, The)= 0.00\",\"attn(需要,  Fed)= 0.00\",\"attn(需要,  apparent)= 0.00\",\"attn(需要, ly)= 0.00\",\"attn(需要,  could)= 0.00\",\"attn(需要,  not)= 0.00\",\"attn(需要,  st)= 0.00\",\"attn(需要, om)= 0.00\",\"attn(需要, ach)= 0.00\",\"attn(需要,  the)= 0.00\",\"attn(需要,  sell)= 0.00\",\"attn(需要, -)= 0.00\",\"attn(需要, off)= 0.00\",\"attn(需要,  in)= 0.00\",\"attn(需要,  global)= 0.00\",\"attn(需要,  financial)= 0.02\",\"attn(需要,  markets)= 0.01\",\"attn(需要,  in)= 0.00\",\"attn(需要,  January)= 0.00\",\"attn(需要,  and)= 0.00\",\"attn(需要,  F)= 0.00\",\"attn(需要, eb)= 0.00\",\"attn(需要, ru)= 0.00\",\"attn(需要, ary)= 0.00\",\"attn(需要, ,)= 0.00\",\"attn(需要,  which)= 0.00\",\"attn(需要,  was)= 0.00\",\"attn(需要,  driven)= 0.01\",\"attn(需要,  largely)= 0.00\",\"attn(需要,  by)= 0.01\",\"attn(需要,  concerns)= 0.03\",\"attn(需要,  about)= 0.03\",\"attn(需要,  further)= 0.08\",\"attn(需要,  tight)= 0.73\",\"attn(需要, ening)= 0.05\",\"attn(需要, .)= 0.01\",\"attn(需要, &lt;\\u002fs&gt;)= 0.02\"],[\"attn(解决, &lt;s&gt;)= 0.00\",\"attn(解决, The)= 0.00\",\"attn(解决,  Fed)= 0.00\",\"attn(解决,  apparent)= 0.00\",\"attn(解决, ly)= 0.00\",\"attn(解决,  could)= 0.00\",\"attn(解决,  not)= 0.00\",\"attn(解决,  st)= 0.00\",\"attn(解决, om)= 0.00\",\"attn(解决, ach)= 0.00\",\"attn(解决,  the)= 0.00\",\"attn(解决,  sell)= 0.00\",\"attn(解决, -)= 0.00\",\"attn(解决, off)= 0.00\",\"attn(解决,  in)= 0.00\",\"attn(解决,  global)= 0.00\",\"attn(解决,  financial)= 0.04\",\"attn(解决,  markets)= 0.02\",\"attn(解决,  in)= 0.00\",\"attn(解决,  January)= 0.00\",\"attn(解决,  and)= 0.00\",\"attn(解决,  F)= 0.00\",\"attn(解决, eb)= 0.00\",\"attn(解决, ru)= 0.00\",\"attn(解决, ary)= 0.00\",\"attn(解决, ,)= 0.00\",\"attn(解决,  which)= 0.00\",\"attn(解决,  was)= 0.00\",\"attn(解决,  driven)= 0.02\",\"attn(解决,  largely)= 0.00\",\"attn(解决,  by)= 0.01\",\"attn(解决,  concerns)= 0.03\",\"attn(解决,  about)= 0.04\",\"attn(解决,  further)= 0.08\",\"attn(解决,  tight)= 0.64\",\"attn(解决, ening)= 0.06\",\"attn(解决, .)= 0.02\",\"attn(解决, &lt;\\u002fs&gt;)= 0.04\"],[\"attn(。, &lt;s&gt;)= 0.00\",\"attn(。, The)= 0.00\",\"attn(。,  Fed)= 0.00\",\"attn(。,  apparent)= 0.00\",\"attn(。, ly)= 0.00\",\"attn(。,  could)= 0.00\",\"attn(。,  not)= 0.00\",\"attn(。,  st)= 0.00\",\"attn(。, om)= 0.00\",\"attn(。, ach)= 0.00\",\"attn(。,  the)= 0.00\",\"attn(。,  sell)= 0.00\",\"attn(。, -)= 0.00\",\"attn(。, off)= 0.00\",\"attn(。,  in)= 0.00\",\"attn(。,  global)= 0.00\",\"attn(。,  financial)= 0.00\",\"attn(。,  markets)= 0.00\",\"attn(。,  in)= 0.00\",\"attn(。,  January)= 0.00\",\"attn(。,  and)= 0.00\",\"attn(。,  F)= 0.00\",\"attn(。, eb)= 0.00\",\"attn(。, ru)= 0.00\",\"attn(。, ary)= 0.00\",\"attn(。, ,)= 0.01\",\"attn(。,  which)= 0.00\",\"attn(。,  was)= 0.00\",\"attn(。,  driven)= 0.02\",\"attn(。,  largely)= 0.00\",\"attn(。,  by)= 0.05\",\"attn(。,  concerns)= 0.02\",\"attn(。,  about)= 0.12\",\"attn(。,  further)= 0.01\",\"attn(。,  tight)= 0.06\",\"attn(。, ening)= 0.01\",\"attn(。, .)= 0.37\",\"attn(。, &lt;\\u002fs&gt;)= 0.33\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.02\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.05\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.02\",\"attn(&lt;\\u002fs&gt;,  about)= 0.14\",\"attn(&lt;\\u002fs&gt;,  further)= 0.01\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.13\",\"attn(&lt;\\u002fs&gt;, ening)= 0.01\",\"attn(&lt;\\u002fs&gt;, .)= 0.26\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.35\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.02\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.05\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.03\",\"attn(&lt;\\u002fs&gt;,  about)= 0.14\",\"attn(&lt;\\u002fs&gt;,  further)= 0.01\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.15\",\"attn(&lt;\\u002fs&gt;, ening)= 0.01\",\"attn(&lt;\\u002fs&gt;, .)= 0.24\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.35\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.02\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.05\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.02\",\"attn(&lt;\\u002fs&gt;,  about)= 0.14\",\"attn(&lt;\\u002fs&gt;,  further)= 0.01\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.15\",\"attn(&lt;\\u002fs&gt;, ening)= 0.01\",\"attn(&lt;\\u002fs&gt;, .)= 0.24\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.36\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.02\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.05\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.02\",\"attn(&lt;\\u002fs&gt;,  about)= 0.14\",\"attn(&lt;\\u002fs&gt;,  further)= 0.01\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.16\",\"attn(&lt;\\u002fs&gt;, ening)= 0.01\",\"attn(&lt;\\u002fs&gt;, .)= 0.23\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.36\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.02\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.04\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.02\",\"attn(&lt;\\u002fs&gt;,  about)= 0.14\",\"attn(&lt;\\u002fs&gt;,  further)= 0.01\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.18\",\"attn(&lt;\\u002fs&gt;, ening)= 0.01\",\"attn(&lt;\\u002fs&gt;, .)= 0.21\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.36\"],[\"attn(。, &lt;s&gt;)= 0.00\",\"attn(。, The)= 0.00\",\"attn(。,  Fed)= 0.00\",\"attn(。,  apparent)= 0.00\",\"attn(。, ly)= 0.00\",\"attn(。,  could)= 0.00\",\"attn(。,  not)= 0.00\",\"attn(。,  st)= 0.00\",\"attn(。, om)= 0.00\",\"attn(。, ach)= 0.00\",\"attn(。,  the)= 0.00\",\"attn(。,  sell)= 0.00\",\"attn(。, -)= 0.00\",\"attn(。, off)= 0.00\",\"attn(。,  in)= 0.00\",\"attn(。,  global)= 0.00\",\"attn(。,  financial)= 0.00\",\"attn(。,  markets)= 0.00\",\"attn(。,  in)= 0.00\",\"attn(。,  January)= 0.00\",\"attn(。,  and)= 0.00\",\"attn(。,  F)= 0.00\",\"attn(。, eb)= 0.00\",\"attn(。, ru)= 0.00\",\"attn(。, ary)= 0.00\",\"attn(。, ,)= 0.00\",\"attn(。,  which)= 0.00\",\"attn(。,  was)= 0.00\",\"attn(。,  driven)= 0.02\",\"attn(。,  largely)= 0.00\",\"attn(。,  by)= 0.05\",\"attn(。,  concerns)= 0.02\",\"attn(。,  about)= 0.12\",\"attn(。,  further)= 0.01\",\"attn(。,  tight)= 0.06\",\"attn(。, ening)= 0.01\",\"attn(。, .)= 0.37\",\"attn(。, &lt;\\u002fs&gt;)= 0.35\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.05\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.02\",\"attn(&lt;\\u002fs&gt;,  about)= 0.12\",\"attn(&lt;\\u002fs&gt;,  further)= 0.01\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.08\",\"attn(&lt;\\u002fs&gt;, ening)= 0.01\",\"attn(&lt;\\u002fs&gt;, .)= 0.31\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.39\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.05\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.02\",\"attn(&lt;\\u002fs&gt;,  about)= 0.12\",\"attn(&lt;\\u002fs&gt;,  further)= 0.01\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.07\",\"attn(&lt;\\u002fs&gt;, ening)= 0.01\",\"attn(&lt;\\u002fs&gt;, .)= 0.31\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.40\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.04\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.02\",\"attn(&lt;\\u002fs&gt;,  about)= 0.12\",\"attn(&lt;\\u002fs&gt;,  further)= 0.00\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.08\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.29\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.42\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.04\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.01\",\"attn(&lt;\\u002fs&gt;,  about)= 0.13\",\"attn(&lt;\\u002fs&gt;,  further)= 0.00\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.10\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.27\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.44\"],[\"attn(。, &lt;s&gt;)= 0.00\",\"attn(。, The)= 0.00\",\"attn(。,  Fed)= 0.00\",\"attn(。,  apparent)= 0.00\",\"attn(。, ly)= 0.00\",\"attn(。,  could)= 0.00\",\"attn(。,  not)= 0.00\",\"attn(。,  st)= 0.00\",\"attn(。, om)= 0.00\",\"attn(。, ach)= 0.00\",\"attn(。,  the)= 0.00\",\"attn(。,  sell)= 0.00\",\"attn(。, -)= 0.00\",\"attn(。, off)= 0.00\",\"attn(。,  in)= 0.00\",\"attn(。,  global)= 0.00\",\"attn(。,  financial)= 0.00\",\"attn(。,  markets)= 0.00\",\"attn(。,  in)= 0.00\",\"attn(。,  January)= 0.00\",\"attn(。,  and)= 0.00\",\"attn(。,  F)= 0.00\",\"attn(。, eb)= 0.00\",\"attn(。, ru)= 0.00\",\"attn(。, ary)= 0.00\",\"attn(。, ,)= 0.00\",\"attn(。,  which)= 0.00\",\"attn(。,  was)= 0.00\",\"attn(。,  driven)= 0.02\",\"attn(。,  largely)= 0.00\",\"attn(。,  by)= 0.06\",\"attn(。,  concerns)= 0.02\",\"attn(。,  about)= 0.11\",\"attn(。,  further)= 0.01\",\"attn(。,  tight)= 0.05\",\"attn(。, ening)= 0.00\",\"attn(。, .)= 0.38\",\"attn(。, &lt;\\u002fs&gt;)= 0.36\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.05\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.01\",\"attn(&lt;\\u002fs&gt;,  about)= 0.11\",\"attn(&lt;\\u002fs&gt;,  further)= 0.00\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.04\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.35\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.41\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.04\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.01\",\"attn(&lt;\\u002fs&gt;,  about)= 0.11\",\"attn(&lt;\\u002fs&gt;,  further)= 0.00\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.04\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.34\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.43\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.04\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.01\",\"attn(&lt;\\u002fs&gt;,  about)= 0.11\",\"attn(&lt;\\u002fs&gt;,  further)= 0.00\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.06\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.31\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.45\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.04\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.01\",\"attn(&lt;\\u002fs&gt;,  about)= 0.12\",\"attn(&lt;\\u002fs&gt;,  further)= 0.00\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.06\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.30\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.46\"],[\"attn(。, &lt;s&gt;)= 0.00\",\"attn(。, The)= 0.00\",\"attn(。,  Fed)= 0.00\",\"attn(。,  apparent)= 0.00\",\"attn(。, ly)= 0.00\",\"attn(。,  could)= 0.00\",\"attn(。,  not)= 0.00\",\"attn(。,  st)= 0.00\",\"attn(。, om)= 0.00\",\"attn(。, ach)= 0.00\",\"attn(。,  the)= 0.00\",\"attn(。,  sell)= 0.00\",\"attn(。, -)= 0.00\",\"attn(。, off)= 0.00\",\"attn(。,  in)= 0.00\",\"attn(。,  global)= 0.00\",\"attn(。,  financial)= 0.00\",\"attn(。,  markets)= 0.00\",\"attn(。,  in)= 0.00\",\"attn(。,  January)= 0.00\",\"attn(。,  and)= 0.00\",\"attn(。,  F)= 0.00\",\"attn(。, eb)= 0.00\",\"attn(。, ru)= 0.00\",\"attn(。, ary)= 0.00\",\"attn(。, ,)= 0.00\",\"attn(。,  which)= 0.00\",\"attn(。,  was)= 0.00\",\"attn(。,  driven)= 0.02\",\"attn(。,  largely)= 0.00\",\"attn(。,  by)= 0.05\",\"attn(。,  concerns)= 0.01\",\"attn(。,  about)= 0.11\",\"attn(。,  further)= 0.01\",\"attn(。,  tight)= 0.05\",\"attn(。, ening)= 0.00\",\"attn(。, .)= 0.38\",\"attn(。, &lt;\\u002fs&gt;)= 0.37\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.05\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.01\",\"attn(&lt;\\u002fs&gt;,  about)= 0.11\",\"attn(&lt;\\u002fs&gt;,  further)= 0.00\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.04\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.37\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.41\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.05\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.01\",\"attn(&lt;\\u002fs&gt;,  about)= 0.11\",\"attn(&lt;\\u002fs&gt;,  further)= 0.00\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.04\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.35\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.42\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.05\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.01\",\"attn(&lt;\\u002fs&gt;,  about)= 0.11\",\"attn(&lt;\\u002fs&gt;,  further)= 0.00\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.05\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.33\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.43\"],[\"attn(&lt;\\u002fs&gt;, &lt;s&gt;)= 0.00\",\"attn(&lt;\\u002fs&gt;, The)= 0.00\",\"attn(&lt;\\u002fs&gt;,  Fed)= 0.00\",\"attn(&lt;\\u002fs&gt;,  apparent)= 0.00\",\"attn(&lt;\\u002fs&gt;, ly)= 0.00\",\"attn(&lt;\\u002fs&gt;,  could)= 0.00\",\"attn(&lt;\\u002fs&gt;,  not)= 0.00\",\"attn(&lt;\\u002fs&gt;,  st)= 0.00\",\"attn(&lt;\\u002fs&gt;, om)= 0.00\",\"attn(&lt;\\u002fs&gt;, ach)= 0.00\",\"attn(&lt;\\u002fs&gt;,  the)= 0.00\",\"attn(&lt;\\u002fs&gt;,  sell)= 0.00\",\"attn(&lt;\\u002fs&gt;, -)= 0.00\",\"attn(&lt;\\u002fs&gt;, off)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  global)= 0.00\",\"attn(&lt;\\u002fs&gt;,  financial)= 0.00\",\"attn(&lt;\\u002fs&gt;,  markets)= 0.00\",\"attn(&lt;\\u002fs&gt;,  in)= 0.00\",\"attn(&lt;\\u002fs&gt;,  January)= 0.00\",\"attn(&lt;\\u002fs&gt;,  and)= 0.00\",\"attn(&lt;\\u002fs&gt;,  F)= 0.00\",\"attn(&lt;\\u002fs&gt;, eb)= 0.00\",\"attn(&lt;\\u002fs&gt;, ru)= 0.00\",\"attn(&lt;\\u002fs&gt;, ary)= 0.00\",\"attn(&lt;\\u002fs&gt;, ,)= 0.00\",\"attn(&lt;\\u002fs&gt;,  which)= 0.00\",\"attn(&lt;\\u002fs&gt;,  was)= 0.00\",\"attn(&lt;\\u002fs&gt;,  driven)= 0.01\",\"attn(&lt;\\u002fs&gt;,  largely)= 0.00\",\"attn(&lt;\\u002fs&gt;,  by)= 0.04\",\"attn(&lt;\\u002fs&gt;,  concerns)= 0.01\",\"attn(&lt;\\u002fs&gt;,  about)= 0.11\",\"attn(&lt;\\u002fs&gt;,  further)= 0.00\",\"attn(&lt;\\u002fs&gt;,  tight)= 0.06\",\"attn(&lt;\\u002fs&gt;, ening)= 0.00\",\"attn(&lt;\\u002fs&gt;, .)= 0.32\",\"attn(&lt;\\u002fs&gt;, &lt;\\u002fs&gt;)= 0.44\"]],\"x\":[\"\\u003cspan style='font-size: 10px;color:grey'\\u003e000\\u003c\\u002fspan\\u003e  &lt;s&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e001\\u003c\\u002fspan\\u003e  The\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e002\\u003c\\u002fspan\\u003e   Fed\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e003\\u003c\\u002fspan\\u003e   apparent\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e004\\u003c\\u002fspan\\u003e  ly\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e005\\u003c\\u002fspan\\u003e   could\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e006\\u003c\\u002fspan\\u003e   not\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e007\\u003c\\u002fspan\\u003e   st\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e008\\u003c\\u002fspan\\u003e  om\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e009\\u003c\\u002fspan\\u003e  ach\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e010\\u003c\\u002fspan\\u003e   the\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e011\\u003c\\u002fspan\\u003e   sell\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e012\\u003c\\u002fspan\\u003e  -\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e013\\u003c\\u002fspan\\u003e  off\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e014\\u003c\\u002fspan\\u003e   in\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e015\\u003c\\u002fspan\\u003e   global\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e016\\u003c\\u002fspan\\u003e   financial\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e017\\u003c\\u002fspan\\u003e   markets\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e018\\u003c\\u002fspan\\u003e   in\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e019\\u003c\\u002fspan\\u003e   January\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e020\\u003c\\u002fspan\\u003e   and\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e021\\u003c\\u002fspan\\u003e   F\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e022\\u003c\\u002fspan\\u003e  eb\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e023\\u003c\\u002fspan\\u003e  ru\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e024\\u003c\\u002fspan\\u003e  ary\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e025\\u003c\\u002fspan\\u003e  ,\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e026\\u003c\\u002fspan\\u003e   which\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e027\\u003c\\u002fspan\\u003e   was\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e028\\u003c\\u002fspan\\u003e   driven\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e029\\u003c\\u002fspan\\u003e   largely\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e030\\u003c\\u002fspan\\u003e   by\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e031\\u003c\\u002fspan\\u003e   concerns\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e032\\u003c\\u002fspan\\u003e   about\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e033\\u003c\\u002fspan\\u003e   further\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e034\\u003c\\u002fspan\\u003e   tight\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e035\\u003c\\u002fspan\\u003e  ening\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e036\\u003c\\u002fspan\\u003e  .\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e037\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\"],\"xgap\":1,\"y\":[\"\\u003cspan style='font-size: 10px;color:grey'\\u003e000\\u003c\\u002fspan\\u003e  &lt;s&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e001\\u003c\\u002fspan\\u003e  美联储\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e002\\u003c\\u002fspan\\u003e  还\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e003\\u003c\\u002fspan\\u003e  不是\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e004\\u003c\\u002fspan\\u003e  在\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e005\\u003c\\u002fspan\\u003e  2008\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e006\\u003c\\u002fspan\\u003e  年\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e007\\u003c\\u002fspan\\u003e  金融危机\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e008\\u003c\\u002fspan\\u003e  中\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e009\\u003c\\u002fspan\\u003e  ，\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e010\\u003c\\u002fspan\\u003e  欧洲\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e011\\u003c\\u002fspan\\u003e  银行\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e012\\u003c\\u002fspan\\u003e  和\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e013\\u003c\\u002fspan\\u003e  银行\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e014\\u003c\\u002fspan\\u003e  和\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e015\\u003c\\u002fspan\\u003e  银行\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e016\\u003c\\u002fspan\\u003e  都\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e017\\u003c\\u002fspan\\u003e  无法\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e018\\u003c\\u002fspan\\u003e  实现\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e019\\u003c\\u002fspan\\u003e  这一\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e020\\u003c\\u002fspan\\u003e  政策\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e021\\u003c\\u002fspan\\u003e  ，\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e022\\u003c\\u002fspan\\u003e  而\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e023\\u003c\\u002fspan\\u003e  危机\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e024\\u003c\\u002fspan\\u003e  上\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e025\\u003c\\u002fspan\\u003e  就\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e026\\u003c\\u002fspan\\u003e  需要\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e027\\u003c\\u002fspan\\u003e  解决\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e028\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e029\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e030\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e031\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e032\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e033\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e034\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e035\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e036\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e037\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e038\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e039\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e040\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e041\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e042\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e043\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e044\\u003c\\u002fspan\\u003e  。\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e045\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e046\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e047\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e048\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\"],\"ygap\":1,\"z\":[[0.04884824,0.00026909573,0.89707696,0.00028233742,0.000051164818,0.0000025600002,0.0000012251136,0.000010721435,0.0000051367,0.0000044637277,0.0000032433302,0.00011105217,0.00014019421,0.00004912009,0.0016250712,0.049691126,0.00013691891,0.00008130906,0.00049325253,0.00043815264,0.000008967429,0.00016706367,0.00049546844,6.727373e-7,0.0000042854363,1.8368004e-7,0.0000014178361,3.6732e-7,2.005303e-8,1.1003375e-7,6.3042154e-9,1.3858968e-8,2.890864e-9,4.317692e-8,6.1051644e-9,3.789946e-8,8.175345e-10,8.756907e-10],[5.420921e-7,0.0000025514582,0.000010973556,0.0015437871,0.0008938896,0.008982817,0.008770204,0.005634072,0.0051052826,0.011577355,0.010737224,0.027493056,0.20433004,0.011267729,0.10920855,0.13382196,0.069041975,0.08364802,0.010277021,0.00012323052,0.2933986,0.0011175837,0.00014606897,0.00023070499,0.0005283222,0.0009603957,0.0005832014,0.00033750376,0.000009031069,0.00012983604,0.0000022726883,0.000011750596,0.0000012980831,0.000040687297,0.0000014943281,0.000029564471,8.8132657e-7,4.7286082e-7],[0.000011929244,0.000011207,0.00022358917,0.0031886431,0.0014754226,0.010158974,0.009002566,0.010865487,0.007868348,0.017202118,0.014730307,0.07242342,0.15917094,0.035446335,0.2262344,0.19941369,0.041746076,0.049928885,0.048295498,0.0005912284,0.08064775,0.0034817122,0.00082865206,0.0009545471,0.0019791804,0.0004551677,0.002006351,0.0011577269,0.000021253827,0.0003159223,0.000005816844,0.00002818063,0.000003063008,0.00006998466,0.0000026121731,0.000051195035,0.0000010536845,7.694723e-7],[4.8683646e-8,1.664331e-10,0.000004867427,1.5323977e-9,1.1135564e-9,1.7005944e-11,1.02313704e-11,9.7984184e-8,6.483156e-8,8.204334e-7,8.202738e-7,0.000024599512,0.0011572455,0.000094945215,0.0036814031,0.90557635,0.055330772,0.03096136,0.002911974,0.0000059454674,0.00018469772,0.000035879908,0.000011619253,8.4224683e-7,0.000009740394,1.3171726e-7,0.0000044284375,1.7760131e-7,2.9342402e-8,1.7099812e-7,3.6150865e-9,5.0035208e-8,3.235682e-9,4.860249e-7,3.7385327e-8,3.6333984e-7,2.500116e-10,3.7919015e-10],[0.0000050947697,9.62773e-9,0.0014176955,1.5832262e-8,1.2919721e-8,1.1803489e-10,1.01403504e-10,3.2505477e-7,2.1789873e-7,0.0000013947865,0.0000016603908,0.000037933416,0.0007612971,0.0001002531,0.005720815,0.9152375,0.038506962,0.018523654,0.010617892,0.0027404018,0.000051831234,0.0027173364,0.0034330764,0.0000073626115,0.00009632259,8.9593067e-7,0.000013064283,0.00000106782,2.1609912e-7,7.1585646e-7,5.248045e-8,3.272779e-7,4.5170445e-8,0.0000023052266,5.776883e-7,0.0000018188358,5.216765e-9,8.0379206e-9],[1.6557662e-7,3.7087933e-8,0.000009897504,0.000003389097,0.0000032461965,0.0000011608487,0.0000013922747,0.00010246437,0.00009718245,0.00045765706,0.0010545097,0.003628829,0.07486821,0.006749252,0.10479582,0.5641701,0.06498734,0.07114535,0.06412825,0.0043675583,0.020889163,0.0065655606,0.004980854,0.0009845614,0.0024669457,0.00061231,0.0019831033,0.0003957237,0.000027046002,0.00019641995,0.0000053853587,0.000021296764,0.0000032471255,0.00017444113,0.000013624302,0.00010495218,0.0000024560125,0.0000010353989],[6.190843e-10,1.8352633e-10,3.621057e-8,1.6937726e-8,2.968969e-8,3.1283886e-8,3.6291397e-8,0.0000057523307,0.0000067123665,0.0000930739,0.00014056031,0.00026553762,0.023364348,0.00079582277,0.011178586,0.113546304,0.3702235,0.32226983,0.0051090936,0.00002670004,0.15102093,0.000469599,0.00003832973,0.00008024481,0.00033454702,0.0005711835,0.00018916569,0.000034474804,0.000007533031,0.000027507318,0.0000014337772,0.000014397079,0.0000015333543,0.00010731912,0.000010290691,0.00006435645,7.2407465e-7,4.857921e-7],[2.1581101e-9,2.2124143e-8,9.690421e-10,0.000002397185,0.0000046413857,0.00023203046,0.00020811737,0.00033538297,0.00050390325,0.002726279,0.0055263126,0.0010213354,0.008623343,0.004395636,0.001641087,0.00015280656,0.0035750244,0.005902307,0.0012515226,0.0000011559242,0.85355103,0.00004189883,0.0000024123715,0.005382277,0.0017868262,0.05045597,0.008753746,0.00789441,0.0036670147,0.006639789,0.0019063578,0.004755799,0.0018401787,0.0075073093,0.0013168635,0.004168084,0.0029441891,0.0012825647],[3.616097e-9,1.15951e-9,5.4222195e-8,6.448951e-8,9.1533686e-8,2.5815396e-7,2.2610686e-7,0.000014632678,0.000015891652,0.00017669352,0.00022546272,0.00046618117,0.015660422,0.001901369,0.0068372916,0.044254493,0.42244467,0.40666965,0.0045285965,0.0000122084675,0.094106376,0.0002535608,0.000021072787,0.00017197392,0.0004721638,0.00040735258,0.0005210144,0.00010387554,0.000027247308,0.000086000204,0.000005220827,0.00004680944,0.0000052145324,0.00032141557,0.000025102163,0.0002140083,0.0000018336807,0.0000014860849],[1.971676e-7,1.2704519e-9,0.0000058806395,5.8044196e-9,6.9437878e-9,4.9824753e-9,2.8970704e-9,0.000001075115,9.957907e-7,0.000019987243,0.000021920083,0.000094927265,0.004607066,0.0007031918,0.0060543325,0.19317141,0.39669555,0.25056285,0.007718578,0.000026942678,0.13793178,0.0006335928,0.000056053635,0.00008163887,0.00041801872,0.0006015177,0.00018150797,0.00002494294,0.000016889828,0.000018846602,0.0000043310406,0.000038228827,0.0000053360623,0.00016737923,0.000036041805,0.00009628248,0.0000011918634,0.0000014482563],[2.950831e-11,3.013545e-11,2.8209124e-10,1.0715338e-9,3.193644e-9,1.5421797e-8,1.4382456e-8,0.0000012068687,0.0000018774815,0.00003407215,0.000038920043,0.000025091815,0.0024528685,0.00021937909,0.00032635184,0.0024837924,0.39197105,0.39292693,0.0003664936,7.054132e-7,0.203603,0.000036865167,0.0000012083106,0.0000768205,0.00016352993,0.0019315849,0.0001962702,0.00004369197,0.000094343515,0.00008516913,0.000027968672,0.00022014994,0.000045192497,0.0013700437,0.00032722636,0.00088668667,0.000022374403,0.000019061685],[2.0630447e-10,3.4384569e-9,2.7220817e-10,3.4684243e-7,7.859352e-7,0.000120044184,0.00010970939,0.00007083323,0.00011187279,0.0007822841,0.00082553056,0.00018464786,0.0029927448,0.00074747874,0.00023573772,0.00008909677,0.029444324,0.04315621,0.00016885038,3.257581e-7,0.8741609,0.000023193461,5.614774e-7,0.00054325187,0.00035969133,0.027132886,0.0010194214,0.0008863706,0.0011273769,0.0011415726,0.00059018325,0.0023534857,0.0007966391,0.0049731764,0.0011150473,0.0033431756,0.00083619973,0.00055605674],[1.4184558e-8,3.123829e-10,5.912367e-7,4.0453424e-10,1.1364806e-9,1.6477725e-10,1.4921918e-10,2.1912318e-7,2.4321253e-7,0.0000041445787,0.0000037318234,0.000010948164,0.00063114404,0.00008159502,0.00040082543,0.03116406,0.61461836,0.34706438,0.0010479862,0.000032837965,0.0032132203,0.00039138237,0.000048577207,0.000027143213,0.0001919451,0.00007431444,0.000049275885,0.000006744416,0.000022974538,0.000014289643,0.000008058118,0.00005936453,0.000014197898,0.0003142085,0.00022315957,0.0002727091,0.0000025170982,0.0000048183438],[7.654387e-10,1.6240392e-8,3.3776779e-10,3.7349517e-7,0.0000012522214,0.00010260618,0.000095741874,0.00009144104,0.00016489599,0.0009642403,0.0011297638,0.00015543819,0.0021892337,0.0009960466,0.00011206988,0.000045570145,0.04390987,0.062285785,0.00014388877,5.186733e-7,0.5225959,0.000026488135,8.9520057e-7,0.0019785247,0.0009605268,0.07179765,0.0035172526,0.0031895079,0.018064847,0.007727437,0.012841256,0.03458253,0.021807017,0.060727052,0.03512709,0.047461502,0.024848573,0.02035722],[1.2619282e-8,2.7747638e-10,3.6875218e-7,2.7157127e-10,8.616487e-10,1.4340039e-10,1.2703867e-10,1.9969784e-7,2.3113364e-7,0.000004097153,0.000003993306,0.000009529727,0.00053118984,0.00009218775,0.00030621098,0.020376585,0.61733717,0.3534587,0.0010803109,0.000030121719,0.0034104756,0.00038000132,0.000047178568,0.000048237078,0.0002844304,0.00012263405,0.00008336885,0.0000116917445,0.00005920047,0.000028431958,0.000023028417,0.000154036,0.000043053034,0.00074611255,0.0006596185,0.000644853,0.0000076003557,0.000015195879],[8.4908364e-10,2.233994e-8,2.3088971e-10,3.3558794e-7,0.0000012131175,0.0001125571,0.000106574,0.000073150826,0.00013718783,0.00069343933,0.0008746666,0.00009217116,0.0010994532,0.0006787991,0.000052137533,0.000016688107,0.020259112,0.02939806,0.00008545416,3.9391406e-7,0.3048892,0.00001732068,6.8305764e-7,0.0023269588,0.00089589227,0.08631181,0.0037298098,0.0038199027,0.03341842,0.010639233,0.028375858,0.06210466,0.051246345,0.0909264,0.07372805,0.07207318,0.0662409,0.055573978],[3.1545447e-8,4.280882e-8,4.884368e-8,8.514108e-7,0.0000017433598,0.000026502428,0.000024157678,0.00016351149,0.00021260286,0.0012899549,0.0019287972,0.0010196669,0.00916218,0.00876619,0.002557762,0.0024593372,0.11382108,0.14358875,0.008023713,0.000022861605,0.27801394,0.00042901438,0.000047715523,0.014851474,0.009176451,0.041411884,0.02494387,0.011305693,0.025487857,0.017979747,0.014902493,0.045747768,0.020594666,0.08639757,0.036648333,0.058350794,0.010363443,0.010277519],[3.2810855e-11,3.6618777e-12,1.5324497e-11,1.06655015e-11,4.95508e-11,2.6256183e-10,1.3210875e-10,1.02941534e-7,1.710917e-7,0.0000060424222,0.000014677033,0.00000516889,0.00045258808,0.0005593937,0.00007025498,0.000392114,0.113042235,0.108378544,0.0009518393,4.0399076e-8,0.15917328,0.0000049584114,1.7301093e-7,0.002021569,0.0013267082,0.009912683,0.0065188254,0.00071048597,0.027047005,0.00405028,0.0137258,0.06818604,0.03327295,0.16038956,0.170197,0.0983716,0.0081288405,0.013089059],[6.0771943e-9,9.309636e-11,5.1430993e-9,8.812921e-12,4.320029e-11,1.7273426e-12,1.1114867e-12,2.7740084e-8,4.1811443e-8,0.0000011820451,0.0000023750194,0.0000019505178,0.0002779114,0.00014876305,0.000109539,0.010571592,0.38697958,0.22997814,0.001555202,0.0000014912612,0.011604765,0.000025452662,0.000004097116,0.0004865497,0.00089174195,0.0014156804,0.0014047411,0.000073522635,0.007946713,0.0007129882,0.0034460844,0.014833113,0.010666909,0.06457045,0.19639505,0.0473499,0.0028690735,0.005675389],[2.9510492e-8,8.4331555e-9,7.2080053e-9,2.557419e-9,1.0753713e-8,3.191939e-9,1.8892974e-9,0.0000016585522,0.0000027263168,0.00003909459,0.0000260225,0.000018545548,0.00039134483,0.00037655156,0.00004617266,0.00088180404,0.43635887,0.41250947,0.00013159803,1.7116712e-7,0.02739325,0.0000065538798,3.7591482e-7,0.00016835963,0.00028614642,0.00078163017,0.00069283403,0.00012396717,0.004388633,0.0007070705,0.0014070213,0.0069184857,0.0036242858,0.03405187,0.03414276,0.031408098,0.0012002605,0.0019142755],[4.8645243e-10,3.7035826e-9,1.6474735e-11,6.619953e-9,2.7056185e-8,0.0000010562516,8.0052945e-7,0.0000031223053,0.000006163268,0.000044439606,0.000062155865,0.0000044828894,0.000034415083,0.000102763755,0.000002578324,6.4242323e-7,0.0009935051,0.0014918317,0.000014148146,2.0518039e-8,0.04246032,0.0000010154249,4.9774286e-8,0.0013825377,0.00027829828,0.027488688,0.0020509716,0.0017434728,0.05480998,0.006571633,0.053424016,0.08386331,0.11219004,0.093913846,0.15284103,0.06385621,0.16024876,0.14011364],[2.6728477e-9,1.6602213e-11,3.2580882e-9,5.8875873e-12,2.007623e-11,8.0412746e-11,3.6391584e-11,1.9211386e-8,3.0013272e-8,0.0000013395336,0.0000027965975,0.0000012990785,0.0001207104,0.00014248876,0.00005475684,0.0006687322,0.07903246,0.058264546,0.0008692799,5.9027764e-7,0.50398207,0.00004071023,0.0000020557297,0.0011171764,0.0012379845,0.064579874,0.0017153195,0.000263652,0.010717486,0.00064765825,0.006152116,0.025054919,0.015788442,0.06839181,0.116896234,0.029193833,0.006851424,0.00820814],[0.000004902862,7.253507e-9,0.00008437817,6.840575e-10,1.4313274e-9,1.1875488e-10,8.817441e-11,1.7548251e-7,1.8760281e-7,0.0000028912164,0.000004217541,0.000011699124,0.00039907842,0.0003521418,0.0009378921,0.08654963,0.5105428,0.27298683,0.01640383,0.0016876166,0.013483131,0.005867615,0.003068404,0.0013431828,0.0049209334,0.0046544583,0.001454367,0.00016533936,0.002100982,0.000289108,0.0011605537,0.004260402,0.0023226452,0.0176371,0.035589036,0.010205244,0.00056748994,0.00094173354],[1.3105345e-10,5.906369e-10,4.85833e-12,1.353155e-9,6.1091985e-9,2.0987738e-7,1.9610336e-7,7.337019e-7,0.0000014457501,0.000007833569,0.000025992907,0.0000011152719,0.0000061706023,0.00003453762,0.0000010796851,6.44113e-8,0.000013590992,0.000021512185,0.000013137688,2.6601002e-8,0.0041451193,5.6314565e-7,7.0794215e-8,0.00298102,0.00029532,0.025989579,0.0021950204,0.0024304588,0.047813363,0.0061461735,0.07370377,0.06276,0.13355298,0.04139062,0.09945394,0.021984447,0.2880019,0.1870279],[2.4731026e-9,5.21061e-10,4.2228554e-9,1.1318048e-9,4.165959e-9,1.3251111e-8,1.214595e-8,0.0000014799018,0.0000022638385,0.000027279633,0.00006914208,0.000027502923,0.00083549303,0.0010178762,0.0002938666,0.0010716011,0.105360694,0.106552236,0.0038798733,0.000022202392,0.042971257,0.00026780932,0.00004919202,0.009422651,0.0070981085,0.024945725,0.012696078,0.0029789868,0.03268482,0.007605427,0.018729154,0.05478879,0.035276,0.18740134,0.19219117,0.11412368,0.018553546,0.019054709],[1.1873543e-8,2.3973725e-9,1.27787745e-8,2.6629077e-9,8.6838385e-9,1.8975678e-8,1.8112763e-8,0.0000012189198,0.0000017616642,0.000012966026,0.000029202705,0.000011884324,0.00018757164,0.00040584774,0.00007921239,0.00027870107,0.013722421,0.0136292735,0.0015305919,0.0000140297425,0.007340139,0.000104817445,0.00003093532,0.0062781796,0.003488799,0.013282721,0.007220189,0.0019772395,0.045444604,0.0068552154,0.0422093,0.083900794,0.088610895,0.14994696,0.32340086,0.09502184,0.040575836,0.054405943],[4.5116623e-12,6.2190196e-14,1.3692978e-12,2.893347e-15,2.8293123e-14,3.7399728e-15,2.163267e-15,9.043596e-11,1.7361078e-10,8.644509e-9,2.4512413e-8,7.775152e-9,0.000002281736,0.0000031994314,3.89588e-7,0.00003593759,0.018666977,0.011383244,0.000027752414,5.4235945e-9,0.0007989776,2.544163e-7,2.1707061e-8,0.000075531745,0.00007389107,0.00038968,0.00019989,0.000008994617,0.009686536,0.00020412487,0.007015314,0.026739007,0.033840038,0.07959334,0.73035645,0.05474822,0.006935197,0.019214695],[3.222708e-8,6.7350897e-10,9.777976e-9,1.3259718e-11,6.996092e-11,1.5915932e-12,1.1458591e-12,1.5674113e-8,2.5351403e-8,4.07123e-7,8.5939246e-7,4.168977e-7,0.000035979676,0.00003529228,0.000015795506,0.0013020466,0.042115904,0.024731807,0.00035663624,0.0000015695085,0.0015506377,0.00001216735,0.0000037229195,0.0003781955,0.00045787566,0.0012492484,0.0007438924,0.00005260967,0.015691346,0.000712453,0.0119226575,0.028220054,0.04313567,0.077874765,0.6378654,0.05819044,0.016878404,0.036463644],[5.199761e-8,5.490662e-7,6.02162e-10,8.3526054e-8,2.0376086e-7,0.000012207157,0.00001058945,8.769745e-7,0.0000015560873,0.0000021840542,0.0000030706424,1.5415787e-7,1.8331772e-7,0.0000021320775,3.6521335e-8,3.957484e-9,9.966807e-7,0.0000015106185,4.3644107e-7,4.6521492e-8,0.00016653746,2.4959374e-7,7.343545e-8,0.00022678972,0.000022256478,0.005157243,0.00012389457,0.00025548373,0.017899921,0.00093958486,0.054995432,0.02135126,0.1204674,0.00880444,0.064909115,0.006340151,0.36745757,0.33084574],[2.2673557e-8,9.991418e-8,3.058772e-10,4.754249e-9,2.0034738e-8,1.6076724e-7,1.5646306e-7,2.1103195e-7,3.8037044e-7,7.624611e-7,0.0000010770489,6.192157e-8,8.8527585e-8,0.0000010608868,1.7405156e-8,4.056841e-9,0.0000015883858,0.0000020055272,3.1006377e-7,3.6344158e-8,0.000022709903,1.8427662e-7,5.9495402e-8,0.00014177112,0.000021427162,0.00089520833,0.000078129764,0.00011656176,0.017373186,0.00066170853,0.051078066,0.023472426,0.13972235,0.010242919,0.13454983,0.00906036,0.25759968,0.35495535],[1.2812743e-8,5.8359937e-8,1.8127216e-10,3.0660328e-9,1.3869186e-8,1.0610185e-7,1.0440012e-7,1.8595527e-7,3.3677097e-7,7.3491344e-7,0.0000010873579,6.127056e-8,1.0693453e-7,0.0000011441135,1.9053717e-8,5.055574e-9,0.0000022847526,0.0000028497238,3.4467047e-7,3.0515483e-8,0.000024907427,1.704647e-7,5.1034952e-8,0.0001445676,0.000022676159,0.00083094713,0.00008619323,0.000115719944,0.01817283,0.0007142219,0.050389376,0.025346626,0.14130595,0.011629469,0.14781009,0.010565612,0.24261749,0.3502135],[5.423745e-9,2.9231591e-8,7.115053e-11,1.5395148e-9,7.719555e-9,5.8445483e-8,5.8848293e-8,1.2069636e-7,2.2491704e-7,5.039414e-7,7.8358653e-7,3.951762e-8,7.769575e-8,8.09254e-7,1.20051595e-8,3.2489056e-9,0.0000018465291,0.0000022990773,2.3171786e-7,1.7617166e-8,0.00001666722,1.03425876e-7,2.9719004e-8,0.000113338065,0.00001716194,0.0006075715,0.00006964985,0.00009000913,0.017063051,0.0006333477,0.047971807,0.024355343,0.14068523,0.011021042,0.15248302,0.010313676,0.23702279,0.35752904],[3.2849674e-9,1.765273e-8,4.0119227e-11,7.9853485e-10,4.455399e-9,2.802696e-8,2.852648e-8,7.839626e-8,1.4900452e-7,3.4452242e-7,5.489148e-7,2.6447726e-8,5.5765174e-8,5.8672566e-7,7.826631e-9,2.3154636e-9,0.0000015376986,0.0000018789336,1.629109e-7,1.1611552e-8,0.00001023239,6.927537e-8,1.9773477e-8,0.00008862218,0.000013617701,0.00041587945,0.000055898156,0.00006909713,0.01611891,0.0005473189,0.046002652,0.023407895,0.14141978,0.010416355,0.16265199,0.010122641,0.22577232,0.36288118],[1.3886047e-9,6.37135e-9,1.5317029e-11,2.3405997e-10,1.4878557e-9,8.180086e-9,8.200363e-9,3.4838763e-8,6.837786e-8,1.7999984e-7,2.9984943e-7,1.3391098e-8,3.3291922e-8,3.6563276e-7,4.3062305e-9,1.431179e-9,0.0000011976683,0.0000014338437,1.05454575e-7,5.9029293e-9,0.0000067708643,3.9493457e-8,1.05215845e-8,0.00006532005,0.000010089385,0.00030045558,0.00004196212,0.000047621605,0.015016485,0.00042783876,0.043217767,0.022604456,0.1423,0.009987598,0.17984545,0.00978276,0.21278498,0.36355668],[1.6768153e-7,0.0000027490541,1.7251072e-9,3.129064e-7,7.2798724e-7,0.000030595078,0.000028485456,0.0000015373881,0.0000026872553,0.0000025843922,0.000003314731,1.7497305e-7,1.5390641e-7,0.0000017617602,3.010361e-8,3.4922916e-9,7.0534793e-7,0.0000010622196,3.1574996e-7,7.6215294e-8,0.00006870834,2.5574602e-7,1.043997e-7,0.000172007,0.000017128843,0.0030767643,0.00009159377,0.00020816084,0.01580139,0.000855402,0.05293666,0.017580321,0.11553814,0.00684145,0.059275504,0.005453239,0.37070745,0.35129824],[5.7806783e-8,0.0000010374976,4.4207216e-10,6.323744e-8,2.2328251e-7,0.0000030272722,0.00000315503,6.9885573e-7,0.0000012511888,0.0000012457975,0.0000016716017,7.7842664e-8,6.473769e-8,7.843446e-7,1.0308273e-8,1.3415214e-9,3.9841402e-7,5.687523e-7,1.2569468e-7,3.350236e-8,0.00000931606,1.0424698e-7,4.562225e-8,0.000097808865,0.0000108819,0.00062462717,0.000051671333,0.000110426816,0.014030196,0.00066327944,0.04938789,0.016478218,0.12383724,0.0058190683,0.076227576,0.0056560994,0.31464684,0.39233416],[5.1502973e-8,0.0000010446454,4.16187e-10,7.5156244e-8,2.7364544e-7,0.000003381396,0.0000036860738,9.1923357e-7,0.0000016276962,0.0000015407558,0.0000023468976,1.0233411e-7,8.859641e-8,9.652531e-7,1.4502857e-8,1.6113807e-9,3.9297944e-7,5.540678e-7,1.6748152e-7,4.275761e-8,0.0000074234767,1.247174e-7,5.8824583e-8,0.00012307572,0.000013738044,0.00052799616,0.00006484082,0.00013884026,0.014745843,0.00083294825,0.051566873,0.017340995,0.124544375,0.005738063,0.072546735,0.005816344,0.30799642,0.39797795],[6.7317187e-9,1.2379762e-7,4.286468e-11,6.422349e-9,3.027917e-8,3.3290118e-7,3.7139617e-7,1.700499e-7,3.2452903e-7,3.6690307e-7,6.563411e-7,2.134624e-8,2.5189417e-8,2.9463303e-7,3.5100463e-9,4.0483905e-10,1.5569574e-7,2.1314436e-7,5.6771725e-8,1.0361384e-8,0.0000024863043,3.51197e-8,1.5326632e-8,0.00006326526,0.000006507954,0.0002650277,0.000032647105,0.00006321014,0.011898981,0.00048383127,0.044831656,0.015007133,0.122933485,0.0045363903,0.08000617,0.0046426877,0.29391968,0.4213037],[1.6510604e-9,2.3617366e-8,8.707774e-12,8.2758883e-10,4.961027e-9,3.6766192e-8,4.061241e-8,4.4762697e-8,9.0136865e-8,1.2586904e-7,2.4484524e-7,6.919412e-9,1.0903487e-8,1.3255149e-7,1.3008109e-9,1.8768898e-10,1.0694722e-7,1.3861383e-7,2.6989477e-8,3.2589678e-9,0.0000010975756,1.3200041e-8,5.191897e-9,0.000036589536,0.000003824833,0.00013578504,0.000020045742,0.000033118242,0.010538215,0.00032539127,0.04044683,0.014168617,0.12541518,0.004165979,0.096900314,0.0044004763,0.26764274,0.4357648],[7.678005e-7,0.000014910277,7.1872677e-9,0.0000015692553,0.0000031234424,0.000114210736,0.00010728625,0.0000036399774,0.0000060960306,0.000004349757,0.000005471329,3.179573e-7,2.1556396e-7,0.0000024335068,4.8465477e-8,5.2340914e-9,6.2834266e-7,9.422444e-7,4.2338206e-7,1.6070108e-7,0.000056829515,3.910069e-7,2.063673e-7,0.00019896113,0.000019956895,0.0028697012,0.00010428233,0.00025668635,0.015889276,0.0010035173,0.05506596,0.0164771,0.111876175,0.005898924,0.050122492,0.0049223425,0.37675533,0.35821527],[1.7578606e-7,0.000007978925,8.810278e-10,6.336297e-7,0.0000017989491,0.000041773466,0.000044822278,0.000002209481,0.0000038554285,0.0000022030947,0.0000030328574,1.2019058e-7,5.7356313e-8,7.725969e-7,9.525878e-9,6.056711e-10,1.06284105e-7,1.6445442e-7,8.6204565e-8,4.020831e-8,0.0000046089517,8.451546e-8,5.0094098e-8,0.000094947434,0.000008229958,0.00048915343,0.00004652018,0.00013760687,0.012009584,0.0007441597,0.049347863,0.012672903,0.10880442,0.0033073481,0.041421533,0.0034267455,0.35314465,0.41422975],[2.2536605e-8,9.899775e-7,8.662631e-11,6.9451936e-8,2.4994722e-7,0.0000057172015,0.0000061099463,5.4739155e-7,0.0000010082782,7.0824154e-7,0.0000011291826,3.4249513e-8,2.078555e-8,3.124826e-7,2.898424e-9,1.7123393e-10,4.6513417e-8,7.193278e-8,3.4738004e-8,9.184856e-9,0.0000020003683,2.4426747e-8,1.263878e-8,0.00005863885,0.0000044343856,0.00027122488,0.000029144394,0.00007929713,0.010518436,0.00052252726,0.044961642,0.011645603,0.10899484,0.0028496187,0.043887783,0.002956965,0.34352878,0.42967188],[4.757346e-9,1.2922666e-7,1.6045778e-11,5.778897e-9,2.7394133e-8,3.4861594e-7,3.7298307e-7,1.1454877e-7,2.2034375e-7,2.0438196e-7,3.7697214e-7,1.0054833e-8,8.465792e-9,1.3791258e-7,1.1153949e-9,8.39854e-11,2.9347996e-8,4.255319e-8,1.9158069e-8,3.160275e-9,7.66723e-7,9.737675e-9,4.8036655e-9,0.000038102677,0.0000028978905,0.00013259579,0.000019296758,0.00004275037,0.009636431,0.0003593319,0.041824926,0.01126131,0.11434435,0.0027107075,0.056956593,0.00284572,0.31366363,0.4461585],[2.769857e-9,6.203281e-8,8.81188e-12,2.121731e-9,1.1443398e-8,1.0398819e-7,1.1198954e-7,5.8151407e-8,1.1439257e-7,1.1453754e-7,2.2562696e-7,5.7171476e-9,5.5256084e-9,9.122068e-8,7.0458483e-10,6.1302526e-11,2.2877861e-8,3.1878628e-8,1.3914341e-8,2.048052e-9,4.3335936e-7,6.3762604e-9,3.2138139e-9,0.000029463841,0.0000022889687,0.00008886803,0.000015075937,0.0000306225,0.009044122,0.0002924957,0.040032227,0.010759121,0.11614715,0.0025353888,0.063910395,0.0027190582,0.29819885,0.45619354],[0.0000013247432,0.000025915022,1.0239858e-8,0.0000020432167,0.0000039599345,0.00011753086,0.000107993066,0.0000034954999,0.000005794248,0.0000036116735,0.0000044701474,2.7001457e-7,1.5961048e-7,0.0000019819915,3.7290608e-8,4.3170965e-9,4.3501183e-7,6.456948e-7,3.3157735e-7,1.5205872e-7,0.000033417164,3.1097878e-7,1.9202655e-7,0.00016311,0.000016028285,0.002058656,0.00008654363,0.00021283835,0.0150354225,0.0008938416,0.054062597,0.014767712,0.110347755,0.005099563,0.04859707,0.004407004,0.37622663,0.3677112],[2.93862e-7,0.000016241622,1.3471044e-9,0.000001283113,0.0000033891004,0.00008291752,0.00008763015,0.000002953101,0.0000051422653,0.0000025055806,0.0000033086724,1.3575132e-7,5.7865847e-8,7.83499e-7,9.480726e-9,6.025095e-10,8.974514e-8,1.4186243e-7,7.8540324e-8,4.3953303e-8,0.0000043192917,8.10875e-8,5.2690165e-8,0.000087601235,0.000007263661,0.0004994373,0.000043537104,0.00013467303,0.011619798,0.000731138,0.04870195,0.011530521,0.10507048,0.0030365088,0.037794504,0.0031550403,0.36659092,0.41078517],[1.16378594e-7,0.000006150063,5.540848e-10,4.623386e-7,0.0000013972739,0.0000298621,0.00003209607,0.0000016935933,0.0000030261037,0.000001678607,0.00000235513,8.980262e-8,4.916354e-8,6.054932e-7,7.144686e-9,5.413082e-10,1.05581606e-7,1.6123965e-7,6.5434186e-8,2.9045717e-8,0.000003377685,6.0277e-8,3.586736e-8,0.00007364212,0.0000064048986,0.00038561173,0.000038476883,0.0001065188,0.011357146,0.0006626135,0.047101058,0.012023403,0.108217075,0.003224756,0.043956317,0.0034554803,0.34751526,0.42179278],[4.6986724e-8,0.0000022120978,2.1653886e-10,1.5758474e-7,5.3580777e-7,0.000010464872,0.000011221025,9.080405e-7,0.000001655982,0.0000010451582,0.0000015912186,5.61113e-8,3.755151e-8,4.5619538e-7,5.0322813e-9,4.1706807e-10,9.8682314e-8,1.4742515e-7,5.2682893e-8,1.735936e-8,0.0000025894965,4.0581256e-8,2.2530891e-8,0.0000637675,0.0000055114665,0.0003068632,0.00003457275,0.00008702104,0.011148572,0.00059767097,0.046009295,0.012333045,0.11085005,0.0033059074,0.04861367,0.0035721033,0.33444124,0.42859724],[1.879897e-8,7.049621e-7,7.930668e-11,4.089604e-8,1.5988529e-7,0.0000024145586,0.0000025817003,3.842976e-7,7.1853725e-7,5.285746e-7,8.7118894e-7,2.830221e-8,2.2817758e-8,2.8971618e-7,2.9089644e-9,2.7079938e-10,7.7612974e-8,1.1256987e-7,3.683581e-8,9.1638785e-9,0.0000016134311,2.3616549e-8,1.2566121e-8,0.00005004907,0.0000042634274,0.00021598909,0.00002752165,0.00006215161,0.010549503,0.0004845716,0.044052847,0.012109365,0.11318737,0.0032187346,0.055010583,0.0034805841,0.32042012,0.4371157]],\"type\":\"heatmap\"}],                        {\"height\":1000,\"title\":{\"text\":\"Decoder cross-attn, Layer 2, Head 1\",\"x\":0.5},\"width\":1000,\"xaxis\":{\"automargin\":true,\"showgrid\":false,\"tickangle\":-45,\"ticklen\":5,\"ticks\":\"outside\",\"title\":{\"font\":{\"color\":\"crimson\",\"family\":\"Courier\",\"size\":18},\"text\":\"Key\"}},\"yaxis\":{\"automargin\":true,\"autorange\":\"reversed\",\"showgrid\":false,\"ticklen\":5,\"ticks\":\"outside\",\"title\":{\"font\":{\"color\":\"crimson\",\"family\":\"Courier\",\"size\":18},\"text\":\"Query\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2b3bb503-88b2-4899-b419-2f401f825684');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "vis_attn(\n",
        "    matrix,\n",
        "    xlabels=key_labels,\n",
        "    ylabels=query_labels,\n",
        "    title=title\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b5b571",
      "metadata": {
        "id": "f9b5b571"
      },
      "outputs": [],
      "source": [
        "# Image(filename='images/decoder_cross_attn1.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b99a7d",
      "metadata": {
        "id": "a8b99a7d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c0aedd18",
      "metadata": {
        "id": "c0aedd18"
      },
      "source": [
        "## Decoder Visualization [teacher force]\n",
        "\n",
        "* self-attention\n",
        "* cross-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28feaa63",
      "metadata": {
        "id": "28feaa63",
        "outputId": "1d38f08e-075b-4f7b-eaa4-e46ed1ecd427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': torch.Size([1, 38]),\n",
              " 'src_mask': torch.Size([1, 1, 38]),\n",
              " 'tgt': torch.Size([1, 31]),\n",
              " 'tgt_y': torch.Size([1, 31]),\n",
              " 'tgt_mask': torch.Size([1, 31, 31]),\n",
              " 'num_tokens': torch.Size([])}"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "{k:v.shape for k,v in batch.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0388225",
      "metadata": {
        "id": "a0388225"
      },
      "source": [
        "> 上面的例子中，我们采用的 greedy_decode 并未用到 decoder input，即 `batch['tgt']`，\n",
        "> 因此，在此 decoder 的 self-attention 应该展示为 greedy decode 产生的文本（又作为decoder输入）之间的 self-attention，\n",
        "> 并非 `batch['tgt']` 的 self-attention。\n",
        ">\n",
        "> 这里, 我们使用 `batch['tgt']` 直接作为输入（记为 teacher-forece），展示另一种 decoder 端的 attention。\n",
        "\n",
        "\n",
        "> In the examples above, the `greedy_decode` method does not utilize the decoder input, i.e., `batch['tgt']`.  \n",
        "> Therefore, the self-attention in the decoder should represent the self-attention between the text generated\n",
        "> by the greedy decode (which is also used as the decoder input in the next autoregressive step),\n",
        "> rather than the self-attention of `batch['tgt']`.  \n",
        ">\n",
        "> Next, we use `batch['tgt']` directly as the input (denoted as teacher-force) to demonstrate another kind of attention on the decoder side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d31a16",
      "metadata": {
        "id": "67d31a16"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    logits = model(             # decoder output\n",
        "        batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n",
        "    )\n",
        "    y_pred = model.generator(logits)\n",
        "    prob = model.generator(logits)\n",
        "    _, next_tokens = torch.max(prob, dim=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f4fcc4f",
      "metadata": {
        "id": "5f4fcc4f",
        "outputId": "1111d1ed-2a04-4204-dc37-718fff5deeb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 31, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa39b663",
      "metadata": {
        "id": "aa39b663",
        "outputId": "baf1108b-0147-4b4b-d88d-670b6d822a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 31, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "prob.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12cf6a29",
      "metadata": {
        "id": "12cf6a29",
        "outputId": "a4a671f5-1743-4466-b185-a28b0d62d6b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3110,  792,  420,  334, 5829,  276, 1185, 3979, 3412, 1185, 3066, 1095,\n",
              "          276,  526,  377,  456, 3412,  912,  526, 1109,  276,  268,  548,  548,\n",
              "          268, 5030,  268, 1877,  287,  287,    2]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "next_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03dc20d3",
      "metadata": {
        "id": "03dc20d3",
        "outputId": "08980f6c-b28d-47e8-b07c-44efe23d8269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['美联储还会在耗，月112008月初金融，出了而2008政策出银行，的经济经济的恶化的稳定。。</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "tokenizer.batch_decode(next_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa8b4a38",
      "metadata": {
        "id": "aa8b4a38"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "79b234fd",
      "metadata": {
        "id": "79b234fd"
      },
      "source": [
        "### Decoder self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50726707",
      "metadata": {
        "id": "50726707"
      },
      "outputs": [],
      "source": [
        "layer = 0\n",
        "head = 5\n",
        "\n",
        "# Decoder self-attention score\n",
        "attn_score = model.decoder.layers[layer].self_attn.attn_score    # [batch_size, num_heads, seq_len, seq_len]\n",
        "attn_score = attn_score.cpu().numpy()\n",
        "\n",
        "matrix = attn_score[0][head]\n",
        "\n",
        "title = f'Decoder self-attn, Layer {layer}, Head {head}'\n",
        "\n",
        "# 在此 decoder 的 self-attention 应该展示为 batch['tgt'] （作为decoder输入）内部之间的 self-attention，\n",
        "# teacher-force, not `greedy_decode`, should use batch['tgt'] to show the decoder self-attention\n",
        "\n",
        "xlabels = [tokenizer.decode(x) for x in batch['tgt'][0]]    # has been shifted right already\n",
        "ylabels = xlabels\n",
        "\n",
        "# under `greedy_decode`, should use model outputs to show they decoder self-attention\n",
        "# xlabels = [tokenizer.decode(x) for x in output_ids[0][:-1]]\n",
        "# ylabels = xlabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c380aedf",
      "metadata": {
        "id": "c380aedf",
        "outputId": "83cd7c82-6219-4371-940d-88554a4bb4e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350db4c0",
      "metadata": {
        "id": "350db4c0",
        "outputId": "efd5a5ca-83ab-4696-ea90-bb057686ce70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ],
      "source": [
        "batch['tgt'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e101cb9",
      "metadata": {
        "id": "0e101cb9",
        "outputId": "3e4194f8-9807-4b43-f8b3-9a3485719f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>美联储显然无法消化1月和2月的全球金融市场抛售，而这一抛售潮主要是因为对美联储进一步紧缩的担忧导致的。']"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "tokenizer.batch_decode(batch['tgt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49b767b",
      "metadata": {
        "id": "f49b767b",
        "outputId": "1289a1bf-59d7-43ba-9f8c-158939903ae8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ],
      "source": [
        "next_tokens.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a03b3a1f",
      "metadata": {
        "id": "a03b3a1f",
        "outputId": "0994b1d2-8ffc-48cd-b99e-87f8e385fb6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['美联储还会在耗，月112008月初金融，出了而2008政策出银行，的经济经济的恶化的稳定。。</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "tokenizer.batch_decode(next_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd84c5b",
      "metadata": {
        "id": "ddd84c5b",
        "outputId": "bbce5671-2191-4454-bf85-2a21f3f2e094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"85a7a547-2d86-4c3a-9bd0-57b023f9bcb5\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"85a7a547-2d86-4c3a-9bd0-57b023f9bcb5\")) {                    Plotly.newPlot(                        \"85a7a547-2d86-4c3a-9bd0-57b023f9bcb5\",                        [{\"colorbar\":{\"thickness\":15,\"ticklen\":3},\"colorscale\":[[0.0,\"rgb(255,247,251)\"],[0.125,\"rgb(236,231,242)\"],[0.25,\"rgb(208,209,230)\"],[0.375,\"rgb(166,189,219)\"],[0.5,\"rgb(116,169,207)\"],[0.625,\"rgb(54,144,192)\"],[0.75,\"rgb(5,112,176)\"],[0.875,\"rgb(4,90,141)\"],[1.0,\"rgb(2,56,88)\"]],\"hoverinfo\":\"text\",\"hovertext\":[[\"attn(&lt;s&gt;, &lt;s&gt;)= 1.00\",\"attn(&lt;s&gt;, 美联储)= 0.00\",\"attn(&lt;s&gt;, 显然)= 0.00\",\"attn(&lt;s&gt;, 无法)= 0.00\",\"attn(&lt;s&gt;, 消)= 0.00\",\"attn(&lt;s&gt;, 化)= 0.00\",\"attn(&lt;s&gt;, 1)= 0.00\",\"attn(&lt;s&gt;, 月)= 0.00\",\"attn(&lt;s&gt;, 和)= 0.00\",\"attn(&lt;s&gt;, 2)= 0.00\",\"attn(&lt;s&gt;, 月)= 0.00\",\"attn(&lt;s&gt;, 的全球)= 0.00\",\"attn(&lt;s&gt;, 金融市场)= 0.00\",\"attn(&lt;s&gt;, 抛)= 0.00\",\"attn(&lt;s&gt;, 售)= 0.00\",\"attn(&lt;s&gt;, ，)= 0.00\",\"attn(&lt;s&gt;, 而)= 0.00\",\"attn(&lt;s&gt;, 这一)= 0.00\",\"attn(&lt;s&gt;, 抛)= 0.00\",\"attn(&lt;s&gt;, 售)= 0.00\",\"attn(&lt;s&gt;, 潮)= 0.00\",\"attn(&lt;s&gt;, 主要)= 0.00\",\"attn(&lt;s&gt;, 是因为)= 0.00\",\"attn(&lt;s&gt;, 对)= 0.00\",\"attn(&lt;s&gt;, 美联储)= 0.00\",\"attn(&lt;s&gt;, 进一步)= 0.00\",\"attn(&lt;s&gt;, 紧缩)= 0.00\",\"attn(&lt;s&gt;, 的)= 0.00\",\"attn(&lt;s&gt;, 担忧)= 0.00\",\"attn(&lt;s&gt;, 导致的)= 0.00\",\"attn(&lt;s&gt;, 。)= 0.00\"],[\"attn(美联储, &lt;s&gt;)= 0.00\",\"attn(美联储, 美联储)= 1.00\",\"attn(美联储, 显然)= 0.00\",\"attn(美联储, 无法)= 0.00\",\"attn(美联储, 消)= 0.00\",\"attn(美联储, 化)= 0.00\",\"attn(美联储, 1)= 0.00\",\"attn(美联储, 月)= 0.00\",\"attn(美联储, 和)= 0.00\",\"attn(美联储, 2)= 0.00\",\"attn(美联储, 月)= 0.00\",\"attn(美联储, 的全球)= 0.00\",\"attn(美联储, 金融市场)= 0.00\",\"attn(美联储, 抛)= 0.00\",\"attn(美联储, 售)= 0.00\",\"attn(美联储, ，)= 0.00\",\"attn(美联储, 而)= 0.00\",\"attn(美联储, 这一)= 0.00\",\"attn(美联储, 抛)= 0.00\",\"attn(美联储, 售)= 0.00\",\"attn(美联储, 潮)= 0.00\",\"attn(美联储, 主要)= 0.00\",\"attn(美联储, 是因为)= 0.00\",\"attn(美联储, 对)= 0.00\",\"attn(美联储, 美联储)= 0.00\",\"attn(美联储, 进一步)= 0.00\",\"attn(美联储, 紧缩)= 0.00\",\"attn(美联储, 的)= 0.00\",\"attn(美联储, 担忧)= 0.00\",\"attn(美联储, 导致的)= 0.00\",\"attn(美联储, 。)= 0.00\"],[\"attn(显然, &lt;s&gt;)= 0.00\",\"attn(显然, 美联储)= 1.00\",\"attn(显然, 显然)= 0.00\",\"attn(显然, 无法)= 0.00\",\"attn(显然, 消)= 0.00\",\"attn(显然, 化)= 0.00\",\"attn(显然, 1)= 0.00\",\"attn(显然, 月)= 0.00\",\"attn(显然, 和)= 0.00\",\"attn(显然, 2)= 0.00\",\"attn(显然, 月)= 0.00\",\"attn(显然, 的全球)= 0.00\",\"attn(显然, 金融市场)= 0.00\",\"attn(显然, 抛)= 0.00\",\"attn(显然, 售)= 0.00\",\"attn(显然, ，)= 0.00\",\"attn(显然, 而)= 0.00\",\"attn(显然, 这一)= 0.00\",\"attn(显然, 抛)= 0.00\",\"attn(显然, 售)= 0.00\",\"attn(显然, 潮)= 0.00\",\"attn(显然, 主要)= 0.00\",\"attn(显然, 是因为)= 0.00\",\"attn(显然, 对)= 0.00\",\"attn(显然, 美联储)= 0.00\",\"attn(显然, 进一步)= 0.00\",\"attn(显然, 紧缩)= 0.00\",\"attn(显然, 的)= 0.00\",\"attn(显然, 担忧)= 0.00\",\"attn(显然, 导致的)= 0.00\",\"attn(显然, 。)= 0.00\"],[\"attn(无法, &lt;s&gt;)= 0.00\",\"attn(无法, 美联储)= 0.65\",\"attn(无法, 显然)= 0.03\",\"attn(无法, 无法)= 0.32\",\"attn(无法, 消)= 0.00\",\"attn(无法, 化)= 0.00\",\"attn(无法, 1)= 0.00\",\"attn(无法, 月)= 0.00\",\"attn(无法, 和)= 0.00\",\"attn(无法, 2)= 0.00\",\"attn(无法, 月)= 0.00\",\"attn(无法, 的全球)= 0.00\",\"attn(无法, 金融市场)= 0.00\",\"attn(无法, 抛)= 0.00\",\"attn(无法, 售)= 0.00\",\"attn(无法, ，)= 0.00\",\"attn(无法, 而)= 0.00\",\"attn(无法, 这一)= 0.00\",\"attn(无法, 抛)= 0.00\",\"attn(无法, 售)= 0.00\",\"attn(无法, 潮)= 0.00\",\"attn(无法, 主要)= 0.00\",\"attn(无法, 是因为)= 0.00\",\"attn(无法, 对)= 0.00\",\"attn(无法, 美联储)= 0.00\",\"attn(无法, 进一步)= 0.00\",\"attn(无法, 紧缩)= 0.00\",\"attn(无法, 的)= 0.00\",\"attn(无法, 担忧)= 0.00\",\"attn(无法, 导致的)= 0.00\",\"attn(无法, 。)= 0.00\"],[\"attn(消, &lt;s&gt;)= 0.00\",\"attn(消, 美联储)= 0.47\",\"attn(消, 显然)= 0.07\",\"attn(消, 无法)= 0.44\",\"attn(消, 消)= 0.03\",\"attn(消, 化)= 0.00\",\"attn(消, 1)= 0.00\",\"attn(消, 月)= 0.00\",\"attn(消, 和)= 0.00\",\"attn(消, 2)= 0.00\",\"attn(消, 月)= 0.00\",\"attn(消, 的全球)= 0.00\",\"attn(消, 金融市场)= 0.00\",\"attn(消, 抛)= 0.00\",\"attn(消, 售)= 0.00\",\"attn(消, ，)= 0.00\",\"attn(消, 而)= 0.00\",\"attn(消, 这一)= 0.00\",\"attn(消, 抛)= 0.00\",\"attn(消, 售)= 0.00\",\"attn(消, 潮)= 0.00\",\"attn(消, 主要)= 0.00\",\"attn(消, 是因为)= 0.00\",\"attn(消, 对)= 0.00\",\"attn(消, 美联储)= 0.00\",\"attn(消, 进一步)= 0.00\",\"attn(消, 紧缩)= 0.00\",\"attn(消, 的)= 0.00\",\"attn(消, 担忧)= 0.00\",\"attn(消, 导致的)= 0.00\",\"attn(消, 。)= 0.00\"],[\"attn(化, &lt;s&gt;)= 0.00\",\"attn(化, 美联储)= 0.00\",\"attn(化, 显然)= 0.00\",\"attn(化, 无法)= 0.00\",\"attn(化, 消)= 0.98\",\"attn(化, 化)= 0.02\",\"attn(化, 1)= 0.00\",\"attn(化, 月)= 0.00\",\"attn(化, 和)= 0.00\",\"attn(化, 2)= 0.00\",\"attn(化, 月)= 0.00\",\"attn(化, 的全球)= 0.00\",\"attn(化, 金融市场)= 0.00\",\"attn(化, 抛)= 0.00\",\"attn(化, 售)= 0.00\",\"attn(化, ，)= 0.00\",\"attn(化, 而)= 0.00\",\"attn(化, 这一)= 0.00\",\"attn(化, 抛)= 0.00\",\"attn(化, 售)= 0.00\",\"attn(化, 潮)= 0.00\",\"attn(化, 主要)= 0.00\",\"attn(化, 是因为)= 0.00\",\"attn(化, 对)= 0.00\",\"attn(化, 美联储)= 0.00\",\"attn(化, 进一步)= 0.00\",\"attn(化, 紧缩)= 0.00\",\"attn(化, 的)= 0.00\",\"attn(化, 担忧)= 0.00\",\"attn(化, 导致的)= 0.00\",\"attn(化, 。)= 0.00\"],[\"attn(1, &lt;s&gt;)= 0.73\",\"attn(1, 美联储)= 0.01\",\"attn(1, 显然)= 0.00\",\"attn(1, 无法)= 0.00\",\"attn(1, 消)= 0.04\",\"attn(1, 化)= 0.05\",\"attn(1, 1)= 0.17\",\"attn(1, 月)= 0.00\",\"attn(1, 和)= 0.00\",\"attn(1, 2)= 0.00\",\"attn(1, 月)= 0.00\",\"attn(1, 的全球)= 0.00\",\"attn(1, 金融市场)= 0.00\",\"attn(1, 抛)= 0.00\",\"attn(1, 售)= 0.00\",\"attn(1, ，)= 0.00\",\"attn(1, 而)= 0.00\",\"attn(1, 这一)= 0.00\",\"attn(1, 抛)= 0.00\",\"attn(1, 售)= 0.00\",\"attn(1, 潮)= 0.00\",\"attn(1, 主要)= 0.00\",\"attn(1, 是因为)= 0.00\",\"attn(1, 对)= 0.00\",\"attn(1, 美联储)= 0.00\",\"attn(1, 进一步)= 0.00\",\"attn(1, 紧缩)= 0.00\",\"attn(1, 的)= 0.00\",\"attn(1, 担忧)= 0.00\",\"attn(1, 导致的)= 0.00\",\"attn(1, 。)= 0.00\"],[\"attn(月, &lt;s&gt;)= 0.05\",\"attn(月, 美联储)= 0.07\",\"attn(月, 显然)= 0.02\",\"attn(月, 无法)= 0.01\",\"attn(月, 消)= 0.10\",\"attn(月, 化)= 0.24\",\"attn(月, 1)= 0.36\",\"attn(月, 月)= 0.16\",\"attn(月, 和)= 0.00\",\"attn(月, 2)= 0.00\",\"attn(月, 月)= 0.00\",\"attn(月, 的全球)= 0.00\",\"attn(月, 金融市场)= 0.00\",\"attn(月, 抛)= 0.00\",\"attn(月, 售)= 0.00\",\"attn(月, ，)= 0.00\",\"attn(月, 而)= 0.00\",\"attn(月, 这一)= 0.00\",\"attn(月, 抛)= 0.00\",\"attn(月, 售)= 0.00\",\"attn(月, 潮)= 0.00\",\"attn(月, 主要)= 0.00\",\"attn(月, 是因为)= 0.00\",\"attn(月, 对)= 0.00\",\"attn(月, 美联储)= 0.00\",\"attn(月, 进一步)= 0.00\",\"attn(月, 紧缩)= 0.00\",\"attn(月, 的)= 0.00\",\"attn(月, 担忧)= 0.00\",\"attn(月, 导致的)= 0.00\",\"attn(月, 。)= 0.00\"],[\"attn(和, &lt;s&gt;)= 0.00\",\"attn(和, 美联储)= 0.00\",\"attn(和, 显然)= 0.00\",\"attn(和, 无法)= 0.07\",\"attn(和, 消)= 0.00\",\"attn(和, 化)= 0.01\",\"attn(和, 1)= 0.00\",\"attn(和, 月)= 0.00\",\"attn(和, 和)= 0.91\",\"attn(和, 2)= 0.00\",\"attn(和, 月)= 0.00\",\"attn(和, 的全球)= 0.00\",\"attn(和, 金融市场)= 0.00\",\"attn(和, 抛)= 0.00\",\"attn(和, 售)= 0.00\",\"attn(和, ，)= 0.00\",\"attn(和, 而)= 0.00\",\"attn(和, 这一)= 0.00\",\"attn(和, 抛)= 0.00\",\"attn(和, 售)= 0.00\",\"attn(和, 潮)= 0.00\",\"attn(和, 主要)= 0.00\",\"attn(和, 是因为)= 0.00\",\"attn(和, 对)= 0.00\",\"attn(和, 美联储)= 0.00\",\"attn(和, 进一步)= 0.00\",\"attn(和, 紧缩)= 0.00\",\"attn(和, 的)= 0.00\",\"attn(和, 担忧)= 0.00\",\"attn(和, 导致的)= 0.00\",\"attn(和, 。)= 0.00\"],[\"attn(2, &lt;s&gt;)= 0.02\",\"attn(2, 美联储)= 0.00\",\"attn(2, 显然)= 0.00\",\"attn(2, 无法)= 0.00\",\"attn(2, 消)= 0.00\",\"attn(2, 化)= 0.00\",\"attn(2, 1)= 0.02\",\"attn(2, 月)= 0.01\",\"attn(2, 和)= 0.03\",\"attn(2, 2)= 0.92\",\"attn(2, 月)= 0.00\",\"attn(2, 的全球)= 0.00\",\"attn(2, 金融市场)= 0.00\",\"attn(2, 抛)= 0.00\",\"attn(2, 售)= 0.00\",\"attn(2, ，)= 0.00\",\"attn(2, 而)= 0.00\",\"attn(2, 这一)= 0.00\",\"attn(2, 抛)= 0.00\",\"attn(2, 售)= 0.00\",\"attn(2, 潮)= 0.00\",\"attn(2, 主要)= 0.00\",\"attn(2, 是因为)= 0.00\",\"attn(2, 对)= 0.00\",\"attn(2, 美联储)= 0.00\",\"attn(2, 进一步)= 0.00\",\"attn(2, 紧缩)= 0.00\",\"attn(2, 的)= 0.00\",\"attn(2, 担忧)= 0.00\",\"attn(2, 导致的)= 0.00\",\"attn(2, 。)= 0.00\"],[\"attn(月, &lt;s&gt;)= 0.01\",\"attn(月, 美联储)= 0.00\",\"attn(月, 显然)= 0.00\",\"attn(月, 无法)= 0.00\",\"attn(月, 消)= 0.00\",\"attn(月, 化)= 0.00\",\"attn(月, 1)= 0.01\",\"attn(月, 月)= 0.01\",\"attn(月, 和)= 0.05\",\"attn(月, 2)= 0.84\",\"attn(月, 月)= 0.07\",\"attn(月, 的全球)= 0.00\",\"attn(月, 金融市场)= 0.00\",\"attn(月, 抛)= 0.00\",\"attn(月, 售)= 0.00\",\"attn(月, ，)= 0.00\",\"attn(月, 而)= 0.00\",\"attn(月, 这一)= 0.00\",\"attn(月, 抛)= 0.00\",\"attn(月, 售)= 0.00\",\"attn(月, 潮)= 0.00\",\"attn(月, 主要)= 0.00\",\"attn(月, 是因为)= 0.00\",\"attn(月, 对)= 0.00\",\"attn(月, 美联储)= 0.00\",\"attn(月, 进一步)= 0.00\",\"attn(月, 紧缩)= 0.00\",\"attn(月, 的)= 0.00\",\"attn(月, 担忧)= 0.00\",\"attn(月, 导致的)= 0.00\",\"attn(月, 。)= 0.00\"],[\"attn(的全球, &lt;s&gt;)= 0.00\",\"attn(的全球, 美联储)= 0.00\",\"attn(的全球, 显然)= 0.00\",\"attn(的全球, 无法)= 0.03\",\"attn(的全球, 消)= 0.05\",\"attn(的全球, 化)= 0.13\",\"attn(的全球, 1)= 0.02\",\"attn(的全球, 月)= 0.07\",\"attn(的全球, 和)= 0.12\",\"attn(的全球, 2)= 0.05\",\"attn(的全球, 月)= 0.12\",\"attn(的全球, 的全球)= 0.42\",\"attn(的全球, 金融市场)= 0.00\",\"attn(的全球, 抛)= 0.00\",\"attn(的全球, 售)= 0.00\",\"attn(的全球, ，)= 0.00\",\"attn(的全球, 而)= 0.00\",\"attn(的全球, 这一)= 0.00\",\"attn(的全球, 抛)= 0.00\",\"attn(的全球, 售)= 0.00\",\"attn(的全球, 潮)= 0.00\",\"attn(的全球, 主要)= 0.00\",\"attn(的全球, 是因为)= 0.00\",\"attn(的全球, 对)= 0.00\",\"attn(的全球, 美联储)= 0.00\",\"attn(的全球, 进一步)= 0.00\",\"attn(的全球, 紧缩)= 0.00\",\"attn(的全球, 的)= 0.00\",\"attn(的全球, 担忧)= 0.00\",\"attn(的全球, 导致的)= 0.00\",\"attn(的全球, 。)= 0.00\"],[\"attn(金融市场, &lt;s&gt;)= 0.00\",\"attn(金融市场, 美联储)= 0.01\",\"attn(金融市场, 显然)= 0.00\",\"attn(金融市场, 无法)= 0.00\",\"attn(金融市场, 消)= 0.01\",\"attn(金融市场, 化)= 0.02\",\"attn(金融市场, 1)= 0.05\",\"attn(金融市场, 月)= 0.13\",\"attn(金融市场, 和)= 0.00\",\"attn(金融市场, 2)= 0.11\",\"attn(金融市场, 月)= 0.44\",\"attn(金融市场, 的全球)= 0.05\",\"attn(金融市场, 金融市场)= 0.17\",\"attn(金融市场, 抛)= 0.00\",\"attn(金融市场, 售)= 0.00\",\"attn(金融市场, ，)= 0.00\",\"attn(金融市场, 而)= 0.00\",\"attn(金融市场, 这一)= 0.00\",\"attn(金融市场, 抛)= 0.00\",\"attn(金融市场, 售)= 0.00\",\"attn(金融市场, 潮)= 0.00\",\"attn(金融市场, 主要)= 0.00\",\"attn(金融市场, 是因为)= 0.00\",\"attn(金融市场, 对)= 0.00\",\"attn(金融市场, 美联储)= 0.00\",\"attn(金融市场, 进一步)= 0.00\",\"attn(金融市场, 紧缩)= 0.00\",\"attn(金融市场, 的)= 0.00\",\"attn(金融市场, 担忧)= 0.00\",\"attn(金融市场, 导致的)= 0.00\",\"attn(金融市场, 。)= 0.00\"],[\"attn(抛, &lt;s&gt;)= 0.00\",\"attn(抛, 美联储)= 0.00\",\"attn(抛, 显然)= 0.00\",\"attn(抛, 无法)= 0.00\",\"attn(抛, 消)= 0.01\",\"attn(抛, 化)= 0.01\",\"attn(抛, 1)= 0.00\",\"attn(抛, 月)= 0.00\",\"attn(抛, 和)= 0.06\",\"attn(抛, 2)= 0.01\",\"attn(抛, 月)= 0.00\",\"attn(抛, 的全球)= 0.05\",\"attn(抛, 金融市场)= 0.00\",\"attn(抛, 抛)= 0.86\",\"attn(抛, 售)= 0.00\",\"attn(抛, ，)= 0.00\",\"attn(抛, 而)= 0.00\",\"attn(抛, 这一)= 0.00\",\"attn(抛, 抛)= 0.00\",\"attn(抛, 售)= 0.00\",\"attn(抛, 潮)= 0.00\",\"attn(抛, 主要)= 0.00\",\"attn(抛, 是因为)= 0.00\",\"attn(抛, 对)= 0.00\",\"attn(抛, 美联储)= 0.00\",\"attn(抛, 进一步)= 0.00\",\"attn(抛, 紧缩)= 0.00\",\"attn(抛, 的)= 0.00\",\"attn(抛, 担忧)= 0.00\",\"attn(抛, 导致的)= 0.00\",\"attn(抛, 。)= 0.00\"],[\"attn(售, &lt;s&gt;)= 0.00\",\"attn(售, 美联储)= 0.03\",\"attn(售, 显然)= 0.01\",\"attn(售, 无法)= 0.03\",\"attn(售, 消)= 0.06\",\"attn(售, 化)= 0.17\",\"attn(售, 1)= 0.01\",\"attn(售, 月)= 0.01\",\"attn(售, 和)= 0.12\",\"attn(售, 2)= 0.00\",\"attn(售, 月)= 0.01\",\"attn(售, 的全球)= 0.04\",\"attn(售, 金融市场)= 0.02\",\"attn(售, 抛)= 0.10\",\"attn(售, 售)= 0.39\",\"attn(售, ，)= 0.00\",\"attn(售, 而)= 0.00\",\"attn(售, 这一)= 0.00\",\"attn(售, 抛)= 0.00\",\"attn(售, 售)= 0.00\",\"attn(售, 潮)= 0.00\",\"attn(售, 主要)= 0.00\",\"attn(售, 是因为)= 0.00\",\"attn(售, 对)= 0.00\",\"attn(售, 美联储)= 0.00\",\"attn(售, 进一步)= 0.00\",\"attn(售, 紧缩)= 0.00\",\"attn(售, 的)= 0.00\",\"attn(售, 担忧)= 0.00\",\"attn(售, 导致的)= 0.00\",\"attn(售, 。)= 0.00\"],[\"attn(，, &lt;s&gt;)= 0.63\",\"attn(，, 美联储)= 0.03\",\"attn(，, 显然)= 0.01\",\"attn(，, 无法)= 0.00\",\"attn(，, 消)= 0.00\",\"attn(，, 化)= 0.00\",\"attn(，, 1)= 0.00\",\"attn(，, 月)= 0.00\",\"attn(，, 和)= 0.00\",\"attn(，, 2)= 0.00\",\"attn(，, 月)= 0.00\",\"attn(，, 的全球)= 0.00\",\"attn(，, 金融市场)= 0.00\",\"attn(，, 抛)= 0.32\",\"attn(，, 售)= 0.01\",\"attn(，, ，)= 0.00\",\"attn(，, 而)= 0.00\",\"attn(，, 这一)= 0.00\",\"attn(，, 抛)= 0.00\",\"attn(，, 售)= 0.00\",\"attn(，, 潮)= 0.00\",\"attn(，, 主要)= 0.00\",\"attn(，, 是因为)= 0.00\",\"attn(，, 对)= 0.00\",\"attn(，, 美联储)= 0.00\",\"attn(，, 进一步)= 0.00\",\"attn(，, 紧缩)= 0.00\",\"attn(，, 的)= 0.00\",\"attn(，, 担忧)= 0.00\",\"attn(，, 导致的)= 0.00\",\"attn(，, 。)= 0.00\"],[\"attn(而, &lt;s&gt;)= 0.00\",\"attn(而, 美联储)= 0.64\",\"attn(而, 显然)= 0.17\",\"attn(而, 无法)= 0.14\",\"attn(而, 消)= 0.00\",\"attn(而, 化)= 0.00\",\"attn(而, 1)= 0.00\",\"attn(而, 月)= 0.00\",\"attn(而, 和)= 0.00\",\"attn(而, 2)= 0.00\",\"attn(而, 月)= 0.00\",\"attn(而, 的全球)= 0.00\",\"attn(而, 金融市场)= 0.00\",\"attn(而, 抛)= 0.00\",\"attn(而, 售)= 0.01\",\"attn(而, ，)= 0.01\",\"attn(而, 而)= 0.01\",\"attn(而, 这一)= 0.00\",\"attn(而, 抛)= 0.00\",\"attn(而, 售)= 0.00\",\"attn(而, 潮)= 0.00\",\"attn(而, 主要)= 0.00\",\"attn(而, 是因为)= 0.00\",\"attn(而, 对)= 0.00\",\"attn(而, 美联储)= 0.00\",\"attn(而, 进一步)= 0.00\",\"attn(而, 紧缩)= 0.00\",\"attn(而, 的)= 0.00\",\"attn(而, 担忧)= 0.00\",\"attn(而, 导致的)= 0.00\",\"attn(而, 。)= 0.00\"],[\"attn(这一, &lt;s&gt;)= 0.00\",\"attn(这一, 美联储)= 0.01\",\"attn(这一, 显然)= 0.00\",\"attn(这一, 无法)= 0.05\",\"attn(这一, 消)= 0.02\",\"attn(这一, 化)= 0.03\",\"attn(这一, 1)= 0.00\",\"attn(这一, 月)= 0.02\",\"attn(这一, 和)= 0.00\",\"attn(这一, 2)= 0.00\",\"attn(这一, 月)= 0.01\",\"attn(这一, 的全球)= 0.02\",\"attn(这一, 金融市场)= 0.04\",\"attn(这一, 抛)= 0.03\",\"attn(这一, 售)= 0.06\",\"attn(这一, ，)= 0.01\",\"attn(这一, 而)= 0.00\",\"attn(这一, 这一)= 0.71\",\"attn(这一, 抛)= 0.00\",\"attn(这一, 售)= 0.00\",\"attn(这一, 潮)= 0.00\",\"attn(这一, 主要)= 0.00\",\"attn(这一, 是因为)= 0.00\",\"attn(这一, 对)= 0.00\",\"attn(这一, 美联储)= 0.00\",\"attn(这一, 进一步)= 0.00\",\"attn(这一, 紧缩)= 0.00\",\"attn(这一, 的)= 0.00\",\"attn(这一, 担忧)= 0.00\",\"attn(这一, 导致的)= 0.00\",\"attn(这一, 。)= 0.00\"],[\"attn(抛, &lt;s&gt;)= 0.00\",\"attn(抛, 美联储)= 0.00\",\"attn(抛, 显然)= 0.00\",\"attn(抛, 无法)= 0.00\",\"attn(抛, 消)= 0.00\",\"attn(抛, 化)= 0.00\",\"attn(抛, 1)= 0.00\",\"attn(抛, 月)= 0.00\",\"attn(抛, 和)= 0.01\",\"attn(抛, 2)= 0.00\",\"attn(抛, 月)= 0.00\",\"attn(抛, 的全球)= 0.00\",\"attn(抛, 金融市场)= 0.00\",\"attn(抛, 抛)= 0.04\",\"attn(抛, 售)= 0.01\",\"attn(抛, ，)= 0.14\",\"attn(抛, 而)= 0.03\",\"attn(抛, 这一)= 0.05\",\"attn(抛, 抛)= 0.71\",\"attn(抛, 售)= 0.00\",\"attn(抛, 潮)= 0.00\",\"attn(抛, 主要)= 0.00\",\"attn(抛, 是因为)= 0.00\",\"attn(抛, 对)= 0.00\",\"attn(抛, 美联储)= 0.00\",\"attn(抛, 进一步)= 0.00\",\"attn(抛, 紧缩)= 0.00\",\"attn(抛, 的)= 0.00\",\"attn(抛, 担忧)= 0.00\",\"attn(抛, 导致的)= 0.00\",\"attn(抛, 。)= 0.00\"],[\"attn(售, &lt;s&gt;)= 0.00\",\"attn(售, 美联储)= 0.02\",\"attn(售, 显然)= 0.01\",\"attn(售, 无法)= 0.02\",\"attn(售, 消)= 0.06\",\"attn(售, 化)= 0.12\",\"attn(售, 1)= 0.00\",\"attn(售, 月)= 0.01\",\"attn(售, 和)= 0.15\",\"attn(售, 2)= 0.00\",\"attn(售, 月)= 0.00\",\"attn(售, 的全球)= 0.01\",\"attn(售, 金融市场)= 0.01\",\"attn(售, 抛)= 0.02\",\"attn(售, 售)= 0.05\",\"attn(售, ，)= 0.07\",\"attn(售, 而)= 0.02\",\"attn(售, 这一)= 0.10\",\"attn(售, 抛)= 0.09\",\"attn(售, 售)= 0.23\",\"attn(售, 潮)= 0.00\",\"attn(售, 主要)= 0.00\",\"attn(售, 是因为)= 0.00\",\"attn(售, 对)= 0.00\",\"attn(售, 美联储)= 0.00\",\"attn(售, 进一步)= 0.00\",\"attn(售, 紧缩)= 0.00\",\"attn(售, 的)= 0.00\",\"attn(售, 担忧)= 0.00\",\"attn(售, 导致的)= 0.00\",\"attn(售, 。)= 0.00\"],[\"attn(潮, &lt;s&gt;)= 0.00\",\"attn(潮, 美联储)= 0.00\",\"attn(潮, 显然)= 0.00\",\"attn(潮, 无法)= 0.00\",\"attn(潮, 消)= 0.02\",\"attn(潮, 化)= 0.00\",\"attn(潮, 1)= 0.01\",\"attn(潮, 月)= 0.00\",\"attn(潮, 和)= 0.01\",\"attn(潮, 2)= 0.01\",\"attn(潮, 月)= 0.00\",\"attn(潮, 的全球)= 0.00\",\"attn(潮, 金融市场)= 0.00\",\"attn(潮, 抛)= 0.01\",\"attn(潮, 售)= 0.01\",\"attn(潮, ，)= 0.01\",\"attn(潮, 而)= 0.01\",\"attn(潮, 这一)= 0.04\",\"attn(潮, 抛)= 0.06\",\"attn(潮, 售)= 0.06\",\"attn(潮, 潮)= 0.75\",\"attn(潮, 主要)= 0.00\",\"attn(潮, 是因为)= 0.00\",\"attn(潮, 对)= 0.00\",\"attn(潮, 美联储)= 0.00\",\"attn(潮, 进一步)= 0.00\",\"attn(潮, 紧缩)= 0.00\",\"attn(潮, 的)= 0.00\",\"attn(潮, 担忧)= 0.00\",\"attn(潮, 导致的)= 0.00\",\"attn(潮, 。)= 0.00\"],[\"attn(主要, &lt;s&gt;)= 0.00\",\"attn(主要, 美联储)= 0.10\",\"attn(主要, 显然)= 0.00\",\"attn(主要, 无法)= 0.11\",\"attn(主要, 消)= 0.01\",\"attn(主要, 化)= 0.03\",\"attn(主要, 1)= 0.00\",\"attn(主要, 月)= 0.01\",\"attn(主要, 和)= 0.01\",\"attn(主要, 2)= 0.00\",\"attn(主要, 月)= 0.00\",\"attn(主要, 的全球)= 0.05\",\"attn(主要, 金融市场)= 0.02\",\"attn(主要, 抛)= 0.01\",\"attn(主要, 售)= 0.05\",\"attn(主要, ，)= 0.01\",\"attn(主要, 而)= 0.00\",\"attn(主要, 这一)= 0.08\",\"attn(主要, 抛)= 0.02\",\"attn(主要, 售)= 0.16\",\"attn(主要, 潮)= 0.19\",\"attn(主要, 主要)= 0.14\",\"attn(主要, 是因为)= 0.00\",\"attn(主要, 对)= 0.00\",\"attn(主要, 美联储)= 0.00\",\"attn(主要, 进一步)= 0.00\",\"attn(主要, 紧缩)= 0.00\",\"attn(主要, 的)= 0.00\",\"attn(主要, 担忧)= 0.00\",\"attn(主要, 导致的)= 0.00\",\"attn(主要, 。)= 0.00\"],[\"attn(是因为, &lt;s&gt;)= 0.00\",\"attn(是因为, 美联储)= 0.00\",\"attn(是因为, 显然)= 0.00\",\"attn(是因为, 无法)= 0.00\",\"attn(是因为, 消)= 0.00\",\"attn(是因为, 化)= 0.00\",\"attn(是因为, 1)= 0.00\",\"attn(是因为, 月)= 0.00\",\"attn(是因为, 和)= 0.00\",\"attn(是因为, 2)= 0.00\",\"attn(是因为, 月)= 0.00\",\"attn(是因为, 的全球)= 0.00\",\"attn(是因为, 金融市场)= 0.00\",\"attn(是因为, 抛)= 0.01\",\"attn(是因为, 售)= 0.00\",\"attn(是因为, ，)= 0.00\",\"attn(是因为, 而)= 0.01\",\"attn(是因为, 这一)= 0.00\",\"attn(是因为, 抛)= 0.15\",\"attn(是因为, 售)= 0.00\",\"attn(是因为, 潮)= 0.04\",\"attn(是因为, 主要)= 0.01\",\"attn(是因为, 是因为)= 0.76\",\"attn(是因为, 对)= 0.00\",\"attn(是因为, 美联储)= 0.00\",\"attn(是因为, 进一步)= 0.00\",\"attn(是因为, 紧缩)= 0.00\",\"attn(是因为, 的)= 0.00\",\"attn(是因为, 担忧)= 0.00\",\"attn(是因为, 导致的)= 0.00\",\"attn(是因为, 。)= 0.00\"],[\"attn(对, &lt;s&gt;)= 0.00\",\"attn(对, 美联储)= 0.00\",\"attn(对, 显然)= 0.00\",\"attn(对, 无法)= 0.00\",\"attn(对, 消)= 0.00\",\"attn(对, 化)= 0.00\",\"attn(对, 1)= 0.00\",\"attn(对, 月)= 0.00\",\"attn(对, 和)= 0.00\",\"attn(对, 2)= 0.00\",\"attn(对, 月)= 0.00\",\"attn(对, 的全球)= 0.00\",\"attn(对, 金融市场)= 0.00\",\"attn(对, 抛)= 0.02\",\"attn(对, 售)= 0.00\",\"attn(对, ，)= 0.00\",\"attn(对, 而)= 0.00\",\"attn(对, 这一)= 0.00\",\"attn(对, 抛)= 0.06\",\"attn(对, 售)= 0.01\",\"attn(对, 潮)= 0.04\",\"attn(对, 主要)= 0.00\",\"attn(对, 是因为)= 0.27\",\"attn(对, 对)= 0.59\",\"attn(对, 美联储)= 0.00\",\"attn(对, 进一步)= 0.00\",\"attn(对, 紧缩)= 0.00\",\"attn(对, 的)= 0.00\",\"attn(对, 担忧)= 0.00\",\"attn(对, 导致的)= 0.00\",\"attn(对, 。)= 0.00\"],[\"attn(美联储, &lt;s&gt;)= 0.00\",\"attn(美联储, 美联储)= 0.00\",\"attn(美联储, 显然)= 0.00\",\"attn(美联储, 无法)= 0.00\",\"attn(美联储, 消)= 0.00\",\"attn(美联储, 化)= 0.00\",\"attn(美联储, 1)= 0.01\",\"attn(美联储, 月)= 0.01\",\"attn(美联储, 和)= 0.00\",\"attn(美联储, 2)= 0.00\",\"attn(美联储, 月)= 0.01\",\"attn(美联储, 的全球)= 0.01\",\"attn(美联储, 金融市场)= 0.01\",\"attn(美联储, 抛)= 0.01\",\"attn(美联储, 售)= 0.01\",\"attn(美联储, ，)= 0.00\",\"attn(美联储, 而)= 0.00\",\"attn(美联储, 这一)= 0.03\",\"attn(美联储, 抛)= 0.03\",\"attn(美联储, 售)= 0.02\",\"attn(美联储, 潮)= 0.21\",\"attn(美联储, 主要)= 0.04\",\"attn(美联储, 是因为)= 0.04\",\"attn(美联储, 对)= 0.09\",\"attn(美联储, 美联储)= 0.47\",\"attn(美联储, 进一步)= 0.00\",\"attn(美联储, 紧缩)= 0.00\",\"attn(美联储, 的)= 0.00\",\"attn(美联储, 担忧)= 0.00\",\"attn(美联储, 导致的)= 0.00\",\"attn(美联储, 。)= 0.00\"],[\"attn(进一步, &lt;s&gt;)= 0.01\",\"attn(进一步, 美联储)= 0.09\",\"attn(进一步, 显然)= 0.03\",\"attn(进一步, 无法)= 0.03\",\"attn(进一步, 消)= 0.01\",\"attn(进一步, 化)= 0.01\",\"attn(进一步, 1)= 0.01\",\"attn(进一步, 月)= 0.01\",\"attn(进一步, 和)= 0.00\",\"attn(进一步, 2)= 0.00\",\"attn(进一步, 月)= 0.01\",\"attn(进一步, 的全球)= 0.00\",\"attn(进一步, 金融市场)= 0.03\",\"attn(进一步, 抛)= 0.00\",\"attn(进一步, 售)= 0.00\",\"attn(进一步, ，)= 0.00\",\"attn(进一步, 而)= 0.00\",\"attn(进一步, 这一)= 0.06\",\"attn(进一步, 抛)= 0.00\",\"attn(进一步, 售)= 0.00\",\"attn(进一步, 潮)= 0.03\",\"attn(进一步, 主要)= 0.04\",\"attn(进一步, 是因为)= 0.02\",\"attn(进一步, 对)= 0.07\",\"attn(进一步, 美联储)= 0.40\",\"attn(进一步, 进一步)= 0.14\",\"attn(进一步, 紧缩)= 0.00\",\"attn(进一步, 的)= 0.00\",\"attn(进一步, 担忧)= 0.00\",\"attn(进一步, 导致的)= 0.00\",\"attn(进一步, 。)= 0.00\"],[\"attn(紧缩, &lt;s&gt;)= 0.00\",\"attn(紧缩, 美联储)= 0.00\",\"attn(紧缩, 显然)= 0.00\",\"attn(紧缩, 无法)= 0.00\",\"attn(紧缩, 消)= 0.01\",\"attn(紧缩, 化)= 0.00\",\"attn(紧缩, 1)= 0.01\",\"attn(紧缩, 月)= 0.00\",\"attn(紧缩, 和)= 0.00\",\"attn(紧缩, 2)= 0.01\",\"attn(紧缩, 月)= 0.00\",\"attn(紧缩, 的全球)= 0.01\",\"attn(紧缩, 金融市场)= 0.01\",\"attn(紧缩, 抛)= 0.00\",\"attn(紧缩, 售)= 0.00\",\"attn(紧缩, ，)= 0.00\",\"attn(紧缩, 而)= 0.00\",\"attn(紧缩, 这一)= 0.01\",\"attn(紧缩, 抛)= 0.01\",\"attn(紧缩, 售)= 0.00\",\"attn(紧缩, 潮)= 0.05\",\"attn(紧缩, 主要)= 0.01\",\"attn(紧缩, 是因为)= 0.00\",\"attn(紧缩, 对)= 0.01\",\"attn(紧缩, 美联储)= 0.04\",\"attn(紧缩, 进一步)= 0.10\",\"attn(紧缩, 紧缩)= 0.71\",\"attn(紧缩, 的)= 0.00\",\"attn(紧缩, 担忧)= 0.00\",\"attn(紧缩, 导致的)= 0.00\",\"attn(紧缩, 。)= 0.00\"],[\"attn(的, &lt;s&gt;)= 0.01\",\"attn(的, 美联储)= 0.03\",\"attn(的, 显然)= 0.02\",\"attn(的, 无法)= 0.21\",\"attn(的, 消)= 0.04\",\"attn(的, 化)= 0.07\",\"attn(的, 1)= 0.03\",\"attn(的, 月)= 0.32\",\"attn(的, 和)= 0.02\",\"attn(的, 2)= 0.00\",\"attn(的, 月)= 0.05\",\"attn(的, 的全球)= 0.02\",\"attn(的, 金融市场)= 0.06\",\"attn(的, 抛)= 0.00\",\"attn(的, 售)= 0.01\",\"attn(的, ，)= 0.00\",\"attn(的, 而)= 0.00\",\"attn(的, 这一)= 0.00\",\"attn(的, 抛)= 0.00\",\"attn(的, 售)= 0.00\",\"attn(的, 潮)= 0.00\",\"attn(的, 主要)= 0.01\",\"attn(的, 是因为)= 0.01\",\"attn(的, 对)= 0.00\",\"attn(的, 美联储)= 0.02\",\"attn(的, 进一步)= 0.04\",\"attn(的, 紧缩)= 0.02\",\"attn(的, 的)= 0.00\",\"attn(的, 担忧)= 0.00\",\"attn(的, 导致的)= 0.00\",\"attn(的, 。)= 0.00\"],[\"attn(担忧, &lt;s&gt;)= 0.00\",\"attn(担忧, 美联储)= 0.00\",\"attn(担忧, 显然)= 0.00\",\"attn(担忧, 无法)= 0.00\",\"attn(担忧, 消)= 0.00\",\"attn(担忧, 化)= 0.00\",\"attn(担忧, 1)= 0.00\",\"attn(担忧, 月)= 0.00\",\"attn(担忧, 和)= 0.00\",\"attn(担忧, 2)= 0.00\",\"attn(担忧, 月)= 0.00\",\"attn(担忧, 的全球)= 0.00\",\"attn(担忧, 金融市场)= 0.00\",\"attn(担忧, 抛)= 0.00\",\"attn(担忧, 售)= 0.00\",\"attn(担忧, ，)= 0.00\",\"attn(担忧, 而)= 0.00\",\"attn(担忧, 这一)= 0.00\",\"attn(担忧, 抛)= 0.00\",\"attn(担忧, 售)= 0.00\",\"attn(担忧, 潮)= 0.01\",\"attn(担忧, 主要)= 0.00\",\"attn(担忧, 是因为)= 0.00\",\"attn(担忧, 对)= 0.00\",\"attn(担忧, 美联储)= 0.00\",\"attn(担忧, 进一步)= 0.06\",\"attn(担忧, 紧缩)= 0.04\",\"attn(担忧, 的)= 0.04\",\"attn(担忧, 担忧)= 0.84\",\"attn(担忧, 导致的)= 0.00\",\"attn(担忧, 。)= 0.00\"],[\"attn(导致的, &lt;s&gt;)= 0.00\",\"attn(导致的, 美联储)= 0.00\",\"attn(导致的, 显然)= 0.00\",\"attn(导致的, 无法)= 0.00\",\"attn(导致的, 消)= 0.00\",\"attn(导致的, 化)= 0.00\",\"attn(导致的, 1)= 0.00\",\"attn(导致的, 月)= 0.00\",\"attn(导致的, 和)= 0.00\",\"attn(导致的, 2)= 0.00\",\"attn(导致的, 月)= 0.00\",\"attn(导致的, 的全球)= 0.00\",\"attn(导致的, 金融市场)= 0.00\",\"attn(导致的, 抛)= 0.00\",\"attn(导致的, 售)= 0.00\",\"attn(导致的, ，)= 0.00\",\"attn(导致的, 而)= 0.00\",\"attn(导致的, 这一)= 0.00\",\"attn(导致的, 抛)= 0.01\",\"attn(导致的, 售)= 0.00\",\"attn(导致的, 潮)= 0.02\",\"attn(导致的, 主要)= 0.00\",\"attn(导致的, 是因为)= 0.00\",\"attn(导致的, 对)= 0.00\",\"attn(导致的, 美联储)= 0.00\",\"attn(导致的, 进一步)= 0.06\",\"attn(导致的, 紧缩)= 0.04\",\"attn(导致的, 的)= 0.07\",\"attn(导致的, 担忧)= 0.66\",\"attn(导致的, 导致的)= 0.10\",\"attn(导致的, 。)= 0.00\"],[\"attn(。, &lt;s&gt;)= 0.00\",\"attn(。, 美联储)= 0.00\",\"attn(。, 显然)= 0.00\",\"attn(。, 无法)= 0.00\",\"attn(。, 消)= 0.01\",\"attn(。, 化)= 0.00\",\"attn(。, 1)= 0.00\",\"attn(。, 月)= 0.00\",\"attn(。, 和)= 0.00\",\"attn(。, 2)= 0.00\",\"attn(。, 月)= 0.00\",\"attn(。, 的全球)= 0.00\",\"attn(。, 金融市场)= 0.00\",\"attn(。, 抛)= 0.00\",\"attn(。, 售)= 0.00\",\"attn(。, ，)= 0.00\",\"attn(。, 而)= 0.00\",\"attn(。, 这一)= 0.00\",\"attn(。, 抛)= 0.00\",\"attn(。, 售)= 0.00\",\"attn(。, 潮)= 0.02\",\"attn(。, 主要)= 0.01\",\"attn(。, 是因为)= 0.00\",\"attn(。, 对)= 0.00\",\"attn(。, 美联储)= 0.02\",\"attn(。, 进一步)= 0.40\",\"attn(。, 紧缩)= 0.14\",\"attn(。, 的)= 0.03\",\"attn(。, 担忧)= 0.15\",\"attn(。, 导致的)= 0.04\",\"attn(。, 。)= 0.15\"]],\"x\":[\"\\u003cspan style='font-size: 10px;color:grey'\\u003e000\\u003c\\u002fspan\\u003e  &lt;s&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e001\\u003c\\u002fspan\\u003e  美联储\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e002\\u003c\\u002fspan\\u003e  显然\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e003\\u003c\\u002fspan\\u003e  无法\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e004\\u003c\\u002fspan\\u003e  消\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e005\\u003c\\u002fspan\\u003e  化\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e006\\u003c\\u002fspan\\u003e  1\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e007\\u003c\\u002fspan\\u003e  月\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e008\\u003c\\u002fspan\\u003e  和\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e009\\u003c\\u002fspan\\u003e  2\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e010\\u003c\\u002fspan\\u003e  月\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e011\\u003c\\u002fspan\\u003e  的全球\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e012\\u003c\\u002fspan\\u003e  金融市场\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e013\\u003c\\u002fspan\\u003e  抛\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e014\\u003c\\u002fspan\\u003e  售\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e015\\u003c\\u002fspan\\u003e  ，\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e016\\u003c\\u002fspan\\u003e  而\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e017\\u003c\\u002fspan\\u003e  这一\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e018\\u003c\\u002fspan\\u003e  抛\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e019\\u003c\\u002fspan\\u003e  售\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e020\\u003c\\u002fspan\\u003e  潮\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e021\\u003c\\u002fspan\\u003e  主要\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e022\\u003c\\u002fspan\\u003e  是因为\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e023\\u003c\\u002fspan\\u003e  对\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e024\\u003c\\u002fspan\\u003e  美联储\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e025\\u003c\\u002fspan\\u003e  进一步\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e026\\u003c\\u002fspan\\u003e  紧缩\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e027\\u003c\\u002fspan\\u003e  的\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e028\\u003c\\u002fspan\\u003e  担忧\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e029\\u003c\\u002fspan\\u003e  导致的\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e030\\u003c\\u002fspan\\u003e  。\"],\"xgap\":1,\"y\":[\"\\u003cspan style='font-size: 10px;color:grey'\\u003e000\\u003c\\u002fspan\\u003e  &lt;s&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e001\\u003c\\u002fspan\\u003e  美联储\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e002\\u003c\\u002fspan\\u003e  显然\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e003\\u003c\\u002fspan\\u003e  无法\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e004\\u003c\\u002fspan\\u003e  消\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e005\\u003c\\u002fspan\\u003e  化\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e006\\u003c\\u002fspan\\u003e  1\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e007\\u003c\\u002fspan\\u003e  月\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e008\\u003c\\u002fspan\\u003e  和\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e009\\u003c\\u002fspan\\u003e  2\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e010\\u003c\\u002fspan\\u003e  月\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e011\\u003c\\u002fspan\\u003e  的全球\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e012\\u003c\\u002fspan\\u003e  金融市场\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e013\\u003c\\u002fspan\\u003e  抛\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e014\\u003c\\u002fspan\\u003e  售\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e015\\u003c\\u002fspan\\u003e  ，\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e016\\u003c\\u002fspan\\u003e  而\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e017\\u003c\\u002fspan\\u003e  这一\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e018\\u003c\\u002fspan\\u003e  抛\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e019\\u003c\\u002fspan\\u003e  售\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e020\\u003c\\u002fspan\\u003e  潮\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e021\\u003c\\u002fspan\\u003e  主要\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e022\\u003c\\u002fspan\\u003e  是因为\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e023\\u003c\\u002fspan\\u003e  对\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e024\\u003c\\u002fspan\\u003e  美联储\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e025\\u003c\\u002fspan\\u003e  进一步\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e026\\u003c\\u002fspan\\u003e  紧缩\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e027\\u003c\\u002fspan\\u003e  的\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e028\\u003c\\u002fspan\\u003e  担忧\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e029\\u003c\\u002fspan\\u003e  导致的\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e030\\u003c\\u002fspan\\u003e  。\"],\"ygap\":1,\"z\":[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00007815745,0.9999218,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00001389166,0.9981786,0.0018074764,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008058569,0.6466705,0.032664105,0.31985953,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00004349067,0.46638438,0.06664228,0.4398877,0.027042152,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.000021212274,0.0000044014323,0.000029460438,0.0003005091,0.97564566,0.023998821,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.73120815,0.0063664564,0.0048082937,0.0011416866,0.041770224,0.049205914,0.16549928,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.049925987,0.06928614,0.015512196,0.012037347,0.096079305,0.24024393,0.35654616,0.16036895,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.000117199364,0.00052729034,0.0021110005,0.067293145,0.0020378514,0.013580671,0.00042902958,0.0023328713,0.91157097,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.016054047,0.0008636121,0.0008828409,0.00019217284,0.0019248053,0.0034188374,0.017665468,0.0059964485,0.029827071,0.92317474,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0058297864,0.002550845,0.0020754915,0.00029348902,0.0026599674,0.0027196754,0.011803197,0.007079146,0.05345438,0.8423781,0.06915597,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00006705335,0.00011543825,0.000580974,0.026042258,0.046196096,0.12968239,0.015833125,0.06658982,0.117966205,0.054138985,0.120474614,0.42231303,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0017916742,0.012110964,0.0007585442,0.0011155707,0.008813372,0.017872592,0.051888417,0.12883307,0.0042024055,0.11293446,0.43605274,0.048917998,0.17470817,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006421469,0.000068985435,0.00084295915,0.0003568956,0.0065668477,0.008052015,0.0030921136,0.00026153357,0.061741326,0.012911638,0.0011147825,0.04615451,0.0013056854,0.85688865,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.001826687,0.031274382,0.00872279,0.025095414,0.05917236,0.17392598,0.00699722,0.014759506,0.11614231,0.004543869,0.010171669,0.039846946,0.016823284,0.098289736,0.39240783,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.62575036,0.03199712,0.008503548,0.00045231567,0.00028886358,0.000016241589,0.00007813163,0.00010602114,0.00047598765,0.00013309614,0.0002428522,0.000049125403,0.0020517446,0.31713766,0.00827783,0.004439139,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0030669603,0.64146554,0.16695987,0.14335544,0.0009440305,0.0019214074,0.00028570573,0.0018200977,0.0009763888,0.00006933105,0.0009827117,0.00093464373,0.0038540566,0.0022460872,0.01338516,0.00850989,0.009222636,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00016558867,0.010648889,0.0024678325,0.047350064,0.017481405,0.025532218,0.002625008,0.016862338,0.0032644772,0.0029622451,0.0113092335,0.017501649,0.04142464,0.027371883,0.05579748,0.0066011637,0.00359242,0.70704156,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00058295426,0.000020554018,0.00041199446,0.000104688384,0.0012500847,0.0013402279,0.0004244467,0.000056752768,0.012663388,0.0011462242,0.00010287699,0.0018408425,0.00013752631,0.041061632,0.008748094,0.13565989,0.02978299,0.05287038,0.71179444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.004064248,0.017653065,0.011247233,0.01946856,0.05632175,0.12183631,0.0037335316,0.008530173,0.14962758,0.0027310776,0.0034574931,0.011456533,0.005327492,0.02107594,0.053887807,0.070293024,0.020945188,0.10472145,0.08669036,0.22693117,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0040996615,0.000924908,0.0005627504,0.0000598906,0.016704531,0.0029079854,0.008183625,0.0016505548,0.0110642,0.006757114,0.0026031525,0.0013886002,0.0008364996,0.005676735,0.0054170187,0.012599415,0.0064133652,0.042267766,0.05789958,0.059097882,0.75288486,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00009848943,0.09668294,0.0018022392,0.11270906,0.008850749,0.02848654,0.003979502,0.008042027,0.006853566,0.0027079766,0.0038577209,0.05070822,0.016090257,0.0074215415,0.052569166,0.00907193,0.0002351747,0.08089904,0.018507589,0.16106617,0.19100952,0.13835055,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00072882505,0.00033502348,0.0021336107,0.00009637503,0.0013098749,0.000027649825,0.00010880251,0.00004841251,0.00022903118,0.00041712043,0.00017177545,0.00009671652,0.00021661088,0.013695629,0.0003495816,0.002036116,0.012879155,0.0017722961,0.15461586,0.0027158223,0.040786598,0.0062226118,0.7590065,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.000008759717,0.0000015490572,0.0000143173465,0.00020062346,0.00087114074,0.00028017373,0.00007967166,0.00002489096,0.00171808,0.000035359513,0.000017501525,0.0006279608,0.00007081327,0.018644484,0.0022875632,0.0010229347,0.0005073654,0.00025215515,0.06384715,0.0056267823,0.037182394,0.0026073467,0.27033898,0.59373194,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00009707821,0.0019032459,0.00019939111,0.0010006543,0.003823222,0.0021976836,0.0060620243,0.0077191107,0.0006954733,0.004582623,0.009542414,0.0058509014,0.0077261734,0.010593642,0.008905801,0.000809576,0.0009803155,0.025933573,0.033680435,0.020017324,0.20864679,0.038223214,0.040644426,0.08531441,0.47485048,0.0,0.0,0.0,0.0,0.0,0.0],[0.005975014,0.08925778,0.033642568,0.02734642,0.0060463767,0.0055886894,0.0077301594,0.0118666645,0.0033630952,0.0026717533,0.00784306,0.0036183142,0.025964081,0.0011254264,0.0013149463,0.0013506346,0.0019844838,0.05862022,0.0019521619,0.0018779765,0.032359466,0.03800433,0.023082847,0.066088945,0.4000648,0.14125982,0.0,0.0,0.0,0.0,0.0],[0.000006485868,0.0001661904,0.000034966873,0.00039775722,0.013159192,0.0023542573,0.0055829817,0.0037979009,0.00075365393,0.011696848,0.0042337747,0.006902542,0.0068247505,0.0024437562,0.0007734572,0.0001710665,0.00002492536,0.0072469977,0.006127491,0.0018429436,0.051268574,0.0073932162,0.0015315257,0.014109424,0.04292313,0.099754706,0.70847744,0.0,0.0,0.0,0.0],[0.01043635,0.03434545,0.015451554,0.21041103,0.043313373,0.06559175,0.0342118,0.32107696,0.015580966,0.0026895583,0.046460047,0.01718656,0.06386288,0.0025734876,0.008143822,0.0004901788,0.0005209297,0.0041526635,0.00067845866,0.0026100755,0.0013443362,0.01296731,0.006444013,0.0025585878,0.016482072,0.038582854,0.020083535,0.0017494523,0.0,0.0,0.0],[0.0000013624272,5.571684e-7,0.0000017166938,2.9265271e-7,0.00010474792,0.0000040800433,0.00009536697,0.000027209204,0.0000090922285,0.0006775048,0.00016105085,0.00007857282,0.000013978048,0.00021966464,0.000023998575,0.00011884933,0.000014848808,0.00062967604,0.0019499526,0.00012594732,0.010894627,0.0007783429,0.00028797865,0.00080279243,0.0023401217,0.055331185,0.043997414,0.042256463,0.8390526,0.0,0.0],[0.00032571494,0.000079253194,0.00035126443,0.00021046451,0.0036807514,0.0032195789,0.0016018773,0.0035888217,0.0046074903,0.0026456758,0.0034211709,0.0036424533,0.0010995496,0.004626419,0.0009807682,0.0046712453,0.00062622403,0.0015778232,0.0062899347,0.0011865842,0.02384265,0.0015833597,0.0040001697,0.0015473724,0.0025196834,0.06058771,0.041731913,0.06502355,0.6555213,0.095209226,0.0],[0.0034990662,0.00032186083,0.0017024105,0.0005350618,0.01189929,0.0013289996,0.002181149,0.0027922313,0.0015953146,0.0021193482,0.0023550559,0.0007377074,0.0018111665,0.0011171413,0.00036305556,0.00016736062,0.00042397087,0.0009844898,0.0029415437,0.0009174297,0.018917471,0.0076918188,0.0039340085,0.0025166261,0.019342108,0.39750573,0.13570893,0.03483377,0.15170455,0.036822427,0.15122892]],\"type\":\"heatmap\"}],                        {\"height\":1000,\"title\":{\"text\":\"Decoder self-attn, Layer 0, Head 5\",\"x\":0.5},\"width\":1000,\"xaxis\":{\"automargin\":true,\"showgrid\":false,\"tickangle\":-45,\"ticklen\":5,\"ticks\":\"outside\",\"title\":{\"font\":{\"color\":\"crimson\",\"family\":\"Courier\",\"size\":18},\"text\":\"Key\"}},\"yaxis\":{\"automargin\":true,\"autorange\":\"reversed\",\"showgrid\":false,\"ticklen\":5,\"ticks\":\"outside\",\"title\":{\"font\":{\"color\":\"crimson\",\"family\":\"Courier\",\"size\":18},\"text\":\"Query\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('85a7a547-2d86-4c3a-9bd0-57b023f9bcb5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "vis_attn(\n",
        "    matrix,\n",
        "    xlabels,\n",
        "    ylabels,\n",
        "    title=title\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2aa90ca",
      "metadata": {
        "id": "c2aa90ca"
      },
      "outputs": [],
      "source": [
        "# Image(filename='images/decoder_self_attn2.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b13d013a",
      "metadata": {
        "id": "b13d013a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c2af2095",
      "metadata": {
        "id": "c2af2095"
      },
      "source": [
        "### Decoder cross-attention\n",
        "\n",
        "Decoder side (Chinese) is the query, and encoder side (English) is the key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcaeebb3",
      "metadata": {
        "id": "bcaeebb3"
      },
      "outputs": [],
      "source": [
        "layer = 2\n",
        "head = 6\n",
        "\n",
        "# Decoder cross-attention score: decoder input query encoder output\n",
        "attn_score = model.decoder.layers[layer].cross_attn.attn_score    # [batch_size, num_heads, seq_len, seq_len]\n",
        "attn_score = attn_score.cpu().numpy()\n",
        "\n",
        "matrix = attn_score[0][head]\n",
        "\n",
        "title = f'Decoder cross-attn, Layer {layer}, Head {head}'\n",
        "\n",
        "query_labels = [tokenizer.decode(x) for x in batch['tgt'][0]]       # has been shifted right already\n",
        "key_labels = [tokenizer.decode(x) for x in batch['src'][0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec368f8",
      "metadata": {
        "id": "eec368f8",
        "outputId": "507778eb-a698-41fe-fa77-e48e397f9d7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ],
      "source": [
        "matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd38927",
      "metadata": {
        "id": "bbd38927",
        "outputId": "d506f76d-c02d-42d9-ec8c-bfd49f4f1615",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ],
      "source": [
        "len(query_labels), len(key_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6431d086",
      "metadata": {
        "id": "6431d086",
        "outputId": "a7e4b700-4acc-4d2b-c12a-cb962a4d80fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e4f239d3-ce8f-4043-bcef-b12cfa445fbf\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e4f239d3-ce8f-4043-bcef-b12cfa445fbf\")) {                    Plotly.newPlot(                        \"e4f239d3-ce8f-4043-bcef-b12cfa445fbf\",                        [{\"colorbar\":{\"thickness\":15,\"ticklen\":3},\"colorscale\":[[0.0,\"rgb(255,247,251)\"],[0.125,\"rgb(236,231,242)\"],[0.25,\"rgb(208,209,230)\"],[0.375,\"rgb(166,189,219)\"],[0.5,\"rgb(116,169,207)\"],[0.625,\"rgb(54,144,192)\"],[0.75,\"rgb(5,112,176)\"],[0.875,\"rgb(4,90,141)\"],[1.0,\"rgb(2,56,88)\"]],\"hoverinfo\":\"text\",\"hovertext\":[[\"attn(&lt;s&gt;, &lt;s&gt;)= 0.38\",\"attn(&lt;s&gt;, The)= 0.01\",\"attn(&lt;s&gt;,  Fed)= 0.61\",\"attn(&lt;s&gt;,  apparent)= 0.00\",\"attn(&lt;s&gt;, ly)= 0.00\",\"attn(&lt;s&gt;,  could)= 0.00\",\"attn(&lt;s&gt;,  not)= 0.00\",\"attn(&lt;s&gt;,  st)= 0.00\",\"attn(&lt;s&gt;, om)= 0.00\",\"attn(&lt;s&gt;, ach)= 0.00\",\"attn(&lt;s&gt;,  the)= 0.00\",\"attn(&lt;s&gt;,  sell)= 0.00\",\"attn(&lt;s&gt;, -)= 0.00\",\"attn(&lt;s&gt;, off)= 0.00\",\"attn(&lt;s&gt;,  in)= 0.00\",\"attn(&lt;s&gt;,  global)= 0.00\",\"attn(&lt;s&gt;,  financial)= 0.00\",\"attn(&lt;s&gt;,  markets)= 0.00\",\"attn(&lt;s&gt;,  in)= 0.00\",\"attn(&lt;s&gt;,  January)= 0.00\",\"attn(&lt;s&gt;,  and)= 0.00\",\"attn(&lt;s&gt;,  F)= 0.00\",\"attn(&lt;s&gt;, eb)= 0.00\",\"attn(&lt;s&gt;, ru)= 0.00\",\"attn(&lt;s&gt;, ary)= 0.00\",\"attn(&lt;s&gt;, ,)= 0.00\",\"attn(&lt;s&gt;,  which)= 0.00\",\"attn(&lt;s&gt;,  was)= 0.00\",\"attn(&lt;s&gt;,  driven)= 0.00\",\"attn(&lt;s&gt;,  largely)= 0.00\",\"attn(&lt;s&gt;,  by)= 0.00\",\"attn(&lt;s&gt;,  concerns)= 0.00\",\"attn(&lt;s&gt;,  about)= 0.00\",\"attn(&lt;s&gt;,  further)= 0.00\",\"attn(&lt;s&gt;,  tight)= 0.00\",\"attn(&lt;s&gt;, ening)= 0.00\",\"attn(&lt;s&gt;, .)= 0.00\",\"attn(&lt;s&gt;, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(美联储, &lt;s&gt;)= 0.00\",\"attn(美联储, The)= 0.00\",\"attn(美联储,  Fed)= 0.00\",\"attn(美联储,  apparent)= 0.10\",\"attn(美联储, ly)= 0.09\",\"attn(美联储,  could)= 0.29\",\"attn(美联储,  not)= 0.41\",\"attn(美联储,  st)= 0.04\",\"attn(美联储, om)= 0.04\",\"attn(美联储, ach)= 0.01\",\"attn(美联储,  the)= 0.00\",\"attn(美联储,  sell)= 0.01\",\"attn(美联储, -)= 0.00\",\"attn(美联储, off)= 0.00\",\"attn(美联储,  in)= 0.00\",\"attn(美联储,  global)= 0.00\",\"attn(美联储,  financial)= 0.00\",\"attn(美联储,  markets)= 0.00\",\"attn(美联储,  in)= 0.00\",\"attn(美联储,  January)= 0.00\",\"attn(美联储,  and)= 0.00\",\"attn(美联储,  F)= 0.00\",\"attn(美联储, eb)= 0.00\",\"attn(美联储, ru)= 0.00\",\"attn(美联储, ary)= 0.00\",\"attn(美联储, ,)= 0.00\",\"attn(美联储,  which)= 0.00\",\"attn(美联储,  was)= 0.00\",\"attn(美联储,  driven)= 0.00\",\"attn(美联储,  largely)= 0.00\",\"attn(美联储,  by)= 0.00\",\"attn(美联储,  concerns)= 0.00\",\"attn(美联储,  about)= 0.00\",\"attn(美联储,  further)= 0.00\",\"attn(美联储,  tight)= 0.00\",\"attn(美联储, ening)= 0.00\",\"attn(美联储, .)= 0.00\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(显然, &lt;s&gt;)= 0.00\",\"attn(显然, The)= 0.00\",\"attn(显然,  Fed)= 0.00\",\"attn(显然,  apparent)= 0.07\",\"attn(显然, ly)= 0.11\",\"attn(显然,  could)= 0.12\",\"attn(显然,  not)= 0.19\",\"attn(显然,  st)= 0.16\",\"attn(显然, om)= 0.16\",\"attn(显然, ach)= 0.07\",\"attn(显然,  the)= 0.02\",\"attn(显然,  sell)= 0.07\",\"attn(显然, -)= 0.01\",\"attn(显然, off)= 0.01\",\"attn(显然,  in)= 0.01\",\"attn(显然,  global)= 0.00\",\"attn(显然,  financial)= 0.00\",\"attn(显然,  markets)= 0.00\",\"attn(显然,  in)= 0.00\",\"attn(显然,  January)= 0.00\",\"attn(显然,  and)= 0.00\",\"attn(显然,  F)= 0.00\",\"attn(显然, eb)= 0.00\",\"attn(显然, ru)= 0.00\",\"attn(显然, ary)= 0.00\",\"attn(显然, ,)= 0.00\",\"attn(显然,  which)= 0.00\",\"attn(显然,  was)= 0.00\",\"attn(显然,  driven)= 0.00\",\"attn(显然,  largely)= 0.00\",\"attn(显然,  by)= 0.00\",\"attn(显然,  concerns)= 0.00\",\"attn(显然,  about)= 0.00\",\"attn(显然,  further)= 0.00\",\"attn(显然,  tight)= 0.00\",\"attn(显然, ening)= 0.00\",\"attn(显然, .)= 0.00\",\"attn(显然, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(无法, &lt;s&gt;)= 0.00\",\"attn(无法, The)= 0.00\",\"attn(无法,  Fed)= 0.00\",\"attn(无法,  apparent)= 0.04\",\"attn(无法, ly)= 0.06\",\"attn(无法,  could)= 0.06\",\"attn(无法,  not)= 0.11\",\"attn(无法,  st)= 0.16\",\"attn(无法, om)= 0.19\",\"attn(无法, ach)= 0.09\",\"attn(无法,  the)= 0.03\",\"attn(无法,  sell)= 0.11\",\"attn(无法, -)= 0.06\",\"attn(无法, off)= 0.02\",\"attn(无法,  in)= 0.02\",\"attn(无法,  global)= 0.02\",\"attn(无法,  financial)= 0.01\",\"attn(无法,  markets)= 0.01\",\"attn(无法,  in)= 0.00\",\"attn(无法,  January)= 0.00\",\"attn(无法,  and)= 0.00\",\"attn(无法,  F)= 0.00\",\"attn(无法, eb)= 0.00\",\"attn(无法, ru)= 0.00\",\"attn(无法, ary)= 0.00\",\"attn(无法, ,)= 0.00\",\"attn(无法,  which)= 0.00\",\"attn(无法,  was)= 0.00\",\"attn(无法,  driven)= 0.00\",\"attn(无法,  largely)= 0.00\",\"attn(无法,  by)= 0.00\",\"attn(无法,  concerns)= 0.00\",\"attn(无法,  about)= 0.00\",\"attn(无法,  further)= 0.00\",\"attn(无法,  tight)= 0.00\",\"attn(无法, ening)= 0.00\",\"attn(无法, .)= 0.00\",\"attn(无法, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(消, &lt;s&gt;)= 0.00\",\"attn(消, The)= 0.00\",\"attn(消,  Fed)= 0.00\",\"attn(消,  apparent)= 0.00\",\"attn(消, ly)= 0.01\",\"attn(消,  could)= 0.00\",\"attn(消,  not)= 0.00\",\"attn(消,  st)= 0.07\",\"attn(消, om)= 0.10\",\"attn(消, ach)= 0.14\",\"attn(消,  the)= 0.05\",\"attn(消,  sell)= 0.13\",\"attn(消, -)= 0.17\",\"attn(消, off)= 0.03\",\"attn(消,  in)= 0.07\",\"attn(消,  global)= 0.15\",\"attn(消,  financial)= 0.04\",\"attn(消,  markets)= 0.04\",\"attn(消,  in)= 0.01\",\"attn(消,  January)= 0.00\",\"attn(消,  and)= 0.00\",\"attn(消,  F)= 0.00\",\"attn(消, eb)= 0.00\",\"attn(消, ru)= 0.00\",\"attn(消, ary)= 0.00\",\"attn(消, ,)= 0.00\",\"attn(消,  which)= 0.00\",\"attn(消,  was)= 0.00\",\"attn(消,  driven)= 0.00\",\"attn(消,  largely)= 0.00\",\"attn(消,  by)= 0.00\",\"attn(消,  concerns)= 0.00\",\"attn(消,  about)= 0.00\",\"attn(消,  further)= 0.00\",\"attn(消,  tight)= 0.00\",\"attn(消, ening)= 0.00\",\"attn(消, .)= 0.00\",\"attn(消, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(化, &lt;s&gt;)= 0.00\",\"attn(化, The)= 0.00\",\"attn(化,  Fed)= 0.00\",\"attn(化,  apparent)= 0.01\",\"attn(化, ly)= 0.01\",\"attn(化,  could)= 0.01\",\"attn(化,  not)= 0.02\",\"attn(化,  st)= 0.10\",\"attn(化, om)= 0.16\",\"attn(化, ach)= 0.19\",\"attn(化,  the)= 0.09\",\"attn(化,  sell)= 0.22\",\"attn(化, -)= 0.07\",\"attn(化, off)= 0.04\",\"attn(化,  in)= 0.04\",\"attn(化,  global)= 0.01\",\"attn(化,  financial)= 0.00\",\"attn(化,  markets)= 0.00\",\"attn(化,  in)= 0.00\",\"attn(化,  January)= 0.00\",\"attn(化,  and)= 0.00\",\"attn(化,  F)= 0.00\",\"attn(化, eb)= 0.00\",\"attn(化, ru)= 0.00\",\"attn(化, ary)= 0.00\",\"attn(化, ,)= 0.00\",\"attn(化,  which)= 0.00\",\"attn(化,  was)= 0.00\",\"attn(化,  driven)= 0.00\",\"attn(化,  largely)= 0.00\",\"attn(化,  by)= 0.00\",\"attn(化,  concerns)= 0.00\",\"attn(化,  about)= 0.00\",\"attn(化,  further)= 0.00\",\"attn(化,  tight)= 0.00\",\"attn(化, ening)= 0.00\",\"attn(化, .)= 0.00\",\"attn(化, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(1, &lt;s&gt;)= 0.00\",\"attn(1, The)= 0.00\",\"attn(1,  Fed)= 0.00\",\"attn(1,  apparent)= 0.00\",\"attn(1, ly)= 0.00\",\"attn(1,  could)= 0.00\",\"attn(1,  not)= 0.00\",\"attn(1,  st)= 0.00\",\"attn(1, om)= 0.00\",\"attn(1, ach)= 0.00\",\"attn(1,  the)= 0.00\",\"attn(1,  sell)= 0.00\",\"attn(1, -)= 0.00\",\"attn(1, off)= 0.00\",\"attn(1,  in)= 0.00\",\"attn(1,  global)= 0.00\",\"attn(1,  financial)= 0.00\",\"attn(1,  markets)= 0.00\",\"attn(1,  in)= 0.01\",\"attn(1,  January)= 0.45\",\"attn(1,  and)= 0.00\",\"attn(1,  F)= 0.22\",\"attn(1, eb)= 0.26\",\"attn(1, ru)= 0.01\",\"attn(1, ary)= 0.02\",\"attn(1, ,)= 0.00\",\"attn(1,  which)= 0.00\",\"attn(1,  was)= 0.00\",\"attn(1,  driven)= 0.00\",\"attn(1,  largely)= 0.00\",\"attn(1,  by)= 0.00\",\"attn(1,  concerns)= 0.00\",\"attn(1,  about)= 0.00\",\"attn(1,  further)= 0.00\",\"attn(1,  tight)= 0.00\",\"attn(1, ening)= 0.00\",\"attn(1, .)= 0.00\",\"attn(1, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(月, &lt;s&gt;)= 0.00\",\"attn(月, The)= 0.00\",\"attn(月,  Fed)= 0.00\",\"attn(月,  apparent)= 0.00\",\"attn(月, ly)= 0.00\",\"attn(月,  could)= 0.01\",\"attn(月,  not)= 0.02\",\"attn(月,  st)= 0.01\",\"attn(月, om)= 0.01\",\"attn(月, ach)= 0.03\",\"attn(月,  the)= 0.02\",\"attn(月,  sell)= 0.06\",\"attn(月, -)= 0.02\",\"attn(月, off)= 0.02\",\"attn(月,  in)= 0.03\",\"attn(月,  global)= 0.00\",\"attn(月,  financial)= 0.00\",\"attn(月,  markets)= 0.00\",\"attn(月,  in)= 0.02\",\"attn(月,  January)= 0.19\",\"attn(月,  and)= 0.00\",\"attn(月,  F)= 0.30\",\"attn(月, eb)= 0.18\",\"attn(月, ru)= 0.01\",\"attn(月, ary)= 0.04\",\"attn(月, ,)= 0.00\",\"attn(月,  which)= 0.00\",\"attn(月,  was)= 0.01\",\"attn(月,  driven)= 0.00\",\"attn(月,  largely)= 0.00\",\"attn(月,  by)= 0.00\",\"attn(月,  concerns)= 0.00\",\"attn(月,  about)= 0.00\",\"attn(月,  further)= 0.00\",\"attn(月,  tight)= 0.00\",\"attn(月, ening)= 0.00\",\"attn(月, .)= 0.00\",\"attn(月, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(和, &lt;s&gt;)= 0.00\",\"attn(和, The)= 0.00\",\"attn(和,  Fed)= 0.00\",\"attn(和,  apparent)= 0.00\",\"attn(和, ly)= 0.00\",\"attn(和,  could)= 0.00\",\"attn(和,  not)= 0.00\",\"attn(和,  st)= 0.00\",\"attn(和, om)= 0.01\",\"attn(和, ach)= 0.05\",\"attn(和,  the)= 0.02\",\"attn(和,  sell)= 0.07\",\"attn(和, -)= 0.04\",\"attn(和, off)= 0.09\",\"attn(和,  in)= 0.04\",\"attn(和,  global)= 0.03\",\"attn(和,  financial)= 0.14\",\"attn(和,  markets)= 0.13\",\"attn(和,  in)= 0.03\",\"attn(和,  January)= 0.02\",\"attn(和,  and)= 0.00\",\"attn(和,  F)= 0.25\",\"attn(和, eb)= 0.03\",\"attn(和, ru)= 0.00\",\"attn(和, ary)= 0.03\",\"attn(和, ,)= 0.00\",\"attn(和,  which)= 0.00\",\"attn(和,  was)= 0.00\",\"attn(和,  driven)= 0.00\",\"attn(和,  largely)= 0.00\",\"attn(和,  by)= 0.00\",\"attn(和,  concerns)= 0.00\",\"attn(和,  about)= 0.00\",\"attn(和,  further)= 0.00\",\"attn(和,  tight)= 0.00\",\"attn(和, ening)= 0.00\",\"attn(和, .)= 0.00\",\"attn(和, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(2, &lt;s&gt;)= 0.00\",\"attn(2, The)= 0.00\",\"attn(2,  Fed)= 0.00\",\"attn(2,  apparent)= 0.00\",\"attn(2, ly)= 0.00\",\"attn(2,  could)= 0.00\",\"attn(2,  not)= 0.00\",\"attn(2,  st)= 0.00\",\"attn(2, om)= 0.00\",\"attn(2, ach)= 0.00\",\"attn(2,  the)= 0.00\",\"attn(2,  sell)= 0.00\",\"attn(2, -)= 0.00\",\"attn(2, off)= 0.00\",\"attn(2,  in)= 0.00\",\"attn(2,  global)= 0.00\",\"attn(2,  financial)= 0.00\",\"attn(2,  markets)= 0.00\",\"attn(2,  in)= 0.01\",\"attn(2,  January)= 0.45\",\"attn(2,  and)= 0.00\",\"attn(2,  F)= 0.20\",\"attn(2, eb)= 0.28\",\"attn(2, ru)= 0.01\",\"attn(2, ary)= 0.03\",\"attn(2, ,)= 0.00\",\"attn(2,  which)= 0.00\",\"attn(2,  was)= 0.00\",\"attn(2,  driven)= 0.00\",\"attn(2,  largely)= 0.00\",\"attn(2,  by)= 0.00\",\"attn(2,  concerns)= 0.00\",\"attn(2,  about)= 0.00\",\"attn(2,  further)= 0.00\",\"attn(2,  tight)= 0.00\",\"attn(2, ening)= 0.00\",\"attn(2, .)= 0.00\",\"attn(2, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(月, &lt;s&gt;)= 0.00\",\"attn(月, The)= 0.00\",\"attn(月,  Fed)= 0.00\",\"attn(月,  apparent)= 0.00\",\"attn(月, ly)= 0.00\",\"attn(月,  could)= 0.01\",\"attn(月,  not)= 0.01\",\"attn(月,  st)= 0.00\",\"attn(月, om)= 0.01\",\"attn(月, ach)= 0.02\",\"attn(月,  the)= 0.03\",\"attn(月,  sell)= 0.04\",\"attn(月, -)= 0.03\",\"attn(月, off)= 0.04\",\"attn(月,  in)= 0.03\",\"attn(月,  global)= 0.00\",\"attn(月,  financial)= 0.00\",\"attn(月,  markets)= 0.00\",\"attn(月,  in)= 0.05\",\"attn(月,  January)= 0.10\",\"attn(月,  and)= 0.00\",\"attn(月,  F)= 0.26\",\"attn(月, eb)= 0.11\",\"attn(月, ru)= 0.07\",\"attn(月, ary)= 0.14\",\"attn(月, ,)= 0.00\",\"attn(月,  which)= 0.01\",\"attn(月,  was)= 0.05\",\"attn(月,  driven)= 0.00\",\"attn(月,  largely)= 0.01\",\"attn(月,  by)= 0.00\",\"attn(月,  concerns)= 0.00\",\"attn(月,  about)= 0.00\",\"attn(月,  further)= 0.00\",\"attn(月,  tight)= 0.00\",\"attn(月, ening)= 0.00\",\"attn(月, .)= 0.00\",\"attn(月, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(的全球, &lt;s&gt;)= 0.00\",\"attn(的全球, The)= 0.00\",\"attn(的全球,  Fed)= 0.00\",\"attn(的全球,  apparent)= 0.00\",\"attn(的全球, ly)= 0.00\",\"attn(的全球,  could)= 0.00\",\"attn(的全球,  not)= 0.00\",\"attn(的全球,  st)= 0.00\",\"attn(的全球, om)= 0.01\",\"attn(的全球, ach)= 0.02\",\"attn(的全球,  the)= 0.02\",\"attn(的全球,  sell)= 0.01\",\"attn(的全球, -)= 0.17\",\"attn(的全球, off)= 0.04\",\"attn(的全球,  in)= 0.01\",\"attn(的全球,  global)= 0.06\",\"attn(的全球,  financial)= 0.40\",\"attn(的全球,  markets)= 0.24\",\"attn(的全球,  in)= 0.00\",\"attn(的全球,  January)= 0.00\",\"attn(的全球,  and)= 0.00\",\"attn(的全球,  F)= 0.00\",\"attn(的全球, eb)= 0.00\",\"attn(的全球, ru)= 0.00\",\"attn(的全球, ary)= 0.00\",\"attn(的全球, ,)= 0.00\",\"attn(的全球,  which)= 0.00\",\"attn(的全球,  was)= 0.00\",\"attn(的全球,  driven)= 0.00\",\"attn(的全球,  largely)= 0.00\",\"attn(的全球,  by)= 0.00\",\"attn(的全球,  concerns)= 0.01\",\"attn(的全球,  about)= 0.00\",\"attn(的全球,  further)= 0.00\",\"attn(的全球,  tight)= 0.00\",\"attn(的全球, ening)= 0.00\",\"attn(的全球, .)= 0.00\",\"attn(的全球, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(金融市场, &lt;s&gt;)= 0.00\",\"attn(金融市场, The)= 0.00\",\"attn(金融市场,  Fed)= 0.00\",\"attn(金融市场,  apparent)= 0.00\",\"attn(金融市场, ly)= 0.00\",\"attn(金融市场,  could)= 0.07\",\"attn(金融市场,  not)= 0.08\",\"attn(金融市场,  st)= 0.03\",\"attn(金融市场, om)= 0.04\",\"attn(金融市场, ach)= 0.05\",\"attn(金融市场,  the)= 0.11\",\"attn(金融市场,  sell)= 0.03\",\"attn(金融市场, -)= 0.19\",\"attn(金融市场, off)= 0.06\",\"attn(金融市场,  in)= 0.01\",\"attn(金融市场,  global)= 0.00\",\"attn(金融市场,  financial)= 0.01\",\"attn(金融市场,  markets)= 0.02\",\"attn(金融市场,  in)= 0.01\",\"attn(金融市场,  January)= 0.00\",\"attn(金融市场,  and)= 0.00\",\"attn(金融市场,  F)= 0.00\",\"attn(金融市场, eb)= 0.00\",\"attn(金融市场, ru)= 0.01\",\"attn(金融市场, ary)= 0.01\",\"attn(金融市场, ,)= 0.00\",\"attn(金融市场,  which)= 0.02\",\"attn(金融市场,  was)= 0.03\",\"attn(金融市场,  driven)= 0.01\",\"attn(金融市场,  largely)= 0.08\",\"attn(金融市场,  by)= 0.01\",\"attn(金融市场,  concerns)= 0.05\",\"attn(金融市场,  about)= 0.01\",\"attn(金融市场,  further)= 0.02\",\"attn(金融市场,  tight)= 0.01\",\"attn(金融市场, ening)= 0.01\",\"attn(金融市场, .)= 0.00\",\"attn(金融市场, &lt;\\u002fs&gt;)= 0.01\"],[\"attn(抛, &lt;s&gt;)= 0.00\",\"attn(抛, The)= 0.00\",\"attn(抛,  Fed)= 0.00\",\"attn(抛,  apparent)= 0.00\",\"attn(抛, ly)= 0.00\",\"attn(抛,  could)= 0.00\",\"attn(抛,  not)= 0.00\",\"attn(抛,  st)= 0.00\",\"attn(抛, om)= 0.00\",\"attn(抛, ach)= 0.02\",\"attn(抛,  the)= 0.03\",\"attn(抛,  sell)= 0.02\",\"attn(抛, -)= 0.07\",\"attn(抛, off)= 0.11\",\"attn(抛,  in)= 0.01\",\"attn(抛,  global)= 0.01\",\"attn(抛,  financial)= 0.24\",\"attn(抛,  markets)= 0.19\",\"attn(抛,  in)= 0.01\",\"attn(抛,  January)= 0.00\",\"attn(抛,  and)= 0.01\",\"attn(抛,  F)= 0.00\",\"attn(抛, eb)= 0.00\",\"attn(抛, ru)= 0.01\",\"attn(抛, ary)= 0.02\",\"attn(抛, ,)= 0.00\",\"attn(抛,  which)= 0.02\",\"attn(抛,  was)= 0.02\",\"attn(抛,  driven)= 0.01\",\"attn(抛,  largely)= 0.02\",\"attn(抛,  by)= 0.01\",\"attn(抛,  concerns)= 0.08\",\"attn(抛,  about)= 0.02\",\"attn(抛,  further)= 0.03\",\"attn(抛,  tight)= 0.02\",\"attn(抛, ening)= 0.02\",\"attn(抛, .)= 0.00\",\"attn(抛, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(售, &lt;s&gt;)= 0.00\",\"attn(售, The)= 0.00\",\"attn(售,  Fed)= 0.00\",\"attn(售,  apparent)= 0.00\",\"attn(售, ly)= 0.00\",\"attn(售,  could)= 0.00\",\"attn(售,  not)= 0.00\",\"attn(售,  st)= 0.00\",\"attn(售, om)= 0.00\",\"attn(售, ach)= 0.01\",\"attn(售,  the)= 0.02\",\"attn(售,  sell)= 0.01\",\"attn(售, -)= 0.07\",\"attn(售, off)= 0.06\",\"attn(售,  in)= 0.01\",\"attn(售,  global)= 0.01\",\"attn(售,  financial)= 0.39\",\"attn(售,  markets)= 0.31\",\"attn(售,  in)= 0.00\",\"attn(售,  January)= 0.00\",\"attn(售,  and)= 0.00\",\"attn(售,  F)= 0.00\",\"attn(售, eb)= 0.00\",\"attn(售, ru)= 0.00\",\"attn(售, ary)= 0.01\",\"attn(售, ,)= 0.00\",\"attn(售,  which)= 0.00\",\"attn(售,  was)= 0.00\",\"attn(售,  driven)= 0.00\",\"attn(售,  largely)= 0.01\",\"attn(售,  by)= 0.00\",\"attn(售,  concerns)= 0.03\",\"attn(售,  about)= 0.00\",\"attn(售,  further)= 0.01\",\"attn(售,  tight)= 0.00\",\"attn(售, ening)= 0.01\",\"attn(售, .)= 0.00\",\"attn(售, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(，, &lt;s&gt;)= 0.00\",\"attn(，, The)= 0.00\",\"attn(，,  Fed)= 0.00\",\"attn(，,  apparent)= 0.00\",\"attn(，, ly)= 0.00\",\"attn(，,  could)= 0.00\",\"attn(，,  not)= 0.00\",\"attn(，,  st)= 0.00\",\"attn(，, om)= 0.01\",\"attn(，, ach)= 0.04\",\"attn(，,  the)= 0.04\",\"attn(，,  sell)= 0.06\",\"attn(，, -)= 0.05\",\"attn(，, off)= 0.26\",\"attn(，,  in)= 0.04\",\"attn(，,  global)= 0.01\",\"attn(，,  financial)= 0.03\",\"attn(，,  markets)= 0.04\",\"attn(，,  in)= 0.06\",\"attn(，,  January)= 0.01\",\"attn(，,  and)= 0.00\",\"attn(，,  F)= 0.08\",\"attn(，, eb)= 0.01\",\"attn(，, ru)= 0.06\",\"attn(，, ary)= 0.09\",\"attn(，, ,)= 0.00\",\"attn(，,  which)= 0.02\",\"attn(，,  was)= 0.05\",\"attn(，,  driven)= 0.00\",\"attn(，,  largely)= 0.01\",\"attn(，,  by)= 0.00\",\"attn(，,  concerns)= 0.01\",\"attn(，,  about)= 0.00\",\"attn(，,  further)= 0.00\",\"attn(，,  tight)= 0.00\",\"attn(，, ening)= 0.00\",\"attn(，, .)= 0.00\",\"attn(，, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(而, &lt;s&gt;)= 0.00\",\"attn(而, The)= 0.00\",\"attn(而,  Fed)= 0.00\",\"attn(而,  apparent)= 0.00\",\"attn(而, ly)= 0.00\",\"attn(而,  could)= 0.01\",\"attn(而,  not)= 0.01\",\"attn(而,  st)= 0.00\",\"attn(而, om)= 0.00\",\"attn(而, ach)= 0.02\",\"attn(而,  the)= 0.01\",\"attn(而,  sell)= 0.03\",\"attn(而, -)= 0.01\",\"attn(而, off)= 0.10\",\"attn(而,  in)= 0.01\",\"attn(而,  global)= 0.00\",\"attn(而,  financial)= 0.02\",\"attn(而,  markets)= 0.02\",\"attn(而,  in)= 0.05\",\"attn(而,  January)= 0.10\",\"attn(而,  and)= 0.00\",\"attn(而,  F)= 0.24\",\"attn(而, eb)= 0.10\",\"attn(而, ru)= 0.07\",\"attn(而, ary)= 0.09\",\"attn(而, ,)= 0.00\",\"attn(而,  which)= 0.02\",\"attn(而,  was)= 0.05\",\"attn(而,  driven)= 0.00\",\"attn(而,  largely)= 0.01\",\"attn(而,  by)= 0.00\",\"attn(而,  concerns)= 0.01\",\"attn(而,  about)= 0.00\",\"attn(而,  further)= 0.01\",\"attn(而,  tight)= 0.00\",\"attn(而, ening)= 0.00\",\"attn(而, .)= 0.00\",\"attn(而, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(这一, &lt;s&gt;)= 0.00\",\"attn(这一, The)= 0.00\",\"attn(这一,  Fed)= 0.00\",\"attn(这一,  apparent)= 0.00\",\"attn(这一, ly)= 0.00\",\"attn(这一,  could)= 0.00\",\"attn(这一,  not)= 0.00\",\"attn(这一,  st)= 0.04\",\"attn(这一, om)= 0.07\",\"attn(这一, ach)= 0.07\",\"attn(这一,  the)= 0.06\",\"attn(这一,  sell)= 0.05\",\"attn(这一, -)= 0.33\",\"attn(这一, off)= 0.04\",\"attn(这一,  in)= 0.03\",\"attn(这一,  global)= 0.08\",\"attn(这一,  financial)= 0.12\",\"attn(这一,  markets)= 0.08\",\"attn(这一,  in)= 0.00\",\"attn(这一,  January)= 0.00\",\"attn(这一,  and)= 0.01\",\"attn(这一,  F)= 0.00\",\"attn(这一, eb)= 0.00\",\"attn(这一, ru)= 0.00\",\"attn(这一, ary)= 0.00\",\"attn(这一, ,)= 0.00\",\"attn(这一,  which)= 0.00\",\"attn(这一,  was)= 0.00\",\"attn(这一,  driven)= 0.00\",\"attn(这一,  largely)= 0.00\",\"attn(这一,  by)= 0.00\",\"attn(这一,  concerns)= 0.00\",\"attn(这一,  about)= 0.00\",\"attn(这一,  further)= 0.00\",\"attn(这一,  tight)= 0.00\",\"attn(这一, ening)= 0.00\",\"attn(这一, .)= 0.00\",\"attn(这一, &lt;\\u002fs&gt;)= 0.00\"],[\"attn(抛, &lt;s&gt;)= 0.00\",\"attn(抛, The)= 0.00\",\"attn(抛,  Fed)= 0.00\",\"attn(抛,  apparent)= 0.00\",\"attn(抛, ly)= 0.00\",\"attn(抛,  could)= 0.00\",\"attn(抛,  not)= 0.00\",\"attn(抛,  st)= 0.00\",\"attn(抛, om)= 0.00\",\"attn(抛, ach)= 0.00\",\"attn(抛,  the)= 0.00\",\"attn(抛,  sell)= 0.00\",\"attn(抛, -)= 0.01\",\"attn(抛, off)= 0.03\",\"attn(抛,  in)= 0.00\",\"attn(抛,  global)= 0.00\",\"attn(抛,  financial)= 0.09\",\"attn(抛,  markets)= 0.07\",\"attn(抛,  in)= 0.00\",\"attn(抛,  January)= 0.00\",\"attn(抛,  and)= 0.01\",\"attn(抛,  F)= 0.00\",\"attn(抛, eb)= 0.00\",\"attn(抛, ru)= 0.01\",\"attn(抛, ary)= 0.01\",\"attn(抛, ,)= 0.01\",\"attn(抛,  which)= 0.02\",\"attn(抛,  was)= 0.01\",\"attn(抛,  driven)= 0.05\",\"attn(抛,  largely)= 0.02\",\"attn(抛,  by)= 0.06\",\"attn(抛,  concerns)= 0.24\",\"attn(抛,  about)= 0.09\",\"attn(抛,  further)= 0.08\",\"attn(抛,  tight)= 0.10\",\"attn(抛, ening)= 0.06\",\"attn(抛, .)= 0.01\",\"attn(抛, &lt;\\u002fs&gt;)= 0.02\"],[\"attn(售, &lt;s&gt;)= 0.00\",\"attn(售, The)= 0.00\",\"attn(售,  Fed)= 0.00\",\"attn(售,  apparent)= 0.00\",\"attn(售, ly)= 0.00\",\"attn(售,  could)= 0.00\",\"attn(售,  not)= 0.00\",\"attn(售,  st)= 0.00\",\"attn(售, om)= 0.00\",\"attn(售, ach)= 0.00\",\"attn(售,  the)= 0.00\",\"attn(售,  sell)= 0.00\",\"attn(售, -)= 0.01\",\"attn(售, off)= 0.01\",\"attn(售,  in)= 0.00\",\"attn(售,  global)= 0.00\",\"attn(售,  financial)= 0.26\",\"attn(售,  markets)= 0.21\",\"attn(售,  in)= 0.00\",\"attn(售,  January)= 0.00\",\"attn(售,  and)= 0.00\",\"attn(售,  F)= 0.00\",\"attn(售, eb)= 0.00\",\"attn(售, ru)= 0.00\",\"attn(售, ary)= 0.00\",\"attn(售, ,)= 0.00\",\"attn(售,  which)= 0.00\",\"attn(售,  was)= 0.00\",\"attn(售,  driven)= 0.02\",\"attn(售,  largely)= 0.01\",\"attn(售,  by)= 0.02\",\"attn(售,  concerns)= 0.19\",\"attn(售,  about)= 0.05\",\"attn(售,  further)= 0.07\",\"attn(售,  tight)= 0.06\",\"attn(售, ening)= 0.05\",\"attn(售, .)= 0.00\",\"attn(售, &lt;\\u002fs&gt;)= 0.01\"],[\"attn(潮, &lt;s&gt;)= 0.00\",\"attn(潮, The)= 0.00\",\"attn(潮,  Fed)= 0.00\",\"attn(潮,  apparent)= 0.00\",\"attn(潮, ly)= 0.00\",\"attn(潮,  could)= 0.00\",\"attn(潮,  not)= 0.00\",\"attn(潮,  st)= 0.00\",\"attn(潮, om)= 0.00\",\"attn(潮, ach)= 0.00\",\"attn(潮,  the)= 0.00\",\"attn(潮,  sell)= 0.00\",\"attn(潮, -)= 0.00\",\"attn(潮, off)= 0.00\",\"attn(潮,  in)= 0.00\",\"attn(潮,  global)= 0.00\",\"attn(潮,  financial)= 0.00\",\"attn(潮,  markets)= 0.00\",\"attn(潮,  in)= 0.00\",\"attn(潮,  January)= 0.00\",\"attn(潮,  and)= 0.00\",\"attn(潮,  F)= 0.00\",\"attn(潮, eb)= 0.00\",\"attn(潮, ru)= 0.01\",\"attn(潮, ary)= 0.00\",\"attn(潮, ,)= 0.01\",\"attn(潮,  which)= 0.01\",\"attn(潮,  was)= 0.02\",\"attn(潮,  driven)= 0.08\",\"attn(潮,  largely)= 0.04\",\"attn(潮,  by)= 0.13\",\"attn(潮,  concerns)= 0.25\",\"attn(潮,  about)= 0.18\",\"attn(潮,  further)= 0.05\",\"attn(潮,  tight)= 0.07\",\"attn(潮, ening)= 0.03\",\"attn(潮, .)= 0.04\",\"attn(潮, &lt;\\u002fs&gt;)= 0.08\"],[\"attn(主要, &lt;s&gt;)= 0.00\",\"attn(主要, The)= 0.00\",\"attn(主要,  Fed)= 0.00\",\"attn(主要,  apparent)= 0.00\",\"attn(主要, ly)= 0.00\",\"attn(主要,  could)= 0.00\",\"attn(主要,  not)= 0.00\",\"attn(主要,  st)= 0.00\",\"attn(主要, om)= 0.00\",\"attn(主要, ach)= 0.00\",\"attn(主要,  the)= 0.01\",\"attn(主要,  sell)= 0.00\",\"attn(主要, -)= 0.02\",\"attn(主要, off)= 0.01\",\"attn(主要,  in)= 0.00\",\"attn(主要,  global)= 0.00\",\"attn(主要,  financial)= 0.00\",\"attn(主要,  markets)= 0.00\",\"attn(主要,  in)= 0.00\",\"attn(主要,  January)= 0.00\",\"attn(主要,  and)= 0.00\",\"attn(主要,  F)= 0.00\",\"attn(主要, eb)= 0.00\",\"attn(主要, ru)= 0.01\",\"attn(主要, ary)= 0.00\",\"attn(主要, ,)= 0.01\",\"attn(主要,  which)= 0.02\",\"attn(主要,  was)= 0.02\",\"attn(主要,  driven)= 0.05\",\"attn(主要,  largely)= 0.09\",\"attn(主要,  by)= 0.08\",\"attn(主要,  concerns)= 0.36\",\"attn(主要,  about)= 0.12\",\"attn(主要,  further)= 0.06\",\"attn(主要,  tight)= 0.05\",\"attn(主要, ening)= 0.04\",\"attn(主要, .)= 0.01\",\"attn(主要, &lt;\\u002fs&gt;)= 0.04\"],[\"attn(是因为, &lt;s&gt;)= 0.00\",\"attn(是因为, The)= 0.00\",\"attn(是因为,  Fed)= 0.00\",\"attn(是因为,  apparent)= 0.00\",\"attn(是因为, ly)= 0.00\",\"attn(是因为,  could)= 0.00\",\"attn(是因为,  not)= 0.00\",\"attn(是因为,  st)= 0.00\",\"attn(是因为, om)= 0.00\",\"attn(是因为, ach)= 0.00\",\"attn(是因为,  the)= 0.00\",\"attn(是因为,  sell)= 0.00\",\"attn(是因为, -)= 0.00\",\"attn(是因为, off)= 0.03\",\"attn(是因为,  in)= 0.00\",\"attn(是因为,  global)= 0.00\",\"attn(是因为,  financial)= 0.00\",\"attn(是因为,  markets)= 0.00\",\"attn(是因为,  in)= 0.01\",\"attn(是因为,  January)= 0.00\",\"attn(是因为,  and)= 0.00\",\"attn(是因为,  F)= 0.00\",\"attn(是因为, eb)= 0.00\",\"attn(是因为, ru)= 0.08\",\"attn(是因为, ary)= 0.04\",\"attn(是因为, ,)= 0.00\",\"attn(是因为,  which)= 0.04\",\"attn(是因为,  was)= 0.06\",\"attn(是因为,  driven)= 0.05\",\"attn(是因为,  largely)= 0.05\",\"attn(是因为,  by)= 0.08\",\"attn(是因为,  concerns)= 0.32\",\"attn(是因为,  about)= 0.09\",\"attn(是因为,  further)= 0.05\",\"attn(是因为,  tight)= 0.04\",\"attn(是因为, ening)= 0.02\",\"attn(是因为, .)= 0.00\",\"attn(是因为, &lt;\\u002fs&gt;)= 0.01\"],[\"attn(对, &lt;s&gt;)= 0.00\",\"attn(对, The)= 0.00\",\"attn(对,  Fed)= 0.00\",\"attn(对,  apparent)= 0.00\",\"attn(对, ly)= 0.00\",\"attn(对,  could)= 0.00\",\"attn(对,  not)= 0.00\",\"attn(对,  st)= 0.00\",\"attn(对, om)= 0.00\",\"attn(对, ach)= 0.00\",\"attn(对,  the)= 0.00\",\"attn(对,  sell)= 0.00\",\"attn(对, -)= 0.00\",\"attn(对, off)= 0.00\",\"attn(对,  in)= 0.00\",\"attn(对,  global)= 0.00\",\"attn(对,  financial)= 0.00\",\"attn(对,  markets)= 0.00\",\"attn(对,  in)= 0.00\",\"attn(对,  January)= 0.00\",\"attn(对,  and)= 0.00\",\"attn(对,  F)= 0.00\",\"attn(对, eb)= 0.00\",\"attn(对, ru)= 0.01\",\"attn(对, ary)= 0.00\",\"attn(对, ,)= 0.00\",\"attn(对,  which)= 0.01\",\"attn(对,  was)= 0.01\",\"attn(对,  driven)= 0.03\",\"attn(对,  largely)= 0.01\",\"attn(对,  by)= 0.07\",\"attn(对,  concerns)= 0.54\",\"attn(对,  about)= 0.14\",\"attn(对,  further)= 0.05\",\"attn(对,  tight)= 0.08\",\"attn(对, ening)= 0.02\",\"attn(对, .)= 0.00\",\"attn(对, &lt;\\u002fs&gt;)= 0.02\"],[\"attn(美联储, &lt;s&gt;)= 0.00\",\"attn(美联储, The)= 0.00\",\"attn(美联储,  Fed)= 0.00\",\"attn(美联储,  apparent)= 0.00\",\"attn(美联储, ly)= 0.00\",\"attn(美联储,  could)= 0.00\",\"attn(美联储,  not)= 0.00\",\"attn(美联储,  st)= 0.00\",\"attn(美联储, om)= 0.00\",\"attn(美联储, ach)= 0.00\",\"attn(美联储,  the)= 0.00\",\"attn(美联储,  sell)= 0.00\",\"attn(美联储, -)= 0.00\",\"attn(美联储, off)= 0.00\",\"attn(美联储,  in)= 0.00\",\"attn(美联储,  global)= 0.00\",\"attn(美联储,  financial)= 0.00\",\"attn(美联储,  markets)= 0.00\",\"attn(美联储,  in)= 0.00\",\"attn(美联储,  January)= 0.00\",\"attn(美联储,  and)= 0.00\",\"attn(美联储,  F)= 0.00\",\"attn(美联储, eb)= 0.00\",\"attn(美联储, ru)= 0.01\",\"attn(美联储, ary)= 0.00\",\"attn(美联储, ,)= 0.01\",\"attn(美联储,  which)= 0.01\",\"attn(美联储,  was)= 0.02\",\"attn(美联储,  driven)= 0.07\",\"attn(美联储,  largely)= 0.05\",\"attn(美联储,  by)= 0.13\",\"attn(美联储,  concerns)= 0.28\",\"attn(美联储,  about)= 0.17\",\"attn(美联储,  further)= 0.06\",\"attn(美联储,  tight)= 0.06\",\"attn(美联储, ening)= 0.03\",\"attn(美联储, .)= 0.03\",\"attn(美联储, &lt;\\u002fs&gt;)= 0.06\"],[\"attn(进一步, &lt;s&gt;)= 0.00\",\"attn(进一步, The)= 0.00\",\"attn(进一步,  Fed)= 0.00\",\"attn(进一步,  apparent)= 0.00\",\"attn(进一步, ly)= 0.00\",\"attn(进一步,  could)= 0.00\",\"attn(进一步,  not)= 0.00\",\"attn(进一步,  st)= 0.00\",\"attn(进一步, om)= 0.00\",\"attn(进一步, ach)= 0.00\",\"attn(进一步,  the)= 0.00\",\"attn(进一步,  sell)= 0.00\",\"attn(进一步, -)= 0.00\",\"attn(进一步, off)= 0.00\",\"attn(进一步,  in)= 0.00\",\"attn(进一步,  global)= 0.00\",\"attn(进一步,  financial)= 0.00\",\"attn(进一步,  markets)= 0.00\",\"attn(进一步,  in)= 0.00\",\"attn(进一步,  January)= 0.00\",\"attn(进一步,  and)= 0.00\",\"attn(进一步,  F)= 0.00\",\"attn(进一步, eb)= 0.00\",\"attn(进一步, ru)= 0.00\",\"attn(进一步, ary)= 0.00\",\"attn(进一步, ,)= 0.01\",\"attn(进一步,  which)= 0.00\",\"attn(进一步,  was)= 0.00\",\"attn(进一步,  driven)= 0.05\",\"attn(进一步,  largely)= 0.01\",\"attn(进一步,  by)= 0.06\",\"attn(进一步,  concerns)= 0.22\",\"attn(进一步,  about)= 0.17\",\"attn(进一步,  further)= 0.07\",\"attn(进一步,  tight)= 0.18\",\"attn(进一步, ening)= 0.03\",\"attn(进一步, .)= 0.05\",\"attn(进一步, &lt;\\u002fs&gt;)= 0.15\"],[\"attn(紧缩, &lt;s&gt;)= 0.00\",\"attn(紧缩, The)= 0.00\",\"attn(紧缩,  Fed)= 0.00\",\"attn(紧缩,  apparent)= 0.00\",\"attn(紧缩, ly)= 0.00\",\"attn(紧缩,  could)= 0.00\",\"attn(紧缩,  not)= 0.00\",\"attn(紧缩,  st)= 0.00\",\"attn(紧缩, om)= 0.00\",\"attn(紧缩, ach)= 0.00\",\"attn(紧缩,  the)= 0.00\",\"attn(紧缩,  sell)= 0.00\",\"attn(紧缩, -)= 0.00\",\"attn(紧缩, off)= 0.00\",\"attn(紧缩,  in)= 0.00\",\"attn(紧缩,  global)= 0.00\",\"attn(紧缩,  financial)= 0.00\",\"attn(紧缩,  markets)= 0.00\",\"attn(紧缩,  in)= 0.00\",\"attn(紧缩,  January)= 0.00\",\"attn(紧缩,  and)= 0.00\",\"attn(紧缩,  F)= 0.00\",\"attn(紧缩, eb)= 0.00\",\"attn(紧缩, ru)= 0.00\",\"attn(紧缩, ary)= 0.00\",\"attn(紧缩, ,)= 0.01\",\"attn(紧缩,  which)= 0.00\",\"attn(紧缩,  was)= 0.00\",\"attn(紧缩,  driven)= 0.06\",\"attn(紧缩,  largely)= 0.03\",\"attn(紧缩,  by)= 0.10\",\"attn(紧缩,  concerns)= 0.32\",\"attn(紧缩,  about)= 0.19\",\"attn(紧缩,  further)= 0.04\",\"attn(紧缩,  tight)= 0.08\",\"attn(紧缩, ening)= 0.02\",\"attn(紧缩, .)= 0.04\",\"attn(紧缩, &lt;\\u002fs&gt;)= 0.12\"],[\"attn(的, &lt;s&gt;)= 0.00\",\"attn(的, The)= 0.00\",\"attn(的,  Fed)= 0.00\",\"attn(的,  apparent)= 0.00\",\"attn(的, ly)= 0.00\",\"attn(的,  could)= 0.00\",\"attn(的,  not)= 0.00\",\"attn(的,  st)= 0.00\",\"attn(的, om)= 0.00\",\"attn(的, ach)= 0.00\",\"attn(的,  the)= 0.00\",\"attn(的,  sell)= 0.00\",\"attn(的, -)= 0.01\",\"attn(的, off)= 0.01\",\"attn(的,  in)= 0.00\",\"attn(的,  global)= 0.00\",\"attn(的,  financial)= 0.05\",\"attn(的,  markets)= 0.04\",\"attn(的,  in)= 0.00\",\"attn(的,  January)= 0.00\",\"attn(的,  and)= 0.02\",\"attn(的,  F)= 0.00\",\"attn(的, eb)= 0.00\",\"attn(的, ru)= 0.00\",\"attn(的, ary)= 0.00\",\"attn(的, ,)= 0.01\",\"attn(的,  which)= 0.01\",\"attn(的,  was)= 0.01\",\"attn(的,  driven)= 0.05\",\"attn(的,  largely)= 0.02\",\"attn(的,  by)= 0.06\",\"attn(的,  concerns)= 0.27\",\"attn(的,  about)= 0.11\",\"attn(的,  further)= 0.08\",\"attn(的,  tight)= 0.12\",\"attn(的, ening)= 0.05\",\"attn(的, .)= 0.02\",\"attn(的, &lt;\\u002fs&gt;)= 0.05\"],[\"attn(担忧, &lt;s&gt;)= 0.00\",\"attn(担忧, The)= 0.00\",\"attn(担忧,  Fed)= 0.00\",\"attn(担忧,  apparent)= 0.00\",\"attn(担忧, ly)= 0.00\",\"attn(担忧,  could)= 0.00\",\"attn(担忧,  not)= 0.00\",\"attn(担忧,  st)= 0.00\",\"attn(担忧, om)= 0.00\",\"attn(担忧, ach)= 0.00\",\"attn(担忧,  the)= 0.00\",\"attn(担忧,  sell)= 0.00\",\"attn(担忧, -)= 0.00\",\"attn(担忧, off)= 0.00\",\"attn(担忧,  in)= 0.00\",\"attn(担忧,  global)= 0.00\",\"attn(担忧,  financial)= 0.00\",\"attn(担忧,  markets)= 0.00\",\"attn(担忧,  in)= 0.00\",\"attn(担忧,  January)= 0.00\",\"attn(担忧,  and)= 0.00\",\"attn(担忧,  F)= 0.00\",\"attn(担忧, eb)= 0.00\",\"attn(担忧, ru)= 0.00\",\"attn(担忧, ary)= 0.00\",\"attn(担忧, ,)= 0.01\",\"attn(担忧,  which)= 0.01\",\"attn(担忧,  was)= 0.01\",\"attn(担忧,  driven)= 0.07\",\"attn(担忧,  largely)= 0.03\",\"attn(担忧,  by)= 0.15\",\"attn(担忧,  concerns)= 0.18\",\"attn(担忧,  about)= 0.19\",\"attn(担忧,  further)= 0.01\",\"attn(担忧,  tight)= 0.04\",\"attn(担忧, ening)= 0.01\",\"attn(担忧, .)= 0.09\",\"attn(担忧, &lt;\\u002fs&gt;)= 0.19\"],[\"attn(导致的, &lt;s&gt;)= 0.00\",\"attn(导致的, The)= 0.00\",\"attn(导致的,  Fed)= 0.00\",\"attn(导致的,  apparent)= 0.00\",\"attn(导致的, ly)= 0.00\",\"attn(导致的,  could)= 0.00\",\"attn(导致的,  not)= 0.00\",\"attn(导致的,  st)= 0.00\",\"attn(导致的, om)= 0.00\",\"attn(导致的, ach)= 0.00\",\"attn(导致的,  the)= 0.00\",\"attn(导致的,  sell)= 0.00\",\"attn(导致的, -)= 0.00\",\"attn(导致的, off)= 0.00\",\"attn(导致的,  in)= 0.00\",\"attn(导致的,  global)= 0.00\",\"attn(导致的,  financial)= 0.00\",\"attn(导致的,  markets)= 0.00\",\"attn(导致的,  in)= 0.00\",\"attn(导致的,  January)= 0.00\",\"attn(导致的,  and)= 0.00\",\"attn(导致的,  F)= 0.00\",\"attn(导致的, eb)= 0.00\",\"attn(导致的, ru)= 0.00\",\"attn(导致的, ary)= 0.00\",\"attn(导致的, ,)= 0.01\",\"attn(导致的,  which)= 0.00\",\"attn(导致的,  was)= 0.00\",\"attn(导致的,  driven)= 0.05\",\"attn(导致的,  largely)= 0.02\",\"attn(导致的,  by)= 0.07\",\"attn(导致的,  concerns)= 0.37\",\"attn(导致的,  about)= 0.16\",\"attn(导致的,  further)= 0.06\",\"attn(导致的,  tight)= 0.12\",\"attn(导致的, ening)= 0.03\",\"attn(导致的, .)= 0.02\",\"attn(导致的, &lt;\\u002fs&gt;)= 0.07\"],[\"attn(。, &lt;s&gt;)= 0.00\",\"attn(。, The)= 0.00\",\"attn(。,  Fed)= 0.00\",\"attn(。,  apparent)= 0.00\",\"attn(。, ly)= 0.00\",\"attn(。,  could)= 0.09\",\"attn(。,  not)= 0.09\",\"attn(。,  st)= 0.00\",\"attn(。, om)= 0.00\",\"attn(。, ach)= 0.00\",\"attn(。,  the)= 0.01\",\"attn(。,  sell)= 0.00\",\"attn(。, -)= 0.01\",\"attn(。, off)= 0.01\",\"attn(。,  in)= 0.00\",\"attn(。,  global)= 0.00\",\"attn(。,  financial)= 0.00\",\"attn(。,  markets)= 0.00\",\"attn(。,  in)= 0.00\",\"attn(。,  January)= 0.00\",\"attn(。,  and)= 0.00\",\"attn(。,  F)= 0.00\",\"attn(。, eb)= 0.00\",\"attn(。, ru)= 0.03\",\"attn(。, ary)= 0.00\",\"attn(。, ,)= 0.03\",\"attn(。,  which)= 0.02\",\"attn(。,  was)= 0.03\",\"attn(。,  driven)= 0.08\",\"attn(。,  largely)= 0.06\",\"attn(。,  by)= 0.09\",\"attn(。,  concerns)= 0.07\",\"attn(。,  about)= 0.08\",\"attn(。,  further)= 0.04\",\"attn(。,  tight)= 0.04\",\"attn(。, ening)= 0.03\",\"attn(。, .)= 0.07\",\"attn(。, &lt;\\u002fs&gt;)= 0.07\"]],\"x\":[\"\\u003cspan style='font-size: 10px;color:grey'\\u003e000\\u003c\\u002fspan\\u003e  &lt;s&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e001\\u003c\\u002fspan\\u003e  The\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e002\\u003c\\u002fspan\\u003e   Fed\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e003\\u003c\\u002fspan\\u003e   apparent\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e004\\u003c\\u002fspan\\u003e  ly\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e005\\u003c\\u002fspan\\u003e   could\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e006\\u003c\\u002fspan\\u003e   not\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e007\\u003c\\u002fspan\\u003e   st\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e008\\u003c\\u002fspan\\u003e  om\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e009\\u003c\\u002fspan\\u003e  ach\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e010\\u003c\\u002fspan\\u003e   the\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e011\\u003c\\u002fspan\\u003e   sell\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e012\\u003c\\u002fspan\\u003e  -\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e013\\u003c\\u002fspan\\u003e  off\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e014\\u003c\\u002fspan\\u003e   in\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e015\\u003c\\u002fspan\\u003e   global\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e016\\u003c\\u002fspan\\u003e   financial\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e017\\u003c\\u002fspan\\u003e   markets\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e018\\u003c\\u002fspan\\u003e   in\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e019\\u003c\\u002fspan\\u003e   January\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e020\\u003c\\u002fspan\\u003e   and\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e021\\u003c\\u002fspan\\u003e   F\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e022\\u003c\\u002fspan\\u003e  eb\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e023\\u003c\\u002fspan\\u003e  ru\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e024\\u003c\\u002fspan\\u003e  ary\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e025\\u003c\\u002fspan\\u003e  ,\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e026\\u003c\\u002fspan\\u003e   which\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e027\\u003c\\u002fspan\\u003e   was\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e028\\u003c\\u002fspan\\u003e   driven\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e029\\u003c\\u002fspan\\u003e   largely\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e030\\u003c\\u002fspan\\u003e   by\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e031\\u003c\\u002fspan\\u003e   concerns\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e032\\u003c\\u002fspan\\u003e   about\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e033\\u003c\\u002fspan\\u003e   further\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e034\\u003c\\u002fspan\\u003e   tight\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e035\\u003c\\u002fspan\\u003e  ening\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e036\\u003c\\u002fspan\\u003e  .\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e037\\u003c\\u002fspan\\u003e  &lt;\\u002fs&gt;\"],\"xgap\":1,\"y\":[\"\\u003cspan style='font-size: 10px;color:grey'\\u003e000\\u003c\\u002fspan\\u003e  &lt;s&gt;\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e001\\u003c\\u002fspan\\u003e  美联储\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e002\\u003c\\u002fspan\\u003e  显然\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e003\\u003c\\u002fspan\\u003e  无法\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e004\\u003c\\u002fspan\\u003e  消\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e005\\u003c\\u002fspan\\u003e  化\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e006\\u003c\\u002fspan\\u003e  1\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e007\\u003c\\u002fspan\\u003e  月\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e008\\u003c\\u002fspan\\u003e  和\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e009\\u003c\\u002fspan\\u003e  2\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e010\\u003c\\u002fspan\\u003e  月\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e011\\u003c\\u002fspan\\u003e  的全球\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e012\\u003c\\u002fspan\\u003e  金融市场\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e013\\u003c\\u002fspan\\u003e  抛\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e014\\u003c\\u002fspan\\u003e  售\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e015\\u003c\\u002fspan\\u003e  ，\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e016\\u003c\\u002fspan\\u003e  而\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e017\\u003c\\u002fspan\\u003e  这一\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e018\\u003c\\u002fspan\\u003e  抛\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e019\\u003c\\u002fspan\\u003e  售\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e020\\u003c\\u002fspan\\u003e  潮\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e021\\u003c\\u002fspan\\u003e  主要\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e022\\u003c\\u002fspan\\u003e  是因为\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e023\\u003c\\u002fspan\\u003e  对\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e024\\u003c\\u002fspan\\u003e  美联储\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e025\\u003c\\u002fspan\\u003e  进一步\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e026\\u003c\\u002fspan\\u003e  紧缩\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e027\\u003c\\u002fspan\\u003e  的\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e028\\u003c\\u002fspan\\u003e  担忧\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e029\\u003c\\u002fspan\\u003e  导致的\",\"\\u003cspan style='font-size: 10px;color:grey'\\u003e030\\u003c\\u002fspan\\u003e  。\"],\"ygap\":1,\"z\":[[0.37538648,0.011386743,0.60986465,0.0019681838,0.0008294692,0.00005139333,0.000070871676,0.00012316079,0.00013897574,0.00008746986,0.0000040857676,0.00005642332,4.526768e-7,0.0000024271708,0.0000025725963,0.000002380257,4.2418117e-7,3.197966e-7,3.807078e-7,0.000009729575,6.51536e-8,0.000006397274,0.0000064334085,5.3433645e-8,2.3324772e-7,2.888339e-9,3.412807e-8,9.359401e-8,2.8867253e-9,1.4727852e-8,2.0069122e-9,3.4726704e-9,1.4262008e-9,2.3058742e-9,7.8599616e-10,4.0518633e-9,5.2675364e-10,8.1339385e-10],[0.000046862016,0.0012040087,0.00073321036,0.09513881,0.09270822,0.28969648,0.40932685,0.04378299,0.041314535,0.011979985,0.0021280705,0.009265205,0.00061063864,0.00028309107,0.0005874595,0.0001372594,0.00004680016,0.00005778641,0.000062511564,0.00014324974,0.0000014721585,0.0005412565,0.00013270297,0.00000924295,0.00003276648,1.3365445e-7,0.0000049139903,0.000017277891,1.2557662e-7,0.00000515624,8.4708866e-8,2.2267514e-7,4.2891124e-8,1.806907e-7,1.5176575e-8,3.2101048e-7,9.02953e-9,1.445143e-8],[0.00042097637,0.0016714019,0.0022486842,0.06945085,0.10930591,0.11758023,0.19213445,0.16202967,0.15922096,0.069039434,0.0248395,0.065891266,0.007795744,0.00523359,0.0068057575,0.00067218026,0.00011826729,0.00012874746,0.001199488,0.0003947638,0.000018641036,0.0011894886,0.00048431818,0.0003171741,0.00073415803,0.0000030373017,0.00020892896,0.0006705233,0.0000050051667,0.00016434623,0.0000035838948,0.000008016599,0.0000016712991,0.000002930699,4.0113892e-7,0.0000048001143,4.2687216e-7,6.750257e-7],[0.000070855705,0.00059479376,0.00036134289,0.042916432,0.061293703,0.06369204,0.11086785,0.15524007,0.19127294,0.09430038,0.032077298,0.10675061,0.057245404,0.019913182,0.022266556,0.024972677,0.00500232,0.005064482,0.0031535546,0.00008602173,0.000111643385,0.0007486057,0.000114339455,0.00018086324,0.0005377108,0.000003989104,0.00029865926,0.00037085256,0.000012605168,0.00036288245,0.000007171292,0.00004181093,0.0000049725795,0.000023109464,0.000002435643,0.000034168854,4.5265557e-7,0.0000012210678],[0.000033668286,0.00011703507,0.0000846931,0.003044041,0.006550252,0.0005572861,0.0010559821,0.072032884,0.10365417,0.1387816,0.047497265,0.12532541,0.16692431,0.030126099,0.066365875,0.14805694,0.043234136,0.035548713,0.0065988936,0.0000450157,0.0009823807,0.0010774443,0.00006854889,0.00014523846,0.0009107311,0.000008219127,0.00036308594,0.00029354508,0.00001311539,0.00031543858,0.0000067289066,0.00006180533,0.000005856069,0.00004351344,0.0000056390463,0.00006269229,4.5176063e-7,0.0000012947436],[0.000044379947,0.000078260186,0.00039089107,0.008282748,0.0137166865,0.011740854,0.021385264,0.10001144,0.16016693,0.19383897,0.094460286,0.21619268,0.06927834,0.04483384,0.0394534,0.0058929734,0.0026482667,0.0029258511,0.004779841,0.00033580847,0.0001101074,0.0031266469,0.00043267445,0.0007071827,0.0024923168,0.0000071174704,0.00060262316,0.0016005698,0.000012952417,0.0003703417,0.000007443482,0.00003250057,0.0000038540193,0.000014776558,0.0000015562872,0.000018494353,3.7248515e-7,7.114182e-7],[0.000039760707,0.000001961014,0.00334479,0.000018653855,0.000016103939,0.00011381616,0.000086561835,0.00017171024,0.00027018876,0.0022809205,0.0013403443,0.0029517498,0.001140365,0.0026370191,0.002974759,0.00051796425,0.000718096,0.0010514952,0.008069005,0.45418292,0.00038505511,0.22411735,0.26163545,0.0057070674,0.020605516,0.00033046844,0.0012732106,0.0028432396,0.00018501373,0.00027825456,0.000104916675,0.00008851459,0.000055311943,0.00017614059,0.000093349445,0.00014413998,0.000032913278,0.000015907006],[0.0000027543808,0.0000022788868,0.000860253,0.00069353986,0.0008891794,0.013100209,0.015968647,0.009547288,0.014030448,0.03119876,0.024684133,0.057480574,0.018533248,0.020582829,0.026349096,0.0015819924,0.0011301214,0.001598302,0.024348255,0.19131982,0.00006189286,0.3020701,0.18019567,0.011527744,0.040348947,0.000045475837,0.0022846244,0.008542356,0.00004813326,0.0007730166,0.000031717413,0.000055776163,0.000012758692,0.000043661676,0.00000622575,0.0000457556,0.0000022985112,0.0000020796315],[0.000006448629,2.4842277e-7,0.0014530367,0.00002409935,0.000027129186,0.00008724016,0.00012076538,0.0020802855,0.0055070505,0.053370796,0.018535353,0.07128322,0.03562032,0.088208824,0.042226057,0.03184245,0.14266457,0.13420309,0.029956782,0.02371341,0.00073734624,0.25266072,0.025983032,0.0038479376,0.028761417,0.00004387991,0.0018800409,0.0033357767,0.00007936432,0.00064046786,0.00005673984,0.00040531252,0.000043482334,0.00028654997,0.00004511928,0.00025679191,0.0000014314597,0.0000033805654],[0.000009532823,7.922695e-7,0.00089826516,0.000010874965,0.000010694078,0.00009513792,0.000072482726,0.00012295521,0.0001788233,0.0012818754,0.0011881635,0.0020277246,0.0012550574,0.0021452282,0.0029697404,0.00039246117,0.0004571387,0.0006796514,0.009542288,0.4532399,0.00024660313,0.2012602,0.28093985,0.007997172,0.026062062,0.00037392325,0.0016540772,0.0036120254,0.00020120319,0.00036136553,0.00011616557,0.00008912391,0.000058468904,0.00016645537,0.00008883599,0.00013837575,0.000038309678,0.00001709781],[1.197943e-7,1.2486585e-7,0.00003395446,0.00006990343,0.00011738439,0.007143037,0.00795219,0.0037461314,0.005794668,0.020520033,0.032627836,0.035603475,0.02823903,0.040093787,0.026598817,0.0010079769,0.001620851,0.0024829963,0.047300722,0.09709496,0.0002372657,0.25648758,0.11243487,0.06504842,0.1366966,0.0004511065,0.0138444975,0.046662882,0.0006940579,0.0064045773,0.00056579866,0.0009452059,0.00026147583,0.00054617424,0.00011292859,0.00047018772,0.00004501132,0.00004337957],[0.0000013127355,8.9147966e-7,0.0000013398134,0.000014393037,0.00005386387,0.0000048698143,0.0000123140935,0.0030323232,0.0066571143,0.01904795,0.018202012,0.012957726,0.16951223,0.036632538,0.013162973,0.06349934,0.39568838,0.23694514,0.0016363603,8.320241e-7,0.0031362332,0.000071211885,0.0000016401623,0.0002354446,0.00072625105,0.00009809654,0.0010788896,0.0006687196,0.0005033113,0.0025905813,0.00041454675,0.0072801416,0.0007605096,0.002131316,0.00076192955,0.0023086595,0.000023360533,0.00014524521],[2.998761e-8,0.0000014117242,8.208291e-8,0.00048664978,0.0015407276,0.06512513,0.08320493,0.026697852,0.03586878,0.04667569,0.113342844,0.030878624,0.18579654,0.064658634,0.014688068,0.0022499335,0.01100901,0.015540006,0.005489724,0.000018376402,0.0044357153,0.0005439105,0.000033313532,0.01390941,0.008921934,0.003379896,0.020427106,0.034702048,0.01436103,0.075823344,0.014826143,0.049181774,0.013884506,0.015898015,0.0052197753,0.014029735,0.0021289068,0.0050203977],[0.0000010706023,1.494109e-7,0.0000050150634,0.000003144809,0.000008864587,0.000013902437,0.000025130117,0.001146733,0.002559609,0.019181091,0.025587097,0.016774748,0.07107568,0.11336142,0.0136992205,0.012303347,0.23606932,0.19234094,0.010478795,0.00007531227,0.006858471,0.0020802906,0.00012538675,0.011710661,0.019347688,0.002148581,0.015855452,0.017047932,0.012382602,0.021480903,0.012080358,0.08166682,0.016164672,0.025227884,0.01513606,0.022105215,0.0008637588,0.0030066432],[6.093585e-8,2.6073785e-8,6.8158056e-7,0.00000187357,0.000005224551,0.000013014794,0.000027812066,0.00070945354,0.0018498846,0.011387016,0.015792398,0.009408002,0.07212089,0.06404406,0.009128136,0.013470173,0.38938987,0.31383386,0.004126523,0.000018399718,0.0020950828,0.0010914602,0.000032184103,0.002908066,0.0053757424,0.00046806995,0.0042118784,0.0043541812,0.0028117695,0.008195434,0.0027183066,0.032753833,0.0041647777,0.010610304,0.0037149917,0.00852014,0.000113045986,0.0005334018],[1.7112865e-7,2.3096971e-8,0.00005698248,0.000016276861,0.000018091016,0.0018910648,0.0032268942,0.0019107647,0.00511043,0.03554114,0.035195716,0.05989574,0.05178445,0.2644885,0.037611526,0.01005382,0.02615037,0.036234282,0.06405317,0.011936133,0.0008433509,0.0848718,0.014664482,0.05624769,0.08708714,0.00070392597,0.020761214,0.047414973,0.0028420235,0.0139465965,0.002638478,0.012438679,0.0019128727,0.0046964553,0.0009628779,0.002584217,0.00006613243,0.00014161995],[0.0000028462937,2.4365886e-7,0.00089889497,0.00004864849,0.000038278264,0.005381201,0.0057240156,0.0013715946,0.0028155535,0.016718399,0.0131149795,0.027692959,0.012196684,0.09727037,0.014824965,0.0037381714,0.017056858,0.024217911,0.04703763,0.09699821,0.0010382938,0.24110098,0.100564614,0.06762306,0.09463871,0.0012475755,0.018981539,0.045399968,0.0037962897,0.010838174,0.003951377,0.009487282,0.0026394115,0.0058600754,0.0015917559,0.003536635,0.00021982304,0.000336041],[0.000060538456,0.00013918248,0.000019881898,0.00094915624,0.003880511,0.00006236427,0.00013750535,0.042023588,0.06661006,0.074281126,0.05734009,0.05393774,0.33354524,0.03914,0.029570948,0.07763251,0.122051574,0.0796203,0.0020554005,0.0000023407317,0.0052483836,0.00007472222,0.0000042454476,0.00028045848,0.00077848026,0.00013161231,0.001168313,0.00094364875,0.00039323064,0.0025180243,0.0002893005,0.0023909255,0.00037966773,0.0007725391,0.00035096484,0.00101999,0.000040735915,0.00015465275],[3.1510032e-7,3.009294e-8,8.9682953e-7,2.525278e-7,7.0473163e-7,0.0000020060547,0.0000030612316,0.000094011135,0.00019686768,0.0019252498,0.00418449,0.0016102357,0.011341109,0.025016977,0.002034955,0.0019082135,0.089772694,0.07423944,0.0033473715,0.000038951726,0.007164415,0.00070533913,0.0000627756,0.011866455,0.011840443,0.008294666,0.015050829,0.014354139,0.04504211,0.024227267,0.05528921,0.23522317,0.0881026,0.07680064,0.09877247,0.058186077,0.008573668,0.024725849],[7.4274333e-9,2.6706521e-9,5.043305e-8,6.906825e-8,1.9696027e-7,0.0000012496744,0.0000021280596,0.00003357463,0.00008490539,0.00078400766,0.0018727095,0.0005372212,0.009953292,0.011823919,0.0010264431,0.002003304,0.25726417,0.21026886,0.0011914537,0.000007802483,0.0037974576,0.00037713657,0.000013258315,0.0032764177,0.0033077346,0.0034656299,0.004401168,0.003663889,0.01828025,0.012121967,0.023581572,0.18792468,0.049491473,0.071111225,0.059673812,0.04628726,0.0024188876,0.009950767],[2.822828e-11,2.2251126e-10,9.8916535e-11,3.38346e-8,1.3037989e-7,0.000052489315,0.000053394,0.000011937355,0.000019351108,0.00009489828,0.0008410264,0.000063533575,0.0012087174,0.0017154303,0.00009543902,0.0000067373353,0.00037225345,0.00053800823,0.00026097152,0.0000011011706,0.00067975634,0.000030749445,0.0000022960696,0.01134497,0.0026910994,0.011181222,0.009341923,0.015620312,0.07502592,0.040931012,0.13208699,0.2479129,0.17611155,0.050744306,0.06582772,0.029759465,0.040703684,0.084668644],[1.9533498e-11,3.3005218e-10,4.791688e-11,1.0217497e-7,5.67244e-7,0.00003728164,0.000058813792,0.00009961255,0.00017106302,0.00061262475,0.005475298,0.0004860424,0.019314598,0.010728347,0.00094255386,0.00015993393,0.0029179456,0.0035986288,0.0011944418,3.2699174e-7,0.0014877849,0.000022616468,8.600432e-7,0.011667865,0.004020077,0.0064717024,0.017567433,0.020041164,0.054783408,0.08856612,0.08137723,0.35926074,0.116127215,0.05951732,0.046382207,0.037627567,0.011478212,0.03780237],[3.7736858e-10,1.3592765e-11,5.05357e-8,4.4042365e-9,7.97562e-9,0.0000028306276,0.000004320656,0.000005053609,0.000013589799,0.0002204718,0.001009706,0.0003933785,0.0026001337,0.029121604,0.00097569014,0.00023908034,0.0028985352,0.003618632,0.0102200415,0.00019349503,0.00038073046,0.0018273965,0.0003678704,0.07544325,0.04255164,0.002994106,0.04182647,0.056867342,0.050713137,0.04890308,0.08385219,0.3215738,0.09444961,0.05286998,0.037987527,0.022134803,0.0036558474,0.010084544],[1.1853002e-11,1.3153263e-13,2.862401e-10,8.339357e-12,2.7813266e-11,2.6064608e-9,3.6732037e-9,1.0669437e-7,3.796623e-7,0.00002123776,0.000087972185,0.000016794587,0.00025130564,0.003293704,0.000055929348,0.000021618773,0.003594417,0.0030493492,0.00048822214,8.3155226e-7,0.0005075134,0.000070052105,0.0000021353837,0.0052226386,0.004558582,0.0013407358,0.005910061,0.0052540214,0.029605847,0.010136271,0.069413,0.53579336,0.14480329,0.05178792,0.07896624,0.024442174,0.003324156,0.017980056],[8.7592173e-13,1.5758166e-11,6.531114e-12,8.2991845e-9,3.3811222e-8,0.000053753032,0.0000522212,0.00000787513,0.000012375349,0.000082421364,0.0007076193,0.000046776644,0.0009720528,0.0014113656,0.00008502643,0.0000045575707,0.00022615836,0.00037752473,0.00036739875,9.637853e-7,0.0007063753,0.000042673433,0.0000021087092,0.014281679,0.0036588807,0.01045815,0.011295076,0.017839588,0.06953869,0.054322824,0.12800764,0.2812755,0.16771431,0.055742953,0.057509683,0.030601414,0.029465012,0.06312927],[5.740903e-13,7.280532e-12,3.8134186e-14,1.2413792e-10,6.5468053e-10,2.6053092e-8,2.6406017e-8,1.17439505e-7,1.8500053e-7,0.0000011465467,0.000018133807,5.889799e-7,0.00024506688,0.000086218424,0.0000060054813,0.00000861606,0.00024080196,0.000271628,0.000014405041,2.19066e-10,0.0026067724,1.6449448e-8,6.2906713e-10,0.0001363987,0.000023954028,0.005750818,0.0009945969,0.00026093354,0.045149557,0.007971529,0.06139865,0.22237723,0.1701786,0.06861944,0.1791506,0.03325201,0.051187847,0.1500481],[4.858866e-13,7.382695e-12,1.2405792e-13,5.35566e-10,4.386674e-9,2.5991102e-7,3.4825143e-7,0.0000014658341,0.0000023401901,0.00001419046,0.00023893593,0.00000709591,0.0007406766,0.0004139805,0.000027145245,0.0000029615433,0.000079606994,0.00009686679,0.00005376758,2.2270814e-9,0.00076799165,2.2513684e-7,6.909162e-9,0.0014818144,0.00030952587,0.0058974638,0.0037959092,0.0031593533,0.055551834,0.027562322,0.10015984,0.31671882,0.18821605,0.037777133,0.07778245,0.020917859,0.039330956,0.118890814],[6.8831405e-8,2.5072278e-8,5.928276e-8,2.3325435e-7,7.776117e-7,0.0000018529469,0.0000024278556,0.00006303781,0.00013686613,0.00088735495,0.002331247,0.0005816258,0.014007201,0.0123178065,0.0010248888,0.0015592957,0.050868675,0.04296685,0.0009152978,0.0000014072057,0.018465945,0.000040901592,0.0000026896912,0.0028550539,0.0020411576,0.008568124,0.0077973567,0.0051070075,0.048776582,0.022087378,0.059567723,0.27368218,0.11328605,0.07713555,0.11578656,0.05246495,0.015460912,0.04920685],[8.216445e-12,7.4861436e-11,1.5422704e-12,3.929545e-9,2.6223349e-8,0.00000373537,0.000004145117,0.0000031777165,0.0000043341342,0.00001749028,0.00029534448,0.000009441032,0.00020730378,0.00035380686,0.000014228261,2.514273e-7,0.00000363587,0.0000051448555,0.000039126204,7.932586e-9,0.00024175209,2.6433193e-7,2.3734762e-8,0.0040939795,0.0005115115,0.006550133,0.006254855,0.010025608,0.073358335,0.031747516,0.15003166,0.18473789,0.19106165,0.013832451,0.03691581,0.008468915,0.09422154,0.1869849],[2.5435593e-10,5.535904e-11,8.155547e-11,6.965734e-10,3.2199772e-9,1.9322847e-8,2.77802e-8,0.0000011706395,0.000002653686,0.00002932796,0.00023204942,0.000020132395,0.0018296925,0.0020620222,0.000096693846,0.000082026854,0.0021079765,0.0018228078,0.00016879829,1.5275633e-8,0.0040622936,7.781863e-7,4.0981597e-8,0.0011146426,0.00046127857,0.0057650283,0.0049518864,0.0024118933,0.052986663,0.01583972,0.07287773,0.36810073,0.16285157,0.057792667,0.1218214,0.03030007,0.019983947,0.0702223],[0.0000015002805,0.000014249926,0.0000030637086,0.0006009286,0.00074640743,0.08804333,0.094485134,0.0021324072,0.0025974927,0.0021541144,0.006764627,0.0022168735,0.0096214805,0.010598906,0.0017874545,0.0005881089,0.0013713925,0.002273547,0.0032507295,0.00024386168,0.0046067648,0.00033707466,0.00029336067,0.025812306,0.004762538,0.030068908,0.024696898,0.034979045,0.080214046,0.062175956,0.093452945,0.07452364,0.08210326,0.04235023,0.039311387,0.02672654,0.07171343,0.07237611]],\"type\":\"heatmap\"}],                        {\"height\":1000,\"title\":{\"text\":\"Decoder cross-attn, Layer 2, Head 6\",\"x\":0.5},\"width\":1000,\"xaxis\":{\"automargin\":true,\"showgrid\":false,\"tickangle\":-45,\"ticklen\":5,\"ticks\":\"outside\",\"title\":{\"font\":{\"color\":\"crimson\",\"family\":\"Courier\",\"size\":18},\"text\":\"Key\"}},\"yaxis\":{\"automargin\":true,\"autorange\":\"reversed\",\"showgrid\":false,\"ticklen\":5,\"ticks\":\"outside\",\"title\":{\"font\":{\"color\":\"crimson\",\"family\":\"Courier\",\"size\":18},\"text\":\"Query\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e4f239d3-ce8f-4043-bcef-b12cfa445fbf');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "vis_attn(\n",
        "    matrix,\n",
        "    xlabels=key_labels,\n",
        "    ylabels=query_labels,\n",
        "    title=title\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773f69c0",
      "metadata": {
        "id": "773f69c0"
      },
      "outputs": [],
      "source": [
        "# Image(filename='images/decoder_cross_attn2.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "\n",
        "This post updates the original implementation of Annotated Transformer.\n",
        "By incorporating a custom-trained RoBERTa tokenizer, we enable effective tokenization tailored to an English-to-Chinese translation task.\n",
        "The use of Plotly for visualization enhances interactivity and clarity, providing insights into the model's attention mechanisms.\n",
        "Improvements in batching and data collation ensure efficient handling of variable-length sequences,\n",
        "making the model more adaptable to real-world datasets.\n",
        "\n",
        "Future work could explore additional enhancements, such as integrating beam search for decoding,\n",
        "transfer learning with larger multilingual datasets, or implementing model ensembling to improve translation quality further."
      ],
      "metadata": {
        "id": "5TGGjiJpdwnr"
      },
      "id": "5TGGjiJpdwnr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893e1458",
      "metadata": {
        "id": "893e1458"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-",
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5936b79a9c83435c8d0d9ebadf1da18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_965402349a874ca7a0b7c88cb24edbd6",
              "IPY_MODEL_6cf832ba855d4c4f80758ea47318154b",
              "IPY_MODEL_6c57b0feb8ec4c42b2555c5d6af2a10f"
            ],
            "layout": "IPY_MODEL_27f37bc26c6649d8bbcabb42b1656783"
          }
        },
        "965402349a874ca7a0b7c88cb24edbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99bfe6ba1ea34c0a9de441a60fe6bac6",
            "placeholder": "​",
            "style": "IPY_MODEL_1ad5cd94af6f45768d252bba1715c274",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6cf832ba855d4c4f80758ea47318154b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d95b77cfdd548ff868301edd60d01eb",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af0ce552f63549439271e2a22b413f0f",
            "value": 25
          }
        },
        "6c57b0feb8ec4c42b2555c5d6af2a10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07c7c82243da4327a5f31b0b72c53719",
            "placeholder": "​",
            "style": "IPY_MODEL_bad392f6ee7743929b1aafd54d35942f",
            "value": " 25.0/25.0 [00:00&lt;00:00, 628B/s]"
          }
        },
        "27f37bc26c6649d8bbcabb42b1656783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99bfe6ba1ea34c0a9de441a60fe6bac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad5cd94af6f45768d252bba1715c274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d95b77cfdd548ff868301edd60d01eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af0ce552f63549439271e2a22b413f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07c7c82243da4327a5f31b0b72c53719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad392f6ee7743929b1aafd54d35942f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b67caae8b1b8438fba55f36e976c532b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e33f35a5d87145f0b4859e98771718a8",
              "IPY_MODEL_dd2c23b013cd48f88a6f4f042489b283",
              "IPY_MODEL_d5ae167be06c490db896940d9f325bdd"
            ],
            "layout": "IPY_MODEL_70fd2d3c080e4b4eba22492e7dfdb2ac"
          }
        },
        "e33f35a5d87145f0b4859e98771718a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee4d8e185f0474b9a781617798bb1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_45d5d65e37d4409394e512ef7007679c",
            "value": "config.json: 100%"
          }
        },
        "dd2c23b013cd48f88a6f4f042489b283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6fa5da215844a20ab7829539be3c214",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91542acec03f4664a572b803dd5501ec",
            "value": 481
          }
        },
        "d5ae167be06c490db896940d9f325bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c89afeb7f0514905a295524d4c2cd44f",
            "placeholder": "​",
            "style": "IPY_MODEL_fb7d4dd968ca465d9e66a704bfa6cabc",
            "value": " 481/481 [00:00&lt;00:00, 20.8kB/s]"
          }
        },
        "70fd2d3c080e4b4eba22492e7dfdb2ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ee4d8e185f0474b9a781617798bb1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d5d65e37d4409394e512ef7007679c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6fa5da215844a20ab7829539be3c214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91542acec03f4664a572b803dd5501ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c89afeb7f0514905a295524d4c2cd44f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb7d4dd968ca465d9e66a704bfa6cabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae836899b27b47ff8270b49f41f5712a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebba15a232554b10b7fec0fd312a42ef",
              "IPY_MODEL_e1293b26d33b40adb83d5013404ebb54",
              "IPY_MODEL_2fffb82518fe413fa2f8a0ae32ae3f6a"
            ],
            "layout": "IPY_MODEL_8882e9fc34f34681919d7d468eb39f24"
          }
        },
        "ebba15a232554b10b7fec0fd312a42ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_464e71fb8c614cbcab9db270f1e00b94",
            "placeholder": "​",
            "style": "IPY_MODEL_1a7a0570dca24a6cbdfde1cb21caa707",
            "value": "vocab.json: 100%"
          }
        },
        "e1293b26d33b40adb83d5013404ebb54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_208ca23c381d4f78bf36bedd043c7ce8",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87e597e641aa41a49297dc56f9b96fb0",
            "value": 898823
          }
        },
        "2fffb82518fe413fa2f8a0ae32ae3f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d171c6fa90da4bfbb9586b8d0f440ae6",
            "placeholder": "​",
            "style": "IPY_MODEL_048c14c951744150ba338110c13426e3",
            "value": " 899k/899k [00:00&lt;00:00, 1.91MB/s]"
          }
        },
        "8882e9fc34f34681919d7d468eb39f24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "464e71fb8c614cbcab9db270f1e00b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7a0570dca24a6cbdfde1cb21caa707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "208ca23c381d4f78bf36bedd043c7ce8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e597e641aa41a49297dc56f9b96fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d171c6fa90da4bfbb9586b8d0f440ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "048c14c951744150ba338110c13426e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "002ad56ce9b0491298a79e046fb29859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc001015ca3b4b3199a0583b14cfb5bd",
              "IPY_MODEL_c2d57f19dc544049a58cce8b80ec16e4",
              "IPY_MODEL_db42350cbeaa4c8a8b1dad100eda2a1e"
            ],
            "layout": "IPY_MODEL_7d681fdb70a84c2e8b895a0bde56f551"
          }
        },
        "dc001015ca3b4b3199a0583b14cfb5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05b007b8857a4a1ca5be1d0f2626d6a0",
            "placeholder": "​",
            "style": "IPY_MODEL_af1c90febc384adfaf2091b55813b551",
            "value": "merges.txt: 100%"
          }
        },
        "c2d57f19dc544049a58cce8b80ec16e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0ef7972a49a4ae0abb7fa970fb89fb6",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7be200e2090e49288c66f39e4b3228e5",
            "value": 456318
          }
        },
        "db42350cbeaa4c8a8b1dad100eda2a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4876a4a4577e45dbb1f67bfe74133a33",
            "placeholder": "​",
            "style": "IPY_MODEL_ee60114275934baa8d00221371069412",
            "value": " 456k/456k [00:01&lt;00:00, 307kB/s]"
          }
        },
        "7d681fdb70a84c2e8b895a0bde56f551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05b007b8857a4a1ca5be1d0f2626d6a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af1c90febc384adfaf2091b55813b551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0ef7972a49a4ae0abb7fa970fb89fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be200e2090e49288c66f39e4b3228e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4876a4a4577e45dbb1f67bfe74133a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee60114275934baa8d00221371069412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b9ba46e5da54709b3943298d3c9f429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_902ee27ce7c64bb0a613dbc5a9a86108",
              "IPY_MODEL_e90e2bba5b15433c92c107698dcfe422",
              "IPY_MODEL_e1d5b743ae9a4a4d94dde10f2d6192dd"
            ],
            "layout": "IPY_MODEL_ec395712437740afacb20dc35a661043"
          }
        },
        "902ee27ce7c64bb0a613dbc5a9a86108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0be75ea226bb4da78201efab33cb27bb",
            "placeholder": "​",
            "style": "IPY_MODEL_201a7a8d2ced476c857f91b172515625",
            "value": "tokenizer.json: 100%"
          }
        },
        "e90e2bba5b15433c92c107698dcfe422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d2a3801797f437c88236bd8d40e6eed",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b7a212af88942d5bcb99360efbb469e",
            "value": 1355863
          }
        },
        "e1d5b743ae9a4a4d94dde10f2d6192dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9daeb8ba7437498d9e4be31884be935d",
            "placeholder": "​",
            "style": "IPY_MODEL_e7c42b8dbdfb40a1a1191e0fc86a698a",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.15MB/s]"
          }
        },
        "ec395712437740afacb20dc35a661043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0be75ea226bb4da78201efab33cb27bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "201a7a8d2ced476c857f91b172515625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d2a3801797f437c88236bd8d40e6eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7a212af88942d5bcb99360efbb469e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9daeb8ba7437498d9e4be31884be935d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c42b8dbdfb40a1a1191e0fc86a698a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a8a6903d7b6473f8f03ada15535ec22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be0467d812d84fe78a1705d04cb218a5",
              "IPY_MODEL_2e72678b570644f1b5715dedd003749a",
              "IPY_MODEL_300b20bf33ed4741b0cadacaf302c246"
            ],
            "layout": "IPY_MODEL_5c27665501414ca190fb5c4e8848db3f"
          }
        },
        "be0467d812d84fe78a1705d04cb218a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ccfa428499d416b8e5406a27bf56652",
            "placeholder": "​",
            "style": "IPY_MODEL_235770e5cd374301b02760e888538ca4",
            "value": "Tokenizing: 100%"
          }
        },
        "2e72678b570644f1b5715dedd003749a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1edcfdf1b6943699fcec0b5f952f43b",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbada46cf59c45ce9a715756f001f882",
            "value": 50000
          }
        },
        "300b20bf33ed4741b0cadacaf302c246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6686080ff6e549a9a7393ca9198be6e0",
            "placeholder": "​",
            "style": "IPY_MODEL_ef20c534c37c4ef8a8e1468305eb7f01",
            "value": " 50000/50000 [00:29&lt;00:00, 1743.00 examples/s]"
          }
        },
        "5c27665501414ca190fb5c4e8848db3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ccfa428499d416b8e5406a27bf56652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235770e5cd374301b02760e888538ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1edcfdf1b6943699fcec0b5f952f43b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbada46cf59c45ce9a715756f001f882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6686080ff6e549a9a7393ca9198be6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef20c534c37c4ef8a8e1468305eb7f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6128b06f4525458e8a66c1442cfe0ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33f5036a316d4424a3fc13800adeeda0",
              "IPY_MODEL_9cddcd1d079646ccbc58fa7de2dd62d7",
              "IPY_MODEL_1471cf1c4131449fb8a9740e45b93e20"
            ],
            "layout": "IPY_MODEL_3263b827e5be45a4b211210bb300a819"
          }
        },
        "33f5036a316d4424a3fc13800adeeda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19c621b59d4c4dfd8067d0ef54b9647a",
            "placeholder": "​",
            "style": "IPY_MODEL_85344b982db942b687bd932633a92893",
            "value": "Tokenizing: 100%"
          }
        },
        "9cddcd1d079646ccbc58fa7de2dd62d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59a9463f03c341608f30bc30cda03c0b",
            "max": 25278,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab62503d6c9747598767908c2f52ca79",
            "value": 25278
          }
        },
        "1471cf1c4131449fb8a9740e45b93e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830ae40aa0dd4c2ea80ef29768946a54",
            "placeholder": "​",
            "style": "IPY_MODEL_1e1a5666a6f443c38500bf9861792ed3",
            "value": " 25278/25278 [00:13&lt;00:00, 1786.54 examples/s]"
          }
        },
        "3263b827e5be45a4b211210bb300a819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c621b59d4c4dfd8067d0ef54b9647a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85344b982db942b687bd932633a92893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59a9463f03c341608f30bc30cda03c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab62503d6c9747598767908c2f52ca79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "830ae40aa0dd4c2ea80ef29768946a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e1a5666a6f443c38500bf9861792ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a93c47f9f9524771bfc997cf95b18246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5d19cd29c784a74bd539616ee8556c2",
              "IPY_MODEL_bb253ab223274d57bc1bd57bd278470d",
              "IPY_MODEL_82de570e09cd4b279c1d0d5fbdb0d2fc"
            ],
            "layout": "IPY_MODEL_2c9e42e7200d427e8a067fec0634fb6e"
          }
        },
        "b5d19cd29c784a74bd539616ee8556c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df14734bb4ff40fd8b832b835f216d30",
            "placeholder": "​",
            "style": "IPY_MODEL_cc3f96a6a2214d8998a1c8e932dbe848",
            "value": "Downloading data: 100%"
          }
        },
        "bb253ab223274d57bc1bd57bd278470d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aad10d59a93e479190e92e4a78782920",
            "max": 69648006,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9389608316574119a315b3347447887d",
            "value": 69648006
          }
        },
        "82de570e09cd4b279c1d0d5fbdb0d2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe860fa79ccf421a89138162a5de6802",
            "placeholder": "​",
            "style": "IPY_MODEL_a327445ddf4740d69658969e2b353721",
            "value": " 69.6M/69.6M [00:00&lt;00:00, 211MB/s]"
          }
        },
        "2c9e42e7200d427e8a067fec0634fb6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df14734bb4ff40fd8b832b835f216d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc3f96a6a2214d8998a1c8e932dbe848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aad10d59a93e479190e92e4a78782920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9389608316574119a315b3347447887d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe860fa79ccf421a89138162a5de6802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a327445ddf4740d69658969e2b353721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48bc680ff5b54051b3334ac31c7f72ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58f62bf15c2d4e87a2841c4af83b6f8b",
              "IPY_MODEL_a3abd746816b45b9936e339beab27873",
              "IPY_MODEL_d705e8651b394e77840cef0f4178a457"
            ],
            "layout": "IPY_MODEL_68de719e796e4c7a98bcb6649894b811"
          }
        },
        "58f62bf15c2d4e87a2841c4af83b6f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73812ef70f2649b0870108c4fab8bfb6",
            "placeholder": "​",
            "style": "IPY_MODEL_8b3a95077dea44f6a2d35f3c93bdc579",
            "value": "Generating train split: "
          }
        },
        "a3abd746816b45b9936e339beab27873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_240a2eb2efe34b64aceb1920e13ee6c1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45f5adc4803c443aabefdf9690384fec",
            "value": 1
          }
        },
        "d705e8651b394e77840cef0f4178a457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b07873c079334e2fbdb8da85a56685da",
            "placeholder": "​",
            "style": "IPY_MODEL_2cc8d0cc38c543a2acb0f19eb54b96df",
            "value": " 176943/0 [00:04&lt;00:00, 41456.28 examples/s]"
          }
        },
        "68de719e796e4c7a98bcb6649894b811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73812ef70f2649b0870108c4fab8bfb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3a95077dea44f6a2d35f3c93bdc579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "240a2eb2efe34b64aceb1920e13ee6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "45f5adc4803c443aabefdf9690384fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b07873c079334e2fbdb8da85a56685da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc8d0cc38c543a2acb0f19eb54b96df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7d39ad4a88a4ab2bc7b2885e54fcf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1425386a9194f8ea58b2b7541449a80",
              "IPY_MODEL_e46b836264934fe99dea31967926f00f",
              "IPY_MODEL_f5b0d1f3e1d74422bce41f96b4eebfb3"
            ],
            "layout": "IPY_MODEL_a41cbc230a4f4fa288d55949080fa4a5"
          }
        },
        "a1425386a9194f8ea58b2b7541449a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4099f8a847f0427b908017a5f3f1d46a",
            "placeholder": "​",
            "style": "IPY_MODEL_7fcc78aa3d0d4770a6768977ddf3cd06",
            "value": "Downloading data: 100%"
          }
        },
        "e46b836264934fe99dea31967926f00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_989f89b61f914ef1acee2c0c8c903ad4",
            "max": 9949932,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b816c14689b64d73a59a6e5f752ca155",
            "value": 9949932
          }
        },
        "f5b0d1f3e1d74422bce41f96b4eebfb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5928634cb6ba4d80886f83959cdbd518",
            "placeholder": "​",
            "style": "IPY_MODEL_270a4c3556af49019e65a1ef91946e10",
            "value": " 9.95M/9.95M [00:00&lt;00:00, 85.1MB/s]"
          }
        },
        "a41cbc230a4f4fa288d55949080fa4a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4099f8a847f0427b908017a5f3f1d46a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fcc78aa3d0d4770a6768977ddf3cd06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "989f89b61f914ef1acee2c0c8c903ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b816c14689b64d73a59a6e5f752ca155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5928634cb6ba4d80886f83959cdbd518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "270a4c3556af49019e65a1ef91946e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32ec5efd697849a79d9a232739211e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce040bae9cb14586b5bf81fd1026771a",
              "IPY_MODEL_31519438c3694db9bfa9bc8ae6f0eb35",
              "IPY_MODEL_13f73975c07d40b19fe3adb0d87a64ee"
            ],
            "layout": "IPY_MODEL_34bbe527548846bb876a4da41710029c"
          }
        },
        "ce040bae9cb14586b5bf81fd1026771a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a7e1c360c7b49d39829912e608c8df1",
            "placeholder": "​",
            "style": "IPY_MODEL_62a440d2ddac4a209b43019b7e916b98",
            "value": "Generating train split: "
          }
        },
        "31519438c3694db9bfa9bc8ae6f0eb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a4504b86344992ab85916f5e4b0c79",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d96cb7fda2a415ca78398bfd45e1a9a",
            "value": 1
          }
        },
        "13f73975c07d40b19fe3adb0d87a64ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_751eab0965684c978092656d8d863acb",
            "placeholder": "​",
            "style": "IPY_MODEL_71cf84f4da8947019022cbaa3a5b4686",
            "value": " 25278/0 [00:00&lt;00:00, 78911.51 examples/s]"
          }
        },
        "34bbe527548846bb876a4da41710029c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7e1c360c7b49d39829912e608c8df1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a440d2ddac4a209b43019b7e916b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49a4504b86344992ab85916f5e4b0c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2d96cb7fda2a415ca78398bfd45e1a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "751eab0965684c978092656d8d863acb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71cf84f4da8947019022cbaa3a5b4686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}